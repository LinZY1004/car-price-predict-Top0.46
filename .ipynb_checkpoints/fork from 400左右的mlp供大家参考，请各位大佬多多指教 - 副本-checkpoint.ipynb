{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55214  62977\n"
     ]
    }
   ],
   "source": [
    "# 查看数据文件目录  list datalab files\n",
    "!ls datalab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看个人永久空间文件  list files in your permanent storage\n",
    "!ls /home/tianchi/myspace/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version  \n",
      "----------------------------- ---------\n",
      "absl-py                       0.2.2    \n",
      "alabaster                     0.7.11   \n",
      "alembic                       0.9.9    \n",
      "altair                        1.2.0    \n",
      "arrow                         0.12.1   \n",
      "asn1crypto                    0.24.0   \n",
      "astor                         0.6.2    \n",
      "attrs                         18.1.0   \n",
      "Babel                         2.5.3    \n",
      "backcall                      0.1.0    \n",
      "backports.functools-lru-cache 1.5      \n",
      "beautifulsoup4                4.6.0    \n",
      "blaze                         0.10.1   \n",
      "bleach                        1.5.0    \n",
      "blinker                       1.4      \n",
      "bokeh                         0.12.16  \n",
      "boto                          2.48.0   \n",
      "boto3                         1.7.48   \n",
      "botocore                      1.10.48  \n",
      "bunch                         1.0.1    \n",
      "bz2file                       0.98     \n",
      "certifi                       2019.6.16\n",
      "cffi                          1.11.5   \n",
      "chardet                       3.0.4    \n",
      "click                         6.7      \n",
      "cloudpickle                   0.5.3    \n",
      "colorama                      0.3.9    \n",
      "colorlover                    0.2.1    \n",
      "conda                         4.5.5    \n",
      "cryptography                  2.7      \n",
      "cycler                        0.10.0   \n",
      "Cython                        0.28.3   \n",
      "cytoolz                       0.8.2    \n",
      "dask                          0.18.1   \n",
      "datashape                     0.5.4    \n",
      "deap                          1.2.2    \n",
      "decorator                     4.3.0    \n",
      "dill                          0.2.8.2  \n",
      "distributed                   1.22.0   \n",
      "docopt                        0.6.2    \n",
      "docutils                      0.14     \n",
      "entrypoints                   0.2.3    \n",
      "fastcache                     1.0.2    \n",
      "fbprophet                     0.2.1    \n",
      "fitter                        1.0.4    \n",
      "Flask                         1.0.2    \n",
      "Flask-Cors                    3.0.4    \n",
      "funcy                         1.10.3   \n",
      "future                        0.16.0   \n",
      "gast                          0.2.0    \n",
      "gensim                        3.4.0    \n",
      "geohash2                      1.1      \n",
      "gmpy2                         2.0.8    \n",
      "gpxpy                         1.1.2    \n",
      "grpcio                        1.12.1   \n",
      "h5py                          2.8.0    \n",
      "haversine                     0.4.5    \n",
      "heamy                         0.0.7    \n",
      "heapdict                      1.0.0    \n",
      "hmmlearn                      0.2.0    \n",
      "html5lib                      0.9999999\n",
      "humanize                      0.5.1    \n",
      "idna                          2.6      \n",
      "imageio                       2.3.0    \n",
      "imagesize                     1.0.0    \n",
      "ipykernel                     4.8.2    \n",
      "ipython                       6.4.0    \n",
      "ipython-genutils              0.2.0    \n",
      "ipywidgets                    7.2.1    \n",
      "itsdangerous                  0.24     \n",
      "jedi                          0.12.0   \n",
      "jieba                         0.39     \n",
      "Jinja2                        2.10     \n",
      "jmespath                      0.9.3    \n",
      "joblib                        0.12.0   \n",
      "json5                         0.8.5    \n",
      "jsonpickle                    0.9.6    \n",
      "jsonschema                    2.6.0    \n",
      "jupyter                       1.0.0    \n",
      "jupyter-client                5.2.3    \n",
      "jupyter-console               5.2.0    \n",
      "jupyter-core                  4.4.0    \n",
      "jupyterhub                    0.8.1    \n",
      "jupyterlab                    1.0.2    \n",
      "jupyterlab-launcher           0.10.5   \n",
      "jupyterlab-server             1.0.0    \n",
      "Keras                         2.1.6    \n",
      "kiwisolver                    1.0.1    \n",
      "klab-autotime                 0.0.2    \n",
      "lightgbm                      2.1.1    \n",
      "line-profiler                 2.1.2    \n",
      "llvmlite                      0.23.0   \n",
      "locket                        0.2.0    \n",
      "Mako                          1.0.7    \n",
      "Markdown                      2.6.11   \n",
      "MarkupSafe                    1.0      \n",
      "matplotlib                    2.2.2    \n",
      "matplotlib-venn               0.11.5   \n",
      "MDP                           3.5      \n",
      "missingno                     0.4.1    \n",
      "mistune                       0.8.3    \n",
      "more-itertools                4.1.0    \n",
      "mpld3                         0.3      \n",
      "mplleaflet                    0.0.5    \n",
      "msgpack                       0.5.6    \n",
      "multipledispatch              0.5.0    \n",
      "munch                         2.3.2    \n",
      "mxnet                         1.1.0    \n",
      "nbconvert                     5.3.1    \n",
      "nbformat                      4.4.0    \n",
      "netaddr                       0.7.19   \n",
      "networkx                      2.1      \n",
      "nltk                          3.2.5    \n",
      "notebook                      5.4.1    \n",
      "numba                         0.38.1   \n",
      "numexpr                       2.6.5    \n",
      "numpy                         1.13.3   \n",
      "oauthlib                      2.1.0    \n",
      "odo                           0.5.1    \n",
      "olefile                       0.45.1   \n",
      "orderedmultidict              0.7.11   \n",
      "packaging                     17.1     \n",
      "pamela                        0.3.0    \n",
      "pandas                        0.22.0   \n",
      "pandas-profiling              1.4.1    \n",
      "pandocfilters                 1.4.2    \n",
      "parso                         0.2.1    \n",
      "partd                         0.3.8    \n",
      "patsy                         0.4.1    \n",
      "pexpect                       4.5.0    \n",
      "pickleshare                   0.7.4    \n",
      "Pillow                        4.2.1    \n",
      "pip                           19.1.1   \n",
      "plotly                        2.0.15   \n",
      "pluggy                        0.6.0    \n",
      "prompt-toolkit                1.0.15   \n",
      "protobuf                      3.5.2    \n",
      "psutil                        5.4.6    \n",
      "ptyprocess                    0.5.2    \n",
      "pudb                          2017.1.4 \n",
      "py                            1.5.4    \n",
      "py-cpuinfo                    4.0.0    \n",
      "pyasn1                        0.4.3    \n",
      "pycosat                       0.6.3    \n",
      "pycparser                     2.18     \n",
      "pycrypto                      2.6.1    \n",
      "pydot                         1.2.4    \n",
      "pygal                         2.4.0    \n",
      "Pygments                      2.2.0    \n",
      "pygpu                         0.7.6    \n",
      "PyJWT                         1.6.4    \n",
      "pyOpenSSL                     18.0.0   \n",
      "pyparsing                     2.1.10   \n",
      "PySocks                       1.6.8    \n",
      "pystan                        2.14.0.0 \n",
      "pytest                        3.5.1    \n",
      "python-crfsuite               0.9.5    \n",
      "python-dateutil               2.7.3    \n",
      "python-editor                 1.0.3    \n",
      "python-oauth2                 1.0.1    \n",
      "pytz                          2018.5   \n",
      "PyWavelets                    0.5.2    \n",
      "PyYAML                        3.12     \n",
      "pyzmq                         18.0.0   \n",
      "qtconsole                     4.3.1    \n",
      "requests                      2.18.4   \n",
      "requests-oauthlib             0.8.0    \n",
      "rpy2                          2.8.5    \n",
      "rsa                           3.4.2    \n",
      "ruamel-yaml                   0.15.40  \n",
      "ruamel.yaml                   0.15.42  \n",
      "s2sphere                      0.2.5    \n",
      "s3transfer                    0.1.13   \n",
      "sacred                        0.7.4    \n",
      "sacred-nbextension            0.1.0    \n",
      "scikit-image                  0.13.1   \n",
      "scikit-learn                  0.19.1   \n",
      "scipy                         1.0.1    \n",
      "seaborn                       0.8.1    \n",
      "Send2Trash                    1.5.0    \n",
      "setuptools                    41.0.1   \n",
      "SexMachine                    0.1.1    \n",
      "simplegeneric                 0.8.1    \n",
      "singledispatch                3.4.0.3  \n",
      "six                           1.11.0   \n",
      "smart-open                    1.6.0    \n",
      "smhasher                      0.150.1  \n",
      "snowballstemmer               1.2.1    \n",
      "sortedcontainers              2.0.4    \n",
      "Sphinx                        1.7.5    \n",
      "sphinxcontrib-websupport      1.0.1    \n",
      "SQLAlchemy                    1.2.9    \n",
      "statsmodels                   0.8.0    \n",
      "stopit                        1.1.2    \n",
      "sympy                         1.1.1    \n",
      "tables                        3.4.4    \n",
      "tabulate                      0.8.2    \n",
      "tblib                         1.3.2    \n",
      "tensorboard                   1.8.0    \n",
      "tensorflow                    1.8.0    \n",
      "termcolor                     1.1.0    \n",
      "terminado                     0.8.1    \n",
      "testpath                      0.3.1    \n",
      "textblob                      0.15.1   \n",
      "tflearn                       0.3.2    \n",
      "Theano                        1.0.2    \n",
      "toolz                         0.8.2    \n",
      "torch                         0.4.0    \n",
      "torchvision                   0.2.1    \n",
      "tornado                       4.5.3    \n",
      "TPOT                          0.9.3    \n",
      "tqdm                          4.23.4   \n",
      "traitlets                     4.3.2    \n",
      "trueskill                     0.4.4    \n",
      "twython                       3.7.0    \n",
      "tzlocal                       1.5.1    \n",
      "update-checker                0.16     \n",
      "urllib3                       1.22     \n",
      "urwid                         1.3.1    \n",
      "vega                          1.3.0    \n",
      "vida                          0.3      \n",
      "vincent                       0.4.4    \n",
      "wcwidth                       0.1.7    \n",
      "webencodings                  0.5      \n",
      "Werkzeug                      0.14.1   \n",
      "wheel                         0.33.4   \n",
      "widgetsnbextension            3.2.1    \n",
      "wordcloud                     1.4.1    \n",
      "wrapt                         1.10.11  \n",
      "xgboost                       0.72     \n",
      "xlrd                          1.0.0    \n",
      "zict                          0.1.3    \n"
     ]
    }
   ],
   "source": [
    "# 查看当前kernel下已安装的包  list packages\n",
    "!pip list --format=columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，十分感谢为这次比赛辛苦付出的组织者，下面代码主要是参考了天才儿童大佬和论坛上其他大佬的代码，感谢你们的分享。下面的代码应该能到400左右。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将kilometer当做类别变量处理试试,异常值用groupby处理,'匿名特征可以进一步处理一下'\n",
    "## 基础工具\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import jn\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "## 模型预测的\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "\n",
    "## 数据降维处理的\n",
    "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "## 参数搜索和评价的\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,StratifiedKFold,train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import scipy.signal as signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理异常值\n",
    "def smooth_cols(group,out_value,kind):\n",
    "    cols = ['power']\n",
    "    if kind == 'g':\n",
    "        for col in cols:\n",
    "            yes_no = (group[col]<out_value).astype('int')\n",
    "            new = yes_no * group[col]\n",
    "            group[col] = new.replace(0,group[col].quantile(q=0.995))\n",
    "        return group\n",
    "    if kind == 'l':\n",
    "        for col in cols:\n",
    "            yes_no = (group[col]>out_value).astype('int')\n",
    "            new = yes_no * group[col]\n",
    "            group[col] = new.replace(0,group[col].quantile(q=0.07))\n",
    "        return group        \n",
    "def date_proc(x):\n",
    "    m = int(x[4:6])\n",
    "    if m == 0:\n",
    "        m = 1\n",
    "    return x[:4] + '-' + str(m) + '-' + x[6:]\n",
    "\n",
    "#定义日期提取函数\n",
    "def date_tran(df,fea_col):\n",
    "    for f in tqdm(fea_col):\n",
    "        df[f] = pd.to_datetime(df[f].astype('str').apply(date_proc))\n",
    "        df[f + '_year'] = df[f].dt.year\n",
    "        df[f + '_month'] = df[f].dt.month\n",
    "        df[f + '_day'] = df[f].dt.day\n",
    "        df[f + '_dayofweek'] = df[f].dt.dayofweek\n",
    "    return (df)\n",
    "\n",
    "#分桶操作\n",
    "def cut_group(df,cols,num_bins=50):\n",
    "    for col in cols:\n",
    "        all_range = int(df[col].max()-df[col].min())\n",
    "        bin = [i*all_range/num_bins for i in range(all_range)]\n",
    "        df[col+'_bin'] = pd.cut(df[col], bin, labels=False)\n",
    "    return df\n",
    "\n",
    "### count编码\n",
    "def count_coding(df,fea_col):\n",
    "    for f in fea_col:\n",
    "        df[f + '_count'] = df[f].map(df[f].value_counts())\n",
    "    return(df)\n",
    "#定义交叉特征统计\n",
    "def cross_cat_num(df,num_col,cat_col):\n",
    "    for f1 in tqdm(cat_col):\n",
    "        g = df.groupby(f1, as_index=False)\n",
    "        for f2 in tqdm(num_col):\n",
    "            feat = g[f2].agg({\n",
    "                '{}_{}_max'.format(f1, f2): 'max', '{}_{}_min'.format(f1, f2): 'min',\n",
    "                '{}_{}_median'.format(f1, f2): 'median',\n",
    "            })\n",
    "            df = df.merge(feat, on=f1, how='left')\n",
    "    return(df)\n",
    "### 类别特征的二阶交叉\n",
    "from scipy.stats import entropy\n",
    "def cross_qua_cat_num(df):\n",
    "    for f_pair in tqdm([\n",
    "        ['model', 'brand'], ['model', 'regionCode'], ['brand', 'regionCode']\n",
    "    ]):\n",
    "        ### 共现次数\n",
    "        df['_'.join(f_pair) + '_count'] = df.groupby(f_pair)['SaleID'].transform('count')\n",
    "        ### n unique、熵\n",
    "        df = df.merge(df.groupby(f_pair[0], as_index=False)[f_pair[1]].agg({\n",
    "            '{}_{}_nunique'.format(f_pair[0], f_pair[1]): 'nunique',\n",
    "            '{}_{}_ent'.format(f_pair[0], f_pair[1]): lambda x: entropy(x.value_counts() / x.shape[0])\n",
    "        }), on=f_pair[0], how='left')\n",
    "        df = df.merge(df.groupby(f_pair[1], as_index=False)[f_pair[0]].agg({\n",
    "            '{}_{}_nunique'.format(f_pair[1], f_pair[0]): 'nunique',\n",
    "            '{}_{}_ent'.format(f_pair[1], f_pair[0]): lambda x: entropy(x.value_counts() / x.shape[0])\n",
    "        }), on=f_pair[1], how='left')\n",
    "        ### 比例偏好\n",
    "        df['{}_in_{}_prop'.format(f_pair[0], f_pair[1])] = df['_'.join(f_pair) + '_count'] / df[f_pair[1] + '_count']\n",
    "        df['{}_in_{}_prop'.format(f_pair[1], f_pair[0])] = df['_'.join(f_pair) + '_count'] / df[f_pair[0] + '_count']\n",
    "    return (df)\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 37200080.00 MB\n",
      "Memory usage after optimization is: 10200184.00 MB\n",
      "Decreased by 72.6%\n",
      "Memory usage of dataframe is 12000080.00 MB\n",
      "Memory usage after optimization is: 3200184.00 MB\n",
      "Decreased by 73.3%\n",
      "Train data shape: (150000, 31)\n",
      "TestA data shape: (50000, 30)\n",
      "concat_data shape: (200000, 31)\n"
     ]
    }
   ],
   "source": [
    "## 通过Pandas对于数据进行读取 (pandas是一个很友好的数据读取函数库)\n",
    "Train_data = reduce_mem_usage(pd.read_csv('datalab/62977/used_car_train_20200313.csv', sep=' '))\n",
    "TestA_data = reduce_mem_usage(pd.read_csv('datalab/62977/used_car_testB_20200421.csv', sep=' '))\n",
    "\n",
    "#Train_data = Train_data[Train_data['price']>100]\n",
    "#Train_data['price'] = np.log1p(Train_data['price'])\n",
    "## 输出数据的大小信息\n",
    "print('Train data shape:',Train_data.shape)\n",
    "print('TestA data shape:',TestA_data.shape)\n",
    "\n",
    "\n",
    "#合并数据集\n",
    "concat_data = pd.concat([Train_data,TestA_data])\n",
    "concat_data['notRepairedDamage'] = concat_data['notRepairedDamage'].replace('-',0).astype('float16')\n",
    "concat_data = concat_data.fillna(concat_data.mode().iloc[0,:])\n",
    "#concat_data.index = range(200000)\n",
    "#concat_data = concat_data.groupby('bodyType').apply(smooth_cols,out_value=600,kind='g')\n",
    "#concat_data.index = range(200000)\n",
    "#concat_data['power'] = np.log(concat_data['power'])\n",
    "print('concat_data shape:',concat_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#截断异常值\n",
    "concat_data['power'][concat_data['power']>600] = 600\n",
    "concat_data['power'][concat_data['power']<1] = 1\n",
    "\n",
    "concat_data['v_13'][concat_data['v_13']>6] = 6\n",
    "concat_data['v_14'][concat_data['v_14']>4] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 353)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ['v_' +str(i) for i in range(14)]:\n",
    "    for j in ['v_' +str(i) for i in range(14)]:\n",
    "        concat_data[str(i)+'+'+str(j)] = concat_data[str(i)]+concat_data[str(j)]\n",
    "for i in ['model','brand', 'bodyType', 'fuelType','gearbox', 'power', 'kilometer', 'notRepairedDamage', 'regionCode']:\n",
    "    for j in ['v_' +str(i) for i in range(14)]:\n",
    "        concat_data[str(i)+'*'+str(j)] = concat_data[i]*concat_data[j]    \n",
    "concat_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# 对类别较少的特征采用one-hot编码\\none_hot_list = ['fuelType','gearbox','notRepairedDamage','bodyType','creatDate_year',]\\nfor col in one_hot_list:\\n    one_hot = pd.get_dummies(concat_data[col])\\n    one_hot.columns = [col+'_'+str(i) for i in range(len(one_hot.columns))]\\n    concat_data = pd.concat([concat_data,one_hot],axis=1)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#提取日期信息\n",
    "date_cols = ['regDate', 'creatDate']\n",
    "concat_data = date_tran(concat_data,date_cols)\n",
    "\n",
    "'''\n",
    "# 对类别较少的特征采用one-hot编码\n",
    "one_hot_list = ['fuelType','gearbox','notRepairedDamage','bodyType','creatDate_year',]\n",
    "for col in one_hot_list:\n",
    "    one_hot = pd.get_dummies(concat_data[col])\n",
    "    one_hot.columns = [col+'_'+str(i) for i in range(len(one_hot.columns))]\n",
    "    concat_data = pd.concat([concat_data,one_hot],axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = concat_data.copy()\n",
    "\n",
    "#count编码\n",
    "count_list = ['regDate', 'creatDate', 'model', 'brand', 'regionCode','bodyType','fuelType','name','regDate_year', 'regDate_month', 'regDate_day',\n",
    "       'regDate_dayofweek' , 'creatDate_month','creatDate_day', 'creatDate_dayofweek','kilometer']\n",
    "       \n",
    "data = count_coding(data,count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征构造\n",
    "# 使用时间：data['creatDate'] - data['regDate']，反应汽车使用时间，一般来说价格与使用时间成反比\n",
    "# 不过要注意，数据里有时间出错的格式，所以我们需要 errors='coerce'\n",
    "data['used_time1'] = (pd.to_datetime(data['creatDate'], format='%Y%m%d', errors='coerce') - \n",
    "                            pd.to_datetime(data['regDate'], format='%Y%m%d', errors='coerce')).dt.days\n",
    "data['used_time2'] = (pd.datetime.now() - pd.to_datetime(data['regDate'], format='%Y%m%d', errors='coerce')).dt.days                        \n",
    "data['used_time3'] = (pd.datetime.now() - pd.to_datetime(data['creatDate'], format='%Y%m%d', errors='coerce') ).dt.days\n",
    "\n",
    "#分桶操作\n",
    "cut_cols = ['power']+['used_time1','used_time2','used_time3']\n",
    "data = cut_group(data,cut_cols,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:02<00:05,  1.44s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:03<00:03,  1.12s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:03<00:01,  1.03it/s]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.16it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:04<00:00,  1.24it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:04<00:09,  4.89s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:02<00:14,  2.96s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:03<00:06,  1.73s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:03<00:03,  1.32s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:04<00:02,  1.11s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:04<00:00,  1.01it/s]\u001b[A\n",
      "100%|██████████| 6/6 [00:05<00:00,  1.10it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:10<00:05,  5.30s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:03<00:18,  3.64s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:04<00:08,  2.08s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:04<00:04,  1.55s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:05<00:02,  1.29s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:05<00:01,  1.13s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:17<00:00,  5.70s/it]\n"
     ]
    }
   ],
   "source": [
    "### 用数值特征对类别特征做统计刻画，随便挑了几个跟price相关性最高的匿名特征\n",
    "cross_cat = ['model', 'brand','regDate_year']\n",
    "cross_num = ['v_0','v_3', 'v_4', 'v_8', 'v_12','power']\n",
    "data = cross_cat_num(data,cross_num,cross_cat)#一阶交叉\n",
    "#data = cross_qua_cat_num(data)#二阶交叉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 选择特征列\n",
    "numerical_cols = data.columns\n",
    "#print(numerical_cols)\n",
    "\n",
    "cat_fea = ['SaleID','offerType','seller']\n",
    "feature_cols = [col for col in numerical_cols if col not in cat_fea]\n",
    "feature_cols = [col for col in feature_cols if col not in ['price']]\n",
    "\n",
    "## 提前特征列，标签列构造训练样本和测试样本\n",
    "X_data = data.iloc[:len(Train_data),:][feature_cols]\n",
    "Y_data = Train_data['price']\n",
    "X_test  = data.iloc[len(Train_data):,:][feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from itertools import product\n",
    "class MeanEncoder:\n",
    "    def __init__(self, categorical_features, n_splits=10, target_type='classification', prior_weight_func=None):\n",
    "        \"\"\"\n",
    "        :param categorical_features: list of str, the name of the categorical columns to encode\n",
    " \n",
    "        :param n_splits: the number of splits used in mean encoding\n",
    " \n",
    "        :param target_type: str, 'regression' or 'classification'\n",
    " \n",
    "        :param prior_weight_func:\n",
    "        a function that takes in the number of observations, and outputs prior weight\n",
    "        when a dict is passed, the default exponential decay function will be used:\n",
    "        k: the number of observations needed for the posterior to be weighted equally as the prior\n",
    "        f: larger f --> smaller slope\n",
    "        \"\"\"\n",
    " \n",
    "        self.categorical_features = categorical_features\n",
    "        self.n_splits = n_splits\n",
    "        self.learned_stats = {}\n",
    " \n",
    "        if target_type == 'classification':\n",
    "            self.target_type = target_type\n",
    "            self.target_values = []\n",
    "        else:\n",
    "            self.target_type = 'regression'\n",
    "            self.target_values = None\n",
    " \n",
    "        if isinstance(prior_weight_func, dict):\n",
    "            self.prior_weight_func = eval('lambda x: 1 / (1 + np.exp((x - k) / f))', dict(prior_weight_func, np=np))\n",
    "        elif callable(prior_weight_func):\n",
    "            self.prior_weight_func = prior_weight_func\n",
    "        else:\n",
    "            self.prior_weight_func = lambda x: 1 / (1 + np.exp((x - 2) / 1))\n",
    " \n",
    "    @staticmethod\n",
    "    def mean_encode_subroutine(X_train, y_train, X_test, variable, target, prior_weight_func):\n",
    "        X_train = X_train[[variable]].copy()\n",
    "        X_test = X_test[[variable]].copy()\n",
    " \n",
    "        if target is not None:\n",
    "            nf_name = '{}_pred_{}'.format(variable, target)\n",
    "            X_train['pred_temp'] = (y_train == target).astype(int)  # classification\n",
    "        else:\n",
    "            nf_name = '{}_pred'.format(variable)\n",
    "            X_train['pred_temp'] = y_train  # regression\n",
    "        prior = X_train['pred_temp'].mean()\n",
    " \n",
    "        col_avg_y = X_train.groupby(by=variable, axis=0)['pred_temp'].agg({'mean': 'mean', 'beta': 'size'})\n",
    "        col_avg_y['beta'] = prior_weight_func(col_avg_y['beta'])\n",
    "        col_avg_y[nf_name] = col_avg_y['beta'] * prior + (1 - col_avg_y['beta']) * col_avg_y['mean']\n",
    "        col_avg_y.drop(['beta', 'mean'], axis=1, inplace=True)\n",
    " \n",
    "        nf_train = X_train.join(col_avg_y, on=variable)[nf_name].values\n",
    "        nf_test = X_test.join(col_avg_y, on=variable).fillna(prior, inplace=False)[nf_name].values\n",
    " \n",
    "        return nf_train, nf_test, prior, col_avg_y\n",
    " \n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :param y: pandas Series or numpy array, n_samples\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    "        if self.target_type == 'classification':\n",
    "            skf = StratifiedKFold(self.n_splits)\n",
    "        else:\n",
    "            skf = KFold(self.n_splits)\n",
    " \n",
    "        if self.target_type == 'classification':\n",
    "            self.target_values = sorted(set(y))\n",
    "            self.learned_stats = {'{}_pred_{}'.format(variable, target): [] for variable, target in\n",
    "                                  product(self.categorical_features, self.target_values)}\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, target, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        else:\n",
    "            self.learned_stats = {'{}_pred'.format(variable): [] for variable in self.categorical_features}\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new.loc[:, nf_name] = np.nan\n",
    "                for large_ind, small_ind in skf.split(y, y):\n",
    "                    nf_large, nf_small, prior, col_avg_y = MeanEncoder.mean_encode_subroutine(\n",
    "                        X_new.iloc[large_ind], y.iloc[large_ind], X_new.iloc[small_ind], variable, None, self.prior_weight_func)\n",
    "                    X_new.iloc[small_ind, -1] = nf_small\n",
    "                    self.learned_stats[nf_name].append((prior, col_avg_y))\n",
    "        return X_new\n",
    " \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        :param X: pandas DataFrame, n_samples * n_features\n",
    "        :return X_new: the transformed pandas DataFrame containing mean-encoded categorical features\n",
    "        \"\"\"\n",
    "        X_new = X.copy()\n",
    " \n",
    "        if self.target_type == 'classification':\n",
    "            for variable, target in product(self.categorical_features, self.target_values):\n",
    "                nf_name = '{}_pred_{}'.format(variable, target)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    "        else:\n",
    "            for variable in self.categorical_features:\n",
    "                nf_name = '{}_pred'.format(variable)\n",
    "                X_new[nf_name] = 0\n",
    "                for prior, col_avg_y in self.learned_stats[nf_name]:\n",
    "                    X_new[nf_name] += X_new[[variable]].join(col_avg_y, on=variable).fillna(prior, inplace=False)[\n",
    "                        nf_name]\n",
    "                X_new[nf_name] /= self.n_splits\n",
    " \n",
    "        return X_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['model','brand','name','regionCode']+date_cols\n",
    "MeanEnocodeFeature = class_list#声明需要平均数编码的特征\n",
    "ME = MeanEncoder(MeanEnocodeFeature,target_type='regression') #声明平均数编码的类\n",
    "X_data = ME.fit_transform(X_data,Y_data)#对训练数据集的X和y进行拟合\n",
    "#x_train_fav = ME.fit_transform(x_train,y_train_fav)#对训练数据集的X和y进行拟合\n",
    "X_test = ME.transform(X_test)#对测试集进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data['price'] = Train_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:22<00:00,  3.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "### target encoding目标编码，回归场景相对来说做目标编码的选择更多，不仅可以做均值编码，还可以做标准差编码、中位数编码等\n",
    "enc_cols = []\n",
    "stats_default_dict = {\n",
    "    'max': X_data['price'].max(),\n",
    "    'min': X_data['price'].min(),\n",
    "    'median': X_data['price'].median(),\n",
    "    'mean': X_data['price'].mean(),\n",
    "    'sum': X_data['price'].sum(),\n",
    "    'std': X_data['price'].std(),\n",
    "    'skew': X_data['price'].skew(),\n",
    "    'kurt': X_data['price'].kurt(),\n",
    "    'mad': X_data['price'].mad()\n",
    "}\n",
    "### 暂且选择这三种编码\n",
    "enc_stats = ['max','min','mean']\n",
    "skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for f in tqdm(['regionCode','brand','regDate_year','creatDate_year','kilometer','model']):\n",
    "    enc_dict = {}\n",
    "    for stat in enc_stats:\n",
    "        enc_dict['{}_target_{}'.format(f, stat)] = stat\n",
    "        X_data['{}_target_{}'.format(f, stat)] = 0\n",
    "        X_test['{}_target_{}'.format(f, stat)] = 0\n",
    "        enc_cols.append('{}_target_{}'.format(f, stat))\n",
    "    for i, (trn_idx, val_idx) in enumerate(skf.split(X_data, Y_data)):\n",
    "        trn_x, val_x = X_data.iloc[trn_idx].reset_index(drop=True), X_data.iloc[val_idx].reset_index(drop=True)\n",
    "        enc_df = trn_x.groupby(f, as_index=False)['price'].agg(enc_dict)\n",
    "        val_x = val_x[[f]].merge(enc_df, on=f, how='left')\n",
    "        test_x = X_test[[f]].merge(enc_df, on=f, how='left')\n",
    "        for stat in enc_stats:\n",
    "            val_x['{}_target_{}'.format(f, stat)] = val_x['{}_target_{}'.format(f, stat)].fillna(stats_default_dict[stat])\n",
    "            test_x['{}_target_{}'.format(f, stat)] = test_x['{}_target_{}'.format(f, stat)].fillna(stats_default_dict[stat])\n",
    "            X_data.loc[val_idx, '{}_target_{}'.format(f, stat)] = val_x['{}_target_{}'.format(f, stat)].values \n",
    "            X_test['{}_target_{}'.format(f, stat)] += test_x['{}_target_{}'.format(f, stat)].values / skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 454)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "drop_list = ['regDate', 'creatDate','brand_power_min', 'regDate_year_power_min']\n",
    "x_train = X_data.drop(drop_list+['price'],axis=1)\n",
    "x_test = X_test.drop(drop_list,axis=1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#特征归一化\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(pd.concat([x_train,x_test]).values)\n",
    "all_data = min_max_scaler.transform(pd.concat([x_train,x_test]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "pca = decomposition.PCA(n_components=146)\n",
    "all_pca = pca.fit_transform(all_data)\n",
    "X_pca = all_pca[:len(x_train)]\n",
    "test = all_pca[len(x_train):]\n",
    "y = Train_data['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, Activation, MaxPool1D, Flatten, Dense\n",
    "from keras.layers import Input, Dense, Concatenate, Reshape, Dropout, merge, Add\n",
    "def NN_model(input_dim):\n",
    "    init = keras.initializers.glorot_uniform(seed=1)\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dense(units=300, input_dim=input_dim, kernel_initializer=init, activation='softplus'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=300, kernel_initializer=init, activation='softplus'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=64, kernel_initializer=init, activation='softplus'))\n",
    "    model.add(Dense(units=32, kernel_initializer=init, activation='softplus'))\n",
    "    model.add(Dense(units=8, kernel_initializer=init, activation='softplus'))\n",
    "    model.add(Dense(units=1))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, EarlyStopping\n",
    "class Metric(Callback):\n",
    "    def __init__(self, model, callbacks, data):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.callbacks = callbacks\n",
    "        self.data = data\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_begin(logs)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_train_end(logs)\n",
    "\n",
    "    def on_epoch_end(self, batch, logs=None):\n",
    "        X_train, y_train = self.data[0][0], self.data[0][1]\n",
    "        y_pred3 = self.model.predict(X_train)\n",
    "        y_pred = np.zeros((len(y_pred3), ))\n",
    "        y_true = np.zeros((len(y_pred3), ))\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_pred[i] = y_pred3[i]\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_true[i] = y_train[i]\n",
    "        trn_s = mean_absolute_error(y_true, y_pred)\n",
    "        logs['trn_score'] = trn_s\n",
    "        \n",
    "        X_val, y_val = self.data[1][0], self.data[1][1]\n",
    "        y_pred3 = self.model.predict(X_val)\n",
    "        y_pred = np.zeros((len(y_pred3), ))\n",
    "        y_true = np.zeros((len(y_pred3), ))\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_pred[i] = y_pred3[i]\n",
    "        for i in range(len(y_pred3)):\n",
    "            y_true[i] = y_val[i]\n",
    "        val_s = mean_absolute_error(y_true, y_pred)\n",
    "        logs['val_score'] = val_s\n",
    "        print('trn_score', trn_s, 'val_score', val_s)\n",
    "\n",
    "        for callback in self.callbacks:\n",
    "            callback.on_epoch_end(batch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "  \n",
    "def scheduler(epoch):\n",
    "    # 每隔100个epoch，学习率减小为原来的1/10\n",
    "    if epoch % 20 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.6)\n",
    "        print(\"lr changed to {}\".format(lr * 0.6))\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "reduce_lr = LearningRateScheduler(scheduler)\n",
    "#model.fit(train_x, train_y, batch_size=32, epochs=5, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Train on 125000 samples, validate on 25000 samples\n",
      "Epoch 1/145\n",
      " - 4s - loss: 2748.1693 - mean_absolute_error: 2748.1693 - val_loss: 956.0244 - val_mean_absolute_error: 956.0244\n",
      "Epoch 2/145\n",
      " - 3s - loss: 796.8404 - mean_absolute_error: 796.8404 - val_loss: 704.1753 - val_mean_absolute_error: 704.1753\n",
      "Epoch 3/145\n",
      " - 3s - loss: 668.9540 - mean_absolute_error: 668.9540 - val_loss: 617.4219 - val_mean_absolute_error: 617.4219\n",
      "Epoch 4/145\n",
      " - 3s - loss: 621.6312 - mean_absolute_error: 621.6312 - val_loss: 585.2483 - val_mean_absolute_error: 585.2483\n",
      "Epoch 5/145\n",
      " - 3s - loss: 573.7685 - mean_absolute_error: 573.7685 - val_loss: 614.9446 - val_mean_absolute_error: 614.9446\n",
      "Epoch 6/145\n",
      " - 3s - loss: 616.6134 - mean_absolute_error: 616.6134 - val_loss: 553.0452 - val_mean_absolute_error: 553.0452\n",
      "Epoch 7/145\n",
      " - 3s - loss: 540.1156 - mean_absolute_error: 540.1156 - val_loss: 531.8066 - val_mean_absolute_error: 531.8066\n",
      "Epoch 8/145\n",
      " - 3s - loss: 532.4214 - mean_absolute_error: 532.4214 - val_loss: 518.6968 - val_mean_absolute_error: 518.6968\n",
      "Epoch 9/145\n",
      " - 3s - loss: 532.2785 - mean_absolute_error: 532.2785 - val_loss: 520.0359 - val_mean_absolute_error: 520.0359\n",
      "Epoch 10/145\n",
      " - 3s - loss: 539.0498 - mean_absolute_error: 539.0498 - val_loss: 536.4044 - val_mean_absolute_error: 536.4044\n",
      "Epoch 11/145\n",
      " - 3s - loss: 516.2880 - mean_absolute_error: 516.2880 - val_loss: 526.3314 - val_mean_absolute_error: 526.3314\n",
      "Epoch 12/145\n",
      " - 3s - loss: 504.7082 - mean_absolute_error: 504.7082 - val_loss: 514.6281 - val_mean_absolute_error: 514.6281\n",
      "Epoch 13/145\n",
      " - 3s - loss: 511.4145 - mean_absolute_error: 511.4145 - val_loss: 499.4312 - val_mean_absolute_error: 499.4312\n",
      "Epoch 14/145\n",
      " - 3s - loss: 497.1655 - mean_absolute_error: 497.1655 - val_loss: 496.8550 - val_mean_absolute_error: 496.8550\n",
      "Epoch 15/145\n",
      " - 3s - loss: 492.9403 - mean_absolute_error: 492.9403 - val_loss: 509.8174 - val_mean_absolute_error: 509.8174\n",
      "Epoch 16/145\n",
      " - 3s - loss: 524.8291 - mean_absolute_error: 524.8291 - val_loss: 517.1246 - val_mean_absolute_error: 517.1246\n",
      "Epoch 17/145\n",
      " - 3s - loss: 533.4517 - mean_absolute_error: 533.4517 - val_loss: 499.7583 - val_mean_absolute_error: 499.7583\n",
      "Epoch 18/145\n",
      " - 3s - loss: 476.3398 - mean_absolute_error: 476.3398 - val_loss: 484.3632 - val_mean_absolute_error: 484.3632\n",
      "Epoch 19/145\n",
      " - 3s - loss: 482.4722 - mean_absolute_error: 482.4722 - val_loss: 508.2374 - val_mean_absolute_error: 508.2374\n",
      "Epoch 20/145\n",
      " - 3s - loss: 494.8527 - mean_absolute_error: 494.8527 - val_loss: 494.0030 - val_mean_absolute_error: 494.0030\n",
      "Epoch 21/145\n",
      "lr changed to 0.008999999798834323\n",
      " - 3s - loss: 451.5539 - mean_absolute_error: 451.5539 - val_loss: 497.8087 - val_mean_absolute_error: 497.8087\n",
      "Epoch 22/145\n",
      " - 3s - loss: 463.8732 - mean_absolute_error: 463.8732 - val_loss: 494.5838 - val_mean_absolute_error: 494.5838\n",
      "Epoch 23/145\n",
      " - 3s - loss: 453.4724 - mean_absolute_error: 453.4724 - val_loss: 461.9168 - val_mean_absolute_error: 461.9168\n",
      "Epoch 24/145\n",
      " - 3s - loss: 442.9335 - mean_absolute_error: 442.9335 - val_loss: 457.6612 - val_mean_absolute_error: 457.6612\n",
      "Epoch 25/145\n",
      " - 4s - loss: 440.0019 - mean_absolute_error: 440.0019 - val_loss: 467.9085 - val_mean_absolute_error: 467.9085\n",
      "Epoch 26/145\n",
      " - 3s - loss: 438.8551 - mean_absolute_error: 438.8551 - val_loss: 457.0414 - val_mean_absolute_error: 457.0414\n",
      "Epoch 27/145\n",
      " - 3s - loss: 434.2833 - mean_absolute_error: 434.2833 - val_loss: 452.2187 - val_mean_absolute_error: 452.2187\n",
      "Epoch 28/145\n",
      " - 3s - loss: 435.4832 - mean_absolute_error: 435.4832 - val_loss: 454.3953 - val_mean_absolute_error: 454.3953\n",
      "Epoch 29/145\n",
      " - 3s - loss: 440.2532 - mean_absolute_error: 440.2532 - val_loss: 462.5070 - val_mean_absolute_error: 462.5070\n",
      "Epoch 30/145\n",
      " - 3s - loss: 432.5550 - mean_absolute_error: 432.5550 - val_loss: 447.6811 - val_mean_absolute_error: 447.6811\n",
      "Epoch 31/145\n",
      " - 3s - loss: 430.0938 - mean_absolute_error: 430.0938 - val_loss: 455.8700 - val_mean_absolute_error: 455.8700\n",
      "Epoch 32/145\n",
      " - 3s - loss: 434.7380 - mean_absolute_error: 434.7380 - val_loss: 446.8543 - val_mean_absolute_error: 446.8543\n",
      "Epoch 33/145\n",
      " - 3s - loss: 430.8647 - mean_absolute_error: 430.8647 - val_loss: 450.5866 - val_mean_absolute_error: 450.5866\n",
      "Epoch 34/145\n",
      " - 3s - loss: 430.0832 - mean_absolute_error: 430.0832 - val_loss: 453.6982 - val_mean_absolute_error: 453.6982\n",
      "Epoch 35/145\n",
      " - 3s - loss: 427.7168 - mean_absolute_error: 427.7168 - val_loss: 464.4011 - val_mean_absolute_error: 464.4011\n",
      "Epoch 36/145\n",
      " - 3s - loss: 427.3898 - mean_absolute_error: 427.3898 - val_loss: 448.1439 - val_mean_absolute_error: 448.1439\n",
      "Epoch 37/145\n",
      " - 3s - loss: 425.8953 - mean_absolute_error: 425.8953 - val_loss: 450.9302 - val_mean_absolute_error: 450.9302\n",
      "Epoch 38/145\n",
      " - 4s - loss: 426.8399 - mean_absolute_error: 426.8399 - val_loss: 446.0984 - val_mean_absolute_error: 446.0984\n",
      "Epoch 39/145\n",
      " - 3s - loss: 423.6063 - mean_absolute_error: 423.6063 - val_loss: 439.5644 - val_mean_absolute_error: 439.5644\n",
      "Epoch 40/145\n",
      " - 3s - loss: 449.1322 - mean_absolute_error: 449.1322 - val_loss: 479.9493 - val_mean_absolute_error: 479.9493\n",
      "Epoch 41/145\n",
      "lr changed to 0.005399999767541885\n",
      " - 3s - loss: 414.6349 - mean_absolute_error: 414.6349 - val_loss: 442.2357 - val_mean_absolute_error: 442.2357\n",
      "Epoch 42/145\n",
      " - 3s - loss: 408.2271 - mean_absolute_error: 408.2271 - val_loss: 437.6525 - val_mean_absolute_error: 437.6525\n",
      "Epoch 43/145\n",
      " - 3s - loss: 407.8608 - mean_absolute_error: 407.8608 - val_loss: 436.5162 - val_mean_absolute_error: 436.5162\n",
      "Epoch 44/145\n",
      " - 4s - loss: 407.6693 - mean_absolute_error: 407.6693 - val_loss: 441.1997 - val_mean_absolute_error: 441.1997\n",
      "Epoch 45/145\n",
      " - 3s - loss: 406.9661 - mean_absolute_error: 406.9661 - val_loss: 437.2816 - val_mean_absolute_error: 437.2816\n",
      "Epoch 46/145\n",
      " - 3s - loss: 409.0091 - mean_absolute_error: 409.0091 - val_loss: 440.6034 - val_mean_absolute_error: 440.6034\n",
      "Epoch 47/145\n",
      " - 3s - loss: 411.3717 - mean_absolute_error: 411.3717 - val_loss: 459.6611 - val_mean_absolute_error: 459.6611\n",
      "Epoch 48/145\n",
      " - 3s - loss: 407.9768 - mean_absolute_error: 407.9768 - val_loss: 436.1360 - val_mean_absolute_error: 436.1360\n",
      "Epoch 49/145\n",
      " - 3s - loss: 405.4253 - mean_absolute_error: 405.4253 - val_loss: 436.9738 - val_mean_absolute_error: 436.9738\n",
      "Epoch 50/145\n",
      " - 3s - loss: 403.6863 - mean_absolute_error: 403.6863 - val_loss: 435.2020 - val_mean_absolute_error: 435.2020\n",
      "Epoch 51/145\n",
      " - 3s - loss: 402.5707 - mean_absolute_error: 402.5707 - val_loss: 438.2087 - val_mean_absolute_error: 438.2087\n",
      "Epoch 52/145\n",
      " - 3s - loss: 406.5546 - mean_absolute_error: 406.5546 - val_loss: 432.2629 - val_mean_absolute_error: 432.2629\n",
      "Epoch 53/145\n",
      " - 4s - loss: 403.5037 - mean_absolute_error: 403.5037 - val_loss: 442.9102 - val_mean_absolute_error: 442.9102\n",
      "Epoch 54/145\n",
      " - 3s - loss: 401.9585 - mean_absolute_error: 401.9585 - val_loss: 440.7633 - val_mean_absolute_error: 440.7633\n",
      "Epoch 55/145\n",
      " - 3s - loss: 405.0262 - mean_absolute_error: 405.0262 - val_loss: 435.1609 - val_mean_absolute_error: 435.1609\n",
      "Epoch 56/145\n",
      " - 3s - loss: 401.4579 - mean_absolute_error: 401.4579 - val_loss: 430.9711 - val_mean_absolute_error: 430.9711\n",
      "Epoch 57/145\n",
      " - 3s - loss: 399.1268 - mean_absolute_error: 399.1268 - val_loss: 436.8752 - val_mean_absolute_error: 436.8752\n",
      "Epoch 58/145\n",
      " - 4s - loss: 399.1697 - mean_absolute_error: 399.1697 - val_loss: 432.1396 - val_mean_absolute_error: 432.1396\n",
      "Epoch 59/145\n",
      " - 4s - loss: 401.9587 - mean_absolute_error: 401.9587 - val_loss: 449.9922 - val_mean_absolute_error: 449.9922\n",
      "Epoch 60/145\n",
      " - 3s - loss: 402.3453 - mean_absolute_error: 402.3453 - val_loss: 433.5989 - val_mean_absolute_error: 433.5989\n",
      "Epoch 61/145\n",
      "lr changed to 0.0032399998046457766\n",
      " - 3s - loss: 392.0153 - mean_absolute_error: 392.0153 - val_loss: 428.0757 - val_mean_absolute_error: 428.0757\n",
      "Epoch 62/145\n",
      " - 4s - loss: 392.6227 - mean_absolute_error: 392.6227 - val_loss: 427.1349 - val_mean_absolute_error: 427.1349\n",
      "Epoch 63/145\n",
      " - 3s - loss: 392.0800 - mean_absolute_error: 392.0800 - val_loss: 434.4767 - val_mean_absolute_error: 434.4767\n",
      "Epoch 64/145\n",
      " - 4s - loss: 391.2098 - mean_absolute_error: 391.2098 - val_loss: 426.6583 - val_mean_absolute_error: 426.6583\n",
      "Epoch 65/145\n",
      " - 4s - loss: 389.3134 - mean_absolute_error: 389.3134 - val_loss: 427.0196 - val_mean_absolute_error: 427.0196\n",
      "Epoch 66/145\n",
      " - 3s - loss: 389.5852 - mean_absolute_error: 389.5852 - val_loss: 429.3515 - val_mean_absolute_error: 429.3515\n",
      "Epoch 67/145\n",
      " - 3s - loss: 388.5519 - mean_absolute_error: 388.5519 - val_loss: 432.0214 - val_mean_absolute_error: 432.0214\n",
      "Epoch 68/145\n",
      " - 3s - loss: 391.9013 - mean_absolute_error: 391.9013 - val_loss: 430.1923 - val_mean_absolute_error: 430.1923\n",
      "Epoch 69/145\n",
      " - 3s - loss: 394.2205 - mean_absolute_error: 394.2205 - val_loss: 428.0772 - val_mean_absolute_error: 428.0772\n",
      "Epoch 70/145\n",
      " - 3s - loss: 387.1945 - mean_absolute_error: 387.1945 - val_loss: 428.7896 - val_mean_absolute_error: 428.7896\n",
      "Epoch 71/145\n",
      " - 3s - loss: 387.8238 - mean_absolute_error: 387.8238 - val_loss: 429.4888 - val_mean_absolute_error: 429.4888\n",
      "Epoch 72/145\n",
      " - 3s - loss: 391.5715 - mean_absolute_error: 391.5715 - val_loss: 428.1961 - val_mean_absolute_error: 428.1961\n",
      "Epoch 73/145\n",
      " - 3s - loss: 386.4886 - mean_absolute_error: 386.4886 - val_loss: 427.3786 - val_mean_absolute_error: 427.3786\n",
      "Epoch 74/145\n",
      " - 3s - loss: 386.4777 - mean_absolute_error: 386.4777 - val_loss: 426.5031 - val_mean_absolute_error: 426.5031\n",
      "Epoch 75/145\n",
      " - 3s - loss: 385.2616 - mean_absolute_error: 385.2616 - val_loss: 427.0550 - val_mean_absolute_error: 427.0550\n",
      "Epoch 76/145\n",
      " - 3s - loss: 386.4481 - mean_absolute_error: 386.4481 - val_loss: 428.6780 - val_mean_absolute_error: 428.6780\n",
      "Epoch 77/145\n",
      " - 3s - loss: 385.1028 - mean_absolute_error: 385.1028 - val_loss: 430.5656 - val_mean_absolute_error: 430.5656\n",
      "Epoch 78/145\n",
      " - 3s - loss: 385.4447 - mean_absolute_error: 385.4447 - val_loss: 427.0961 - val_mean_absolute_error: 427.0961\n",
      "Epoch 79/145\n",
      " - 3s - loss: 383.8361 - mean_absolute_error: 383.8361 - val_loss: 426.4270 - val_mean_absolute_error: 426.4270\n",
      "Epoch 80/145\n",
      " - 4s - loss: 383.7221 - mean_absolute_error: 383.7221 - val_loss: 426.3980 - val_mean_absolute_error: 426.3980\n",
      "Epoch 81/145\n",
      "lr changed to 0.0019439998548477888\n",
      " - 3s - loss: 380.8181 - mean_absolute_error: 380.8181 - val_loss: 424.2973 - val_mean_absolute_error: 424.2973\n",
      "Epoch 82/145\n",
      " - 3s - loss: 379.2569 - mean_absolute_error: 379.2569 - val_loss: 424.0591 - val_mean_absolute_error: 424.0591\n",
      "Epoch 83/145\n",
      " - 3s - loss: 380.2772 - mean_absolute_error: 380.2772 - val_loss: 424.3190 - val_mean_absolute_error: 424.3190\n",
      "Epoch 84/145\n",
      " - 3s - loss: 379.3058 - mean_absolute_error: 379.3058 - val_loss: 424.2591 - val_mean_absolute_error: 424.2591\n",
      "Epoch 85/145\n",
      " - 3s - loss: 378.9979 - mean_absolute_error: 378.9979 - val_loss: 424.4477 - val_mean_absolute_error: 424.4477\n",
      "Epoch 86/145\n",
      " - 3s - loss: 379.2319 - mean_absolute_error: 379.2319 - val_loss: 423.0972 - val_mean_absolute_error: 423.0972\n",
      "Epoch 87/145\n",
      " - 3s - loss: 378.3973 - mean_absolute_error: 378.3973 - val_loss: 424.2440 - val_mean_absolute_error: 424.2440\n",
      "Epoch 88/145\n",
      " - 3s - loss: 377.9884 - mean_absolute_error: 377.9884 - val_loss: 424.1167 - val_mean_absolute_error: 424.1167\n",
      "Epoch 89/145\n",
      " - 3s - loss: 377.8864 - mean_absolute_error: 377.8864 - val_loss: 424.6001 - val_mean_absolute_error: 424.6001\n",
      "Epoch 90/145\n",
      " - 3s - loss: 377.2235 - mean_absolute_error: 377.2235 - val_loss: 423.6016 - val_mean_absolute_error: 423.6016\n",
      "Epoch 91/145\n",
      " - 3s - loss: 378.1692 - mean_absolute_error: 378.1692 - val_loss: 428.2602 - val_mean_absolute_error: 428.2602\n",
      "Epoch 92/145\n",
      " - 3s - loss: 378.7934 - mean_absolute_error: 378.7934 - val_loss: 425.0152 - val_mean_absolute_error: 425.0152\n",
      "Epoch 93/145\n",
      " - 3s - loss: 378.5615 - mean_absolute_error: 378.5615 - val_loss: 429.9509 - val_mean_absolute_error: 429.9509\n",
      "Epoch 94/145\n",
      " - 3s - loss: 378.2825 - mean_absolute_error: 378.2825 - val_loss: 424.0404 - val_mean_absolute_error: 424.0404\n",
      "Epoch 95/145\n",
      " - 4s - loss: 377.1172 - mean_absolute_error: 377.1172 - val_loss: 430.5370 - val_mean_absolute_error: 430.5370\n",
      "Epoch 96/145\n",
      " - 3s - loss: 377.7160 - mean_absolute_error: 377.7160 - val_loss: 423.0320 - val_mean_absolute_error: 423.0320\n",
      "Epoch 97/145\n",
      " - 3s - loss: 376.7147 - mean_absolute_error: 376.7147 - val_loss: 424.5869 - val_mean_absolute_error: 424.5869\n",
      "Epoch 98/145\n",
      " - 4s - loss: 376.4990 - mean_absolute_error: 376.4990 - val_loss: 423.5136 - val_mean_absolute_error: 423.5136\n",
      "Epoch 99/145\n",
      " - 3s - loss: 376.3235 - mean_absolute_error: 376.3235 - val_loss: 424.3701 - val_mean_absolute_error: 424.3701\n",
      "Epoch 100/145\n",
      " - 3s - loss: 375.6803 - mean_absolute_error: 375.6803 - val_loss: 426.9418 - val_mean_absolute_error: 426.9418\n",
      "Epoch 101/145\n",
      "lr changed to 0.0011663999408483504\n",
      " - 4s - loss: 373.4838 - mean_absolute_error: 373.4838 - val_loss: 425.8253 - val_mean_absolute_error: 425.8253\n",
      "Epoch 102/145\n",
      " - 3s - loss: 372.7999 - mean_absolute_error: 372.7999 - val_loss: 423.0668 - val_mean_absolute_error: 423.0668\n",
      "Epoch 103/145\n",
      " - 3s - loss: 372.7210 - mean_absolute_error: 372.7210 - val_loss: 422.3395 - val_mean_absolute_error: 422.3395\n",
      "Epoch 104/145\n",
      " - 3s - loss: 372.3974 - mean_absolute_error: 372.3974 - val_loss: 422.7966 - val_mean_absolute_error: 422.7966\n",
      "Epoch 105/145\n",
      " - 3s - loss: 371.8822 - mean_absolute_error: 371.8822 - val_loss: 423.3199 - val_mean_absolute_error: 423.3199\n",
      "Epoch 106/145\n",
      " - 3s - loss: 371.8642 - mean_absolute_error: 371.8642 - val_loss: 422.8222 - val_mean_absolute_error: 422.8222\n",
      "Epoch 107/145\n",
      " - 3s - loss: 372.0625 - mean_absolute_error: 372.0625 - val_loss: 422.3729 - val_mean_absolute_error: 422.3729\n",
      "Epoch 108/145\n",
      " - 3s - loss: 371.5742 - mean_absolute_error: 371.5742 - val_loss: 422.7068 - val_mean_absolute_error: 422.7068\n",
      "Epoch 109/145\n",
      " - 3s - loss: 371.6707 - mean_absolute_error: 371.6707 - val_loss: 423.2583 - val_mean_absolute_error: 423.2583\n",
      "Epoch 110/145\n",
      " - 3s - loss: 372.7316 - mean_absolute_error: 372.7316 - val_loss: 423.6830 - val_mean_absolute_error: 423.6830\n",
      "Epoch 111/145\n",
      " - 3s - loss: 371.2962 - mean_absolute_error: 371.2962 - val_loss: 423.5416 - val_mean_absolute_error: 423.5416\n",
      "Epoch 112/145\n",
      " - 3s - loss: 370.9368 - mean_absolute_error: 370.9368 - val_loss: 422.5453 - val_mean_absolute_error: 422.5453\n",
      "Epoch 113/145\n",
      " - 4s - loss: 370.8620 - mean_absolute_error: 370.8620 - val_loss: 422.5442 - val_mean_absolute_error: 422.5442\n",
      "Epoch 114/145\n",
      " - 3s - loss: 370.7631 - mean_absolute_error: 370.7631 - val_loss: 423.6429 - val_mean_absolute_error: 423.6429\n",
      "Epoch 115/145\n",
      " - 3s - loss: 371.0514 - mean_absolute_error: 371.0514 - val_loss: 422.9585 - val_mean_absolute_error: 422.9585\n",
      "Epoch 116/145\n",
      " - 3s - loss: 370.6153 - mean_absolute_error: 370.6153 - val_loss: 422.8809 - val_mean_absolute_error: 422.8809\n",
      "Epoch 117/145\n",
      " - 3s - loss: 370.3822 - mean_absolute_error: 370.3822 - val_loss: 424.9392 - val_mean_absolute_error: 424.9392\n",
      "Epoch 118/145\n",
      " - 3s - loss: 371.1124 - mean_absolute_error: 371.1124 - val_loss: 422.2503 - val_mean_absolute_error: 422.2503\n",
      "Epoch 119/145\n",
      " - 4s - loss: 369.4896 - mean_absolute_error: 369.4896 - val_loss: 422.7133 - val_mean_absolute_error: 422.7133\n",
      "Epoch 120/145\n",
      " - 3s - loss: 369.7309 - mean_absolute_error: 369.7309 - val_loss: 423.5645 - val_mean_absolute_error: 423.5645\n",
      "Epoch 121/145\n",
      "lr changed to 0.0006998399505391716\n",
      " - 3s - loss: 368.3804 - mean_absolute_error: 368.3804 - val_loss: 423.1007 - val_mean_absolute_error: 423.1007\n",
      "Epoch 122/145\n",
      " - 3s - loss: 367.9167 - mean_absolute_error: 367.9167 - val_loss: 422.1381 - val_mean_absolute_error: 422.1381\n",
      "Epoch 123/145\n",
      " - 3s - loss: 367.7529 - mean_absolute_error: 367.7529 - val_loss: 422.0316 - val_mean_absolute_error: 422.0316\n",
      "Epoch 124/145\n",
      " - 3s - loss: 368.1844 - mean_absolute_error: 368.1844 - val_loss: 422.4616 - val_mean_absolute_error: 422.4616\n",
      "Epoch 125/145\n",
      " - 3s - loss: 367.6958 - mean_absolute_error: 367.6958 - val_loss: 421.6564 - val_mean_absolute_error: 421.6564\n",
      "Epoch 126/145\n",
      " - 3s - loss: 367.6133 - mean_absolute_error: 367.6133 - val_loss: 424.0790 - val_mean_absolute_error: 424.0790\n",
      "Epoch 127/145\n",
      " - 3s - loss: 367.5812 - mean_absolute_error: 367.5812 - val_loss: 422.2346 - val_mean_absolute_error: 422.2346\n",
      "Epoch 128/145\n",
      " - 4s - loss: 367.3305 - mean_absolute_error: 367.3305 - val_loss: 422.5075 - val_mean_absolute_error: 422.5075\n",
      "Epoch 129/145\n",
      " - 3s - loss: 367.1162 - mean_absolute_error: 367.1162 - val_loss: 422.2798 - val_mean_absolute_error: 422.2798\n",
      "Epoch 130/145\n",
      " - 3s - loss: 367.1075 - mean_absolute_error: 367.1075 - val_loss: 421.8370 - val_mean_absolute_error: 421.8370\n",
      "Epoch 131/145\n",
      " - 4s - loss: 366.9625 - mean_absolute_error: 366.9625 - val_loss: 421.6026 - val_mean_absolute_error: 421.6026\n",
      "Epoch 132/145\n",
      " - 3s - loss: 366.6670 - mean_absolute_error: 366.6670 - val_loss: 421.8242 - val_mean_absolute_error: 421.8242\n",
      "Epoch 133/145\n",
      " - 3s - loss: 366.7641 - mean_absolute_error: 366.7641 - val_loss: 421.8461 - val_mean_absolute_error: 421.8461\n",
      "Epoch 134/145\n",
      " - 3s - loss: 366.4085 - mean_absolute_error: 366.4085 - val_loss: 421.6601 - val_mean_absolute_error: 421.6601\n",
      "Epoch 135/145\n",
      " - 4s - loss: 366.3919 - mean_absolute_error: 366.3919 - val_loss: 421.9196 - val_mean_absolute_error: 421.9196\n",
      "Epoch 136/145\n",
      " - 3s - loss: 366.2895 - mean_absolute_error: 366.2895 - val_loss: 422.4829 - val_mean_absolute_error: 422.4829\n",
      "Epoch 137/145\n",
      " - 4s - loss: 366.1456 - mean_absolute_error: 366.1456 - val_loss: 422.0804 - val_mean_absolute_error: 422.0804\n",
      "Epoch 138/145\n",
      " - 3s - loss: 366.0919 - mean_absolute_error: 366.0919 - val_loss: 422.4006 - val_mean_absolute_error: 422.4006\n",
      "Epoch 139/145\n",
      " - 3s - loss: 365.8159 - mean_absolute_error: 365.8159 - val_loss: 423.2025 - val_mean_absolute_error: 423.2025\n",
      "Epoch 140/145\n",
      " - 3s - loss: 366.7616 - mean_absolute_error: 366.7616 - val_loss: 422.5833 - val_mean_absolute_error: 422.5833\n",
      "Epoch 141/145\n",
      "lr changed to 0.0004199039773084223\n",
      " - 3s - loss: 365.0058 - mean_absolute_error: 365.0058 - val_loss: 421.7423 - val_mean_absolute_error: 421.7423\n",
      "Epoch 142/145\n",
      " - 3s - loss: 365.1058 - mean_absolute_error: 365.1058 - val_loss: 421.8994 - val_mean_absolute_error: 421.8994\n",
      "Epoch 143/145\n",
      " - 4s - loss: 364.6566 - mean_absolute_error: 364.6566 - val_loss: 421.7258 - val_mean_absolute_error: 421.7258\n",
      "Epoch 144/145\n",
      " - 3s - loss: 364.6792 - mean_absolute_error: 364.6792 - val_loss: 421.6905 - val_mean_absolute_error: 421.6905\n",
      "Epoch 145/145\n",
      " - 3s - loss: 364.5027 - mean_absolute_error: 364.5027 - val_loss: 421.6780 - val_mean_absolute_error: 421.6780\n",
      "\n",
      "val_mae is:421.67805439489365\n",
      "\n",
      "fold: 1\n",
      "Train on 125000 samples, validate on 25000 samples\n",
      "Epoch 1/145\n",
      " - 4s - loss: 2705.9672 - mean_absolute_error: 2705.9672 - val_loss: 926.5255 - val_mean_absolute_error: 926.5255\n",
      "Epoch 2/145\n",
      " - 3s - loss: 830.6994 - mean_absolute_error: 830.6994 - val_loss: 687.4540 - val_mean_absolute_error: 687.4540\n",
      "Epoch 3/145\n",
      " - 3s - loss: 690.4344 - mean_absolute_error: 690.4344 - val_loss: 664.8370 - val_mean_absolute_error: 664.8370\n",
      "Epoch 4/145\n",
      " - 4s - loss: 627.8190 - mean_absolute_error: 627.8190 - val_loss: 602.2423 - val_mean_absolute_error: 602.2423\n",
      "Epoch 5/145\n",
      " - 3s - loss: 617.2987 - mean_absolute_error: 617.2987 - val_loss: 606.0972 - val_mean_absolute_error: 606.0972\n",
      "Epoch 6/145\n",
      " - 3s - loss: 621.4065 - mean_absolute_error: 621.4065 - val_loss: 529.7113 - val_mean_absolute_error: 529.7113\n",
      "Epoch 7/145\n",
      " - 3s - loss: 567.7564 - mean_absolute_error: 567.7564 - val_loss: 503.2997 - val_mean_absolute_error: 503.2997\n",
      "Epoch 8/145\n",
      " - 3s - loss: 528.1028 - mean_absolute_error: 528.1028 - val_loss: 490.8699 - val_mean_absolute_error: 490.8699\n",
      "Epoch 9/145\n",
      " - 3s - loss: 546.0613 - mean_absolute_error: 546.0613 - val_loss: 580.8106 - val_mean_absolute_error: 580.8106\n",
      "Epoch 10/145\n",
      " - 4s - loss: 539.9075 - mean_absolute_error: 539.9075 - val_loss: 474.1504 - val_mean_absolute_error: 474.1504\n",
      "Epoch 11/145\n",
      " - 3s - loss: 512.0326 - mean_absolute_error: 512.0326 - val_loss: 473.2407 - val_mean_absolute_error: 473.2407\n",
      "Epoch 12/145\n",
      " - 3s - loss: 501.9509 - mean_absolute_error: 501.9509 - val_loss: 500.2515 - val_mean_absolute_error: 500.2515\n",
      "Epoch 13/145\n",
      " - 3s - loss: 487.8569 - mean_absolute_error: 487.8569 - val_loss: 488.9133 - val_mean_absolute_error: 488.9133\n",
      "Epoch 14/145\n",
      " - 3s - loss: 486.8921 - mean_absolute_error: 486.8921 - val_loss: 517.5927 - val_mean_absolute_error: 517.5927\n",
      "Epoch 15/145\n",
      " - 3s - loss: 483.1372 - mean_absolute_error: 483.1372 - val_loss: 470.7228 - val_mean_absolute_error: 470.7228\n",
      "Epoch 16/145\n",
      " - 3s - loss: 489.1057 - mean_absolute_error: 489.1057 - val_loss: 468.5709 - val_mean_absolute_error: 468.5709\n",
      "Epoch 17/145\n",
      " - 3s - loss: 477.0542 - mean_absolute_error: 477.0542 - val_loss: 468.3738 - val_mean_absolute_error: 468.3738\n",
      "Epoch 18/145\n",
      " - 3s - loss: 586.9242 - mean_absolute_error: 586.9242 - val_loss: 489.1941 - val_mean_absolute_error: 489.1941\n",
      "Epoch 19/145\n",
      " - 3s - loss: 528.2106 - mean_absolute_error: 528.2106 - val_loss: 471.5319 - val_mean_absolute_error: 471.5319\n",
      "Epoch 20/145\n",
      " - 3s - loss: 517.4783 - mean_absolute_error: 517.4783 - val_loss: 546.4199 - val_mean_absolute_error: 546.4199\n",
      "Epoch 21/145\n",
      "lr changed to 0.008999999798834323\n",
      " - 3s - loss: 465.0119 - mean_absolute_error: 465.0119 - val_loss: 482.2375 - val_mean_absolute_error: 482.2375\n",
      "Epoch 22/145\n",
      " - 3s - loss: 446.9978 - mean_absolute_error: 446.9978 - val_loss: 449.3963 - val_mean_absolute_error: 449.3963\n",
      "Epoch 23/145\n",
      " - 3s - loss: 445.5575 - mean_absolute_error: 445.5575 - val_loss: 443.1164 - val_mean_absolute_error: 443.1164\n",
      "Epoch 24/145\n",
      " - 3s - loss: 444.2741 - mean_absolute_error: 444.2741 - val_loss: 469.1298 - val_mean_absolute_error: 469.1298\n",
      "Epoch 25/145\n",
      " - 3s - loss: 441.0499 - mean_absolute_error: 441.0499 - val_loss: 437.2973 - val_mean_absolute_error: 437.2973\n",
      "Epoch 26/145\n",
      " - 3s - loss: 437.4645 - mean_absolute_error: 437.4645 - val_loss: 433.8399 - val_mean_absolute_error: 433.8399\n",
      "Epoch 27/145\n",
      " - 3s - loss: 437.2237 - mean_absolute_error: 437.2237 - val_loss: 435.7655 - val_mean_absolute_error: 435.7655\n",
      "Epoch 28/145\n",
      " - 3s - loss: 457.5113 - mean_absolute_error: 457.5113 - val_loss: 472.1907 - val_mean_absolute_error: 472.1907\n",
      "Epoch 29/145\n",
      " - 4s - loss: 445.9032 - mean_absolute_error: 445.9032 - val_loss: 440.6803 - val_mean_absolute_error: 440.6803\n",
      "Epoch 30/145\n",
      " - 3s - loss: 433.7770 - mean_absolute_error: 433.7770 - val_loss: 431.9768 - val_mean_absolute_error: 431.9768\n",
      "Epoch 31/145\n",
      " - 3s - loss: 433.4426 - mean_absolute_error: 433.4426 - val_loss: 447.9916 - val_mean_absolute_error: 447.9916\n",
      "Epoch 32/145\n",
      " - 3s - loss: 436.7371 - mean_absolute_error: 436.7371 - val_loss: 430.9893 - val_mean_absolute_error: 430.9893\n",
      "Epoch 33/145\n",
      " - 3s - loss: 434.1745 - mean_absolute_error: 434.1745 - val_loss: 430.6804 - val_mean_absolute_error: 430.6804\n",
      "Epoch 34/145\n",
      " - 3s - loss: 432.8753 - mean_absolute_error: 432.8753 - val_loss: 436.3427 - val_mean_absolute_error: 436.3427\n",
      "Epoch 35/145\n",
      " - 3s - loss: 432.6328 - mean_absolute_error: 432.6328 - val_loss: 434.1942 - val_mean_absolute_error: 434.1942\n",
      "Epoch 36/145\n",
      " - 3s - loss: 441.2542 - mean_absolute_error: 441.2542 - val_loss: 439.1689 - val_mean_absolute_error: 439.1689\n",
      "Epoch 37/145\n",
      " - 3s - loss: 430.1478 - mean_absolute_error: 430.1478 - val_loss: 468.3668 - val_mean_absolute_error: 468.3668\n",
      "Epoch 38/145\n",
      " - 3s - loss: 430.9835 - mean_absolute_error: 430.9835 - val_loss: 426.7682 - val_mean_absolute_error: 426.7682\n",
      "Epoch 39/145\n",
      " - 3s - loss: 431.1722 - mean_absolute_error: 431.1722 - val_loss: 440.2138 - val_mean_absolute_error: 440.2138\n",
      "Epoch 40/145\n",
      " - 3s - loss: 431.5326 - mean_absolute_error: 431.5326 - val_loss: 444.7141 - val_mean_absolute_error: 444.7141\n",
      "Epoch 41/145\n",
      "lr changed to 0.005399999767541885\n",
      " - 3s - loss: 415.7783 - mean_absolute_error: 415.7783 - val_loss: 421.2703 - val_mean_absolute_error: 421.2703\n",
      "Epoch 42/145\n",
      " - 3s - loss: 416.0308 - mean_absolute_error: 416.0308 - val_loss: 420.8909 - val_mean_absolute_error: 420.8909\n",
      "Epoch 43/145\n",
      " - 3s - loss: 413.3298 - mean_absolute_error: 413.3298 - val_loss: 420.7399 - val_mean_absolute_error: 420.7399\n",
      "Epoch 44/145\n",
      " - 3s - loss: 412.2055 - mean_absolute_error: 412.2055 - val_loss: 422.4549 - val_mean_absolute_error: 422.4549\n",
      "Epoch 45/145\n",
      " - 3s - loss: 414.7225 - mean_absolute_error: 414.7225 - val_loss: 431.7981 - val_mean_absolute_error: 431.7981\n",
      "Epoch 46/145\n",
      " - 3s - loss: 413.7998 - mean_absolute_error: 413.7998 - val_loss: 420.4826 - val_mean_absolute_error: 420.4826\n",
      "Epoch 47/145\n",
      " - 3s - loss: 410.6198 - mean_absolute_error: 410.6198 - val_loss: 419.3073 - val_mean_absolute_error: 419.3073\n",
      "Epoch 48/145\n",
      " - 3s - loss: 411.5144 - mean_absolute_error: 411.5144 - val_loss: 420.7287 - val_mean_absolute_error: 420.7287\n",
      "Epoch 49/145\n",
      " - 3s - loss: 412.1897 - mean_absolute_error: 412.1897 - val_loss: 418.9238 - val_mean_absolute_error: 418.9238\n",
      "Epoch 50/145\n",
      " - 3s - loss: 411.1755 - mean_absolute_error: 411.1755 - val_loss: 420.4211 - val_mean_absolute_error: 420.4211\n",
      "Epoch 51/145\n",
      " - 3s - loss: 410.6029 - mean_absolute_error: 410.6029 - val_loss: 423.2770 - val_mean_absolute_error: 423.2770\n",
      "Epoch 52/145\n",
      " - 3s - loss: 415.2065 - mean_absolute_error: 415.2065 - val_loss: 429.8169 - val_mean_absolute_error: 429.8169\n",
      "Epoch 53/145\n",
      " - 3s - loss: 410.3576 - mean_absolute_error: 410.3576 - val_loss: 418.9763 - val_mean_absolute_error: 418.9763\n",
      "Epoch 54/145\n",
      " - 3s - loss: 407.9413 - mean_absolute_error: 407.9413 - val_loss: 416.3797 - val_mean_absolute_error: 416.3797\n",
      "Epoch 55/145\n",
      " - 3s - loss: 405.5840 - mean_absolute_error: 405.5840 - val_loss: 416.9988 - val_mean_absolute_error: 416.9988\n",
      "Epoch 56/145\n",
      " - 3s - loss: 406.8380 - mean_absolute_error: 406.8380 - val_loss: 423.7959 - val_mean_absolute_error: 423.7959\n",
      "Epoch 57/145\n",
      " - 3s - loss: 407.4702 - mean_absolute_error: 407.4702 - val_loss: 422.8804 - val_mean_absolute_error: 422.8804\n",
      "Epoch 58/145\n",
      " - 3s - loss: 404.0961 - mean_absolute_error: 404.0961 - val_loss: 416.9108 - val_mean_absolute_error: 416.9108\n",
      "Epoch 59/145\n",
      " - 3s - loss: 403.2757 - mean_absolute_error: 403.2757 - val_loss: 417.7024 - val_mean_absolute_error: 417.7024\n",
      "Epoch 60/145\n",
      " - 3s - loss: 406.2514 - mean_absolute_error: 406.2514 - val_loss: 417.8393 - val_mean_absolute_error: 417.8393\n",
      "Epoch 61/145\n",
      "lr changed to 0.0032399998046457766\n",
      " - 3s - loss: 397.5320 - mean_absolute_error: 397.5320 - val_loss: 414.9485 - val_mean_absolute_error: 414.9485\n",
      "Epoch 62/145\n",
      " - 3s - loss: 396.5304 - mean_absolute_error: 396.5304 - val_loss: 411.8755 - val_mean_absolute_error: 411.8755\n",
      "Epoch 63/145\n",
      " - 3s - loss: 395.7967 - mean_absolute_error: 395.7967 - val_loss: 415.5522 - val_mean_absolute_error: 415.5522\n",
      "Epoch 64/145\n",
      " - 3s - loss: 394.8534 - mean_absolute_error: 394.8534 - val_loss: 413.2151 - val_mean_absolute_error: 413.2151\n",
      "Epoch 65/145\n",
      " - 3s - loss: 393.5175 - mean_absolute_error: 393.5175 - val_loss: 412.2511 - val_mean_absolute_error: 412.2511\n",
      "Epoch 66/145\n",
      " - 3s - loss: 393.8542 - mean_absolute_error: 393.8542 - val_loss: 412.2382 - val_mean_absolute_error: 412.2382\n",
      "Epoch 67/145\n",
      " - 3s - loss: 393.2587 - mean_absolute_error: 393.2587 - val_loss: 411.6170 - val_mean_absolute_error: 411.6170\n",
      "Epoch 68/145\n",
      " - 3s - loss: 393.5438 - mean_absolute_error: 393.5438 - val_loss: 411.6520 - val_mean_absolute_error: 411.6520\n",
      "Epoch 69/145\n",
      " - 3s - loss: 392.0244 - mean_absolute_error: 392.0244 - val_loss: 412.1226 - val_mean_absolute_error: 412.1226\n",
      "Epoch 70/145\n",
      " - 3s - loss: 391.9655 - mean_absolute_error: 391.9655 - val_loss: 419.7491 - val_mean_absolute_error: 419.7491\n",
      "Epoch 71/145\n",
      " - 3s - loss: 394.0325 - mean_absolute_error: 394.0325 - val_loss: 415.6211 - val_mean_absolute_error: 415.6211\n",
      "Epoch 72/145\n",
      " - 3s - loss: 395.1378 - mean_absolute_error: 395.1378 - val_loss: 413.4513 - val_mean_absolute_error: 413.4513\n",
      "Epoch 73/145\n",
      " - 3s - loss: 391.1449 - mean_absolute_error: 391.1449 - val_loss: 410.7764 - val_mean_absolute_error: 410.7764\n",
      "Epoch 74/145\n",
      " - 3s - loss: 394.6237 - mean_absolute_error: 394.6237 - val_loss: 411.7830 - val_mean_absolute_error: 411.7830\n",
      "Epoch 75/145\n",
      " - 3s - loss: 395.6225 - mean_absolute_error: 395.6225 - val_loss: 415.8522 - val_mean_absolute_error: 415.8522\n",
      "Epoch 76/145\n",
      " - 3s - loss: 392.2197 - mean_absolute_error: 392.2197 - val_loss: 409.4994 - val_mean_absolute_error: 409.4994\n",
      "Epoch 77/145\n",
      " - 3s - loss: 388.5642 - mean_absolute_error: 388.5642 - val_loss: 414.0465 - val_mean_absolute_error: 414.0465\n",
      "Epoch 78/145\n",
      " - 3s - loss: 389.4575 - mean_absolute_error: 389.4575 - val_loss: 412.7041 - val_mean_absolute_error: 412.7041\n",
      "Epoch 79/145\n",
      " - 3s - loss: 387.8275 - mean_absolute_error: 387.8275 - val_loss: 410.8790 - val_mean_absolute_error: 410.8790\n",
      "Epoch 80/145\n",
      " - 3s - loss: 390.5310 - mean_absolute_error: 390.5310 - val_loss: 409.5739 - val_mean_absolute_error: 409.5739\n",
      "Epoch 81/145\n",
      "lr changed to 0.0019439998548477888\n",
      " - 3s - loss: 383.1711 - mean_absolute_error: 383.1711 - val_loss: 410.0859 - val_mean_absolute_error: 410.0859\n",
      "Epoch 82/145\n",
      " - 3s - loss: 383.2286 - mean_absolute_error: 383.2286 - val_loss: 412.4559 - val_mean_absolute_error: 412.4559\n",
      "Epoch 83/145\n",
      " - 3s - loss: 382.8300 - mean_absolute_error: 382.8300 - val_loss: 409.9374 - val_mean_absolute_error: 409.9374\n",
      "Epoch 84/145\n",
      " - 3s - loss: 382.7338 - mean_absolute_error: 382.7338 - val_loss: 412.3992 - val_mean_absolute_error: 412.3992\n",
      "Epoch 85/145\n",
      " - 3s - loss: 382.8946 - mean_absolute_error: 382.8946 - val_loss: 411.5841 - val_mean_absolute_error: 411.5841\n",
      "Epoch 86/145\n",
      " - 3s - loss: 382.3460 - mean_absolute_error: 382.3460 - val_loss: 410.4507 - val_mean_absolute_error: 410.4507\n",
      "Epoch 87/145\n",
      " - 3s - loss: 381.5163 - mean_absolute_error: 381.5163 - val_loss: 409.0509 - val_mean_absolute_error: 409.0509\n",
      "Epoch 88/145\n",
      " - 3s - loss: 381.9363 - mean_absolute_error: 381.9363 - val_loss: 409.6430 - val_mean_absolute_error: 409.6430\n",
      "Epoch 89/145\n",
      " - 3s - loss: 380.8822 - mean_absolute_error: 380.8822 - val_loss: 412.2590 - val_mean_absolute_error: 412.2590\n",
      "Epoch 90/145\n",
      " - 3s - loss: 382.7255 - mean_absolute_error: 382.7255 - val_loss: 414.2122 - val_mean_absolute_error: 414.2122\n",
      "Epoch 91/145\n",
      " - 3s - loss: 381.2124 - mean_absolute_error: 381.2124 - val_loss: 408.8201 - val_mean_absolute_error: 408.8201\n",
      "Epoch 92/145\n",
      " - 3s - loss: 380.5686 - mean_absolute_error: 380.5686 - val_loss: 411.7479 - val_mean_absolute_error: 411.7479\n",
      "Epoch 93/145\n",
      " - 3s - loss: 381.4586 - mean_absolute_error: 381.4586 - val_loss: 413.6819 - val_mean_absolute_error: 413.6819\n",
      "Epoch 94/145\n",
      " - 3s - loss: 382.3894 - mean_absolute_error: 382.3894 - val_loss: 409.8782 - val_mean_absolute_error: 409.8782\n",
      "Epoch 95/145\n",
      " - 3s - loss: 380.5602 - mean_absolute_error: 380.5602 - val_loss: 411.5317 - val_mean_absolute_error: 411.5317\n",
      "Epoch 96/145\n",
      " - 3s - loss: 379.9251 - mean_absolute_error: 379.9251 - val_loss: 409.4872 - val_mean_absolute_error: 409.4872\n",
      "Epoch 97/145\n",
      " - 3s - loss: 380.4181 - mean_absolute_error: 380.4181 - val_loss: 410.4799 - val_mean_absolute_error: 410.4799\n",
      "Epoch 98/145\n",
      " - 3s - loss: 378.2902 - mean_absolute_error: 378.2902 - val_loss: 410.6078 - val_mean_absolute_error: 410.6078\n",
      "Epoch 99/145\n",
      " - 3s - loss: 378.0899 - mean_absolute_error: 378.0899 - val_loss: 409.1091 - val_mean_absolute_error: 409.1091\n",
      "Epoch 100/145\n",
      " - 3s - loss: 378.7621 - mean_absolute_error: 378.7621 - val_loss: 409.7557 - val_mean_absolute_error: 409.7557\n",
      "Epoch 101/145\n",
      "lr changed to 0.0011663999408483504\n",
      " - 3s - loss: 375.2755 - mean_absolute_error: 375.2755 - val_loss: 410.4001 - val_mean_absolute_error: 410.4001\n",
      "Epoch 102/145\n",
      " - 3s - loss: 375.1490 - mean_absolute_error: 375.1490 - val_loss: 409.6123 - val_mean_absolute_error: 409.6123\n",
      "Epoch 103/145\n",
      " - 3s - loss: 374.7911 - mean_absolute_error: 374.7911 - val_loss: 408.4864 - val_mean_absolute_error: 408.4864\n",
      "Epoch 104/145\n",
      " - 3s - loss: 374.2129 - mean_absolute_error: 374.2129 - val_loss: 408.6777 - val_mean_absolute_error: 408.6777\n",
      "Epoch 105/145\n",
      " - 3s - loss: 374.3812 - mean_absolute_error: 374.3812 - val_loss: 408.6880 - val_mean_absolute_error: 408.6880\n",
      "Epoch 106/145\n",
      " - 3s - loss: 374.1408 - mean_absolute_error: 374.1408 - val_loss: 408.4353 - val_mean_absolute_error: 408.4353\n",
      "Epoch 107/145\n",
      " - 3s - loss: 374.2304 - mean_absolute_error: 374.2304 - val_loss: 409.6215 - val_mean_absolute_error: 409.6215\n",
      "Epoch 108/145\n",
      " - 3s - loss: 373.6746 - mean_absolute_error: 373.6746 - val_loss: 411.1746 - val_mean_absolute_error: 411.1746\n",
      "Epoch 109/145\n",
      " - 3s - loss: 374.1608 - mean_absolute_error: 374.1608 - val_loss: 409.8461 - val_mean_absolute_error: 409.8461\n",
      "Epoch 110/145\n",
      " - 3s - loss: 374.4550 - mean_absolute_error: 374.4550 - val_loss: 410.8286 - val_mean_absolute_error: 410.8286\n",
      "Epoch 111/145\n",
      " - 3s - loss: 374.5967 - mean_absolute_error: 374.5967 - val_loss: 410.4911 - val_mean_absolute_error: 410.4911\n",
      "Epoch 112/145\n",
      " - 3s - loss: 372.8662 - mean_absolute_error: 372.8662 - val_loss: 412.1574 - val_mean_absolute_error: 412.1574\n",
      "Epoch 113/145\n",
      " - 3s - loss: 373.3809 - mean_absolute_error: 373.3809 - val_loss: 409.6053 - val_mean_absolute_error: 409.6053\n",
      "Epoch 114/145\n",
      " - 3s - loss: 372.9929 - mean_absolute_error: 372.9929 - val_loss: 409.7775 - val_mean_absolute_error: 409.7775\n",
      "Epoch 115/145\n",
      " - 3s - loss: 373.1833 - mean_absolute_error: 373.1833 - val_loss: 409.8846 - val_mean_absolute_error: 409.8846\n",
      "Epoch 116/145\n",
      " - 3s - loss: 372.7893 - mean_absolute_error: 372.7893 - val_loss: 410.9763 - val_mean_absolute_error: 410.9763\n",
      "Epoch 117/145\n",
      " - 3s - loss: 371.9505 - mean_absolute_error: 371.9505 - val_loss: 409.2961 - val_mean_absolute_error: 409.2961\n",
      "Epoch 118/145\n",
      " - 3s - loss: 372.5275 - mean_absolute_error: 372.5275 - val_loss: 409.8206 - val_mean_absolute_error: 409.8206\n",
      "Epoch 119/145\n",
      " - 3s - loss: 371.6501 - mean_absolute_error: 371.6501 - val_loss: 409.4578 - val_mean_absolute_error: 409.4578\n",
      "Epoch 120/145\n",
      " - 3s - loss: 371.5123 - mean_absolute_error: 371.5123 - val_loss: 409.2354 - val_mean_absolute_error: 409.2354\n",
      "Epoch 121/145\n",
      "lr changed to 0.0006998399505391716\n",
      " - 3s - loss: 370.6039 - mean_absolute_error: 370.6039 - val_loss: 408.6696 - val_mean_absolute_error: 408.6696\n",
      "Epoch 122/145\n",
      " - 3s - loss: 370.2876 - mean_absolute_error: 370.2876 - val_loss: 409.2513 - val_mean_absolute_error: 409.2513\n",
      "Epoch 123/145\n",
      " - 3s - loss: 370.4530 - mean_absolute_error: 370.4530 - val_loss: 408.9385 - val_mean_absolute_error: 408.9385\n",
      "Epoch 124/145\n",
      " - 3s - loss: 370.0345 - mean_absolute_error: 370.0345 - val_loss: 408.5886 - val_mean_absolute_error: 408.5886\n",
      "Epoch 125/145\n",
      " - 3s - loss: 369.6548 - mean_absolute_error: 369.6548 - val_loss: 409.5108 - val_mean_absolute_error: 409.5108\n",
      "Epoch 126/145\n",
      " - 3s - loss: 369.2154 - mean_absolute_error: 369.2154 - val_loss: 410.1371 - val_mean_absolute_error: 410.1371\n",
      "Epoch 127/145\n",
      " - 3s - loss: 369.5195 - mean_absolute_error: 369.5195 - val_loss: 410.4931 - val_mean_absolute_error: 410.4931\n",
      "Epoch 128/145\n",
      " - 3s - loss: 369.1936 - mean_absolute_error: 369.1936 - val_loss: 409.7710 - val_mean_absolute_error: 409.7710\n",
      "Epoch 129/145\n",
      " - 3s - loss: 368.9494 - mean_absolute_error: 368.9494 - val_loss: 408.9431 - val_mean_absolute_error: 408.9431\n",
      "Epoch 130/145\n",
      " - 3s - loss: 368.6863 - mean_absolute_error: 368.6863 - val_loss: 410.1253 - val_mean_absolute_error: 410.1253\n",
      "Epoch 131/145\n",
      " - 3s - loss: 369.1720 - mean_absolute_error: 369.1720 - val_loss: 409.4135 - val_mean_absolute_error: 409.4135\n",
      "Epoch 132/145\n",
      " - 3s - loss: 369.3485 - mean_absolute_error: 369.3485 - val_loss: 408.9967 - val_mean_absolute_error: 408.9967\n",
      "Epoch 133/145\n",
      " - 3s - loss: 368.7114 - mean_absolute_error: 368.7114 - val_loss: 409.1895 - val_mean_absolute_error: 409.1895\n",
      "Epoch 134/145\n",
      " - 3s - loss: 368.5249 - mean_absolute_error: 368.5249 - val_loss: 409.1075 - val_mean_absolute_error: 409.1075\n",
      "Epoch 135/145\n",
      " - 3s - loss: 367.9751 - mean_absolute_error: 367.9751 - val_loss: 411.2287 - val_mean_absolute_error: 411.2287\n",
      "Epoch 136/145\n",
      " - 3s - loss: 368.7947 - mean_absolute_error: 368.7947 - val_loss: 409.5523 - val_mean_absolute_error: 409.5523\n",
      "Epoch 137/145\n",
      " - 3s - loss: 368.0605 - mean_absolute_error: 368.0605 - val_loss: 409.6032 - val_mean_absolute_error: 409.6032\n",
      "Epoch 138/145\n",
      " - 3s - loss: 367.5478 - mean_absolute_error: 367.5478 - val_loss: 410.7631 - val_mean_absolute_error: 410.7631\n",
      "Epoch 139/145\n",
      " - 3s - loss: 367.4800 - mean_absolute_error: 367.4800 - val_loss: 409.3484 - val_mean_absolute_error: 409.3484\n",
      "Epoch 140/145\n",
      " - 3s - loss: 367.8939 - mean_absolute_error: 367.8939 - val_loss: 408.9430 - val_mean_absolute_error: 408.9430\n",
      "Epoch 141/145\n",
      "lr changed to 0.0004199039773084223\n",
      " - 3s - loss: 366.7833 - mean_absolute_error: 366.7833 - val_loss: 409.1747 - val_mean_absolute_error: 409.1747\n",
      "Epoch 142/145\n",
      " - 3s - loss: 366.4581 - mean_absolute_error: 366.4581 - val_loss: 409.0032 - val_mean_absolute_error: 409.0032\n",
      "Epoch 143/145\n",
      " - 3s - loss: 366.2562 - mean_absolute_error: 366.2562 - val_loss: 409.7847 - val_mean_absolute_error: 409.7847\n",
      "Epoch 144/145\n",
      " - 3s - loss: 366.5935 - mean_absolute_error: 366.5935 - val_loss: 409.8546 - val_mean_absolute_error: 409.8546\n",
      "Epoch 145/145\n",
      " - 3s - loss: 366.2689 - mean_absolute_error: 366.2689 - val_loss: 409.3120 - val_mean_absolute_error: 409.3120\n",
      "\n",
      "val_mae is:409.3120157018423\n",
      "\n",
      "fold: 2\n",
      "Train on 125000 samples, validate on 25000 samples\n",
      "Epoch 1/145\n",
      " - 4s - loss: 2649.3814 - mean_absolute_error: 2649.3814 - val_loss: 959.9590 - val_mean_absolute_error: 959.9590\n",
      "Epoch 2/145\n",
      " - 3s - loss: 804.1815 - mean_absolute_error: 804.1815 - val_loss: 737.4140 - val_mean_absolute_error: 737.4140\n",
      "Epoch 3/145\n",
      " - 3s - loss: 667.8079 - mean_absolute_error: 667.8079 - val_loss: 620.3537 - val_mean_absolute_error: 620.3537\n",
      "Epoch 4/145\n",
      " - 3s - loss: 620.1479 - mean_absolute_error: 620.1479 - val_loss: 569.2262 - val_mean_absolute_error: 569.2262\n",
      "Epoch 5/145\n",
      " - 3s - loss: 617.2278 - mean_absolute_error: 617.2278 - val_loss: 732.8087 - val_mean_absolute_error: 732.8087\n",
      "Epoch 6/145\n",
      " - 3s - loss: 600.7398 - mean_absolute_error: 600.7398 - val_loss: 564.3689 - val_mean_absolute_error: 564.3689\n",
      "Epoch 7/145\n",
      " - 3s - loss: 556.4140 - mean_absolute_error: 556.4140 - val_loss: 539.9237 - val_mean_absolute_error: 539.9237\n",
      "Epoch 8/145\n",
      " - 3s - loss: 525.6098 - mean_absolute_error: 525.6098 - val_loss: 530.6009 - val_mean_absolute_error: 530.6009\n",
      "Epoch 9/145\n",
      " - 3s - loss: 546.4774 - mean_absolute_error: 546.4774 - val_loss: 555.6465 - val_mean_absolute_error: 555.6465\n",
      "Epoch 10/145\n",
      " - 3s - loss: 517.9537 - mean_absolute_error: 517.9537 - val_loss: 497.5254 - val_mean_absolute_error: 497.5254\n",
      "Epoch 11/145\n",
      " - 3s - loss: 502.7166 - mean_absolute_error: 502.7166 - val_loss: 489.2901 - val_mean_absolute_error: 489.2901\n",
      "Epoch 12/145\n",
      " - 3s - loss: 491.7326 - mean_absolute_error: 491.7326 - val_loss: 495.8360 - val_mean_absolute_error: 495.8360\n",
      "Epoch 13/145\n",
      " - 3s - loss: 525.9197 - mean_absolute_error: 525.9197 - val_loss: 504.6981 - val_mean_absolute_error: 504.6981\n",
      "Epoch 14/145\n",
      " - 3s - loss: 518.5457 - mean_absolute_error: 518.5457 - val_loss: 507.9386 - val_mean_absolute_error: 507.9386\n",
      "Epoch 15/145\n",
      " - 3s - loss: 489.6919 - mean_absolute_error: 489.6919 - val_loss: 510.2008 - val_mean_absolute_error: 510.2008\n",
      "Epoch 16/145\n",
      " - 4s - loss: 512.8417 - mean_absolute_error: 512.8417 - val_loss: 485.3627 - val_mean_absolute_error: 485.3627\n",
      "Epoch 17/145\n",
      " - 3s - loss: 501.0112 - mean_absolute_error: 501.0112 - val_loss: 486.2894 - val_mean_absolute_error: 486.2894\n",
      "Epoch 18/145\n",
      " - 3s - loss: 496.3494 - mean_absolute_error: 496.3494 - val_loss: 512.2813 - val_mean_absolute_error: 512.2813\n",
      "Epoch 19/145\n",
      " - 3s - loss: 469.2769 - mean_absolute_error: 469.2769 - val_loss: 492.5126 - val_mean_absolute_error: 492.5126\n",
      "Epoch 20/145\n",
      " - 3s - loss: 499.2410 - mean_absolute_error: 499.2410 - val_loss: 475.4115 - val_mean_absolute_error: 475.4115\n",
      "Epoch 21/145\n",
      "lr changed to 0.008999999798834323\n",
      " - 3s - loss: 445.5669 - mean_absolute_error: 445.5669 - val_loss: 457.7339 - val_mean_absolute_error: 457.7339\n",
      "Epoch 22/145\n",
      " - 3s - loss: 441.4288 - mean_absolute_error: 441.4288 - val_loss: 454.6303 - val_mean_absolute_error: 454.6303\n",
      "Epoch 23/145\n",
      " - 3s - loss: 438.5893 - mean_absolute_error: 438.5893 - val_loss: 453.0795 - val_mean_absolute_error: 453.0795\n",
      "Epoch 24/145\n",
      " - 3s - loss: 442.8376 - mean_absolute_error: 442.8376 - val_loss: 457.8124 - val_mean_absolute_error: 457.8124\n",
      "Epoch 25/145\n",
      " - 3s - loss: 435.3120 - mean_absolute_error: 435.3120 - val_loss: 456.5789 - val_mean_absolute_error: 456.5789\n",
      "Epoch 26/145\n",
      " - 3s - loss: 437.4865 - mean_absolute_error: 437.4865 - val_loss: 458.2942 - val_mean_absolute_error: 458.2942\n",
      "Epoch 27/145\n",
      " - 3s - loss: 472.1518 - mean_absolute_error: 472.1518 - val_loss: 464.2416 - val_mean_absolute_error: 464.2416\n",
      "Epoch 28/145\n",
      " - 3s - loss: 435.9097 - mean_absolute_error: 435.9097 - val_loss: 447.2634 - val_mean_absolute_error: 447.2634\n",
      "Epoch 29/145\n",
      " - 3s - loss: 435.4170 - mean_absolute_error: 435.4170 - val_loss: 444.6591 - val_mean_absolute_error: 444.6591\n",
      "Epoch 30/145\n",
      " - 3s - loss: 429.5206 - mean_absolute_error: 429.5206 - val_loss: 449.6139 - val_mean_absolute_error: 449.6139\n",
      "Epoch 31/145\n",
      " - 3s - loss: 430.0114 - mean_absolute_error: 430.0114 - val_loss: 455.8127 - val_mean_absolute_error: 455.8127\n",
      "Epoch 32/145\n",
      " - 3s - loss: 453.5808 - mean_absolute_error: 453.5808 - val_loss: 454.9962 - val_mean_absolute_error: 454.9962\n",
      "Epoch 33/145\n",
      " - 3s - loss: 427.2047 - mean_absolute_error: 427.2047 - val_loss: 445.9571 - val_mean_absolute_error: 445.9571\n",
      "Epoch 34/145\n",
      " - 3s - loss: 432.8056 - mean_absolute_error: 432.8056 - val_loss: 465.2485 - val_mean_absolute_error: 465.2485\n",
      "Epoch 35/145\n",
      " - 3s - loss: 429.4851 - mean_absolute_error: 429.4851 - val_loss: 455.6315 - val_mean_absolute_error: 455.6315\n",
      "Epoch 36/145\n",
      " - 3s - loss: 434.5124 - mean_absolute_error: 434.5124 - val_loss: 451.9573 - val_mean_absolute_error: 451.9573\n",
      "Epoch 37/145\n",
      " - 3s - loss: 424.0192 - mean_absolute_error: 424.0192 - val_loss: 442.5820 - val_mean_absolute_error: 442.5820\n",
      "Epoch 38/145\n",
      " - 3s - loss: 426.6633 - mean_absolute_error: 426.6633 - val_loss: 446.7406 - val_mean_absolute_error: 446.7406\n",
      "Epoch 39/145\n",
      " - 3s - loss: 427.9207 - mean_absolute_error: 427.9207 - val_loss: 475.3911 - val_mean_absolute_error: 475.3911\n",
      "Epoch 40/145\n",
      " - 3s - loss: 425.9399 - mean_absolute_error: 425.9399 - val_loss: 445.5447 - val_mean_absolute_error: 445.5447\n",
      "Epoch 41/145\n",
      "lr changed to 0.005399999767541885\n",
      " - 3s - loss: 412.4719 - mean_absolute_error: 412.4719 - val_loss: 448.3531 - val_mean_absolute_error: 448.3531\n",
      "Epoch 42/145\n",
      " - 3s - loss: 413.7059 - mean_absolute_error: 413.7059 - val_loss: 434.0313 - val_mean_absolute_error: 434.0313\n",
      "Epoch 43/145\n",
      " - 3s - loss: 426.4836 - mean_absolute_error: 426.4836 - val_loss: 446.8693 - val_mean_absolute_error: 446.8693\n",
      "Epoch 44/145\n",
      " - 3s - loss: 411.7960 - mean_absolute_error: 411.7960 - val_loss: 444.1357 - val_mean_absolute_error: 444.1357\n",
      "Epoch 45/145\n",
      " - 3s - loss: 409.4203 - mean_absolute_error: 409.4203 - val_loss: 436.6577 - val_mean_absolute_error: 436.6577\n",
      "Epoch 46/145\n",
      " - 3s - loss: 406.7159 - mean_absolute_error: 406.7159 - val_loss: 444.0421 - val_mean_absolute_error: 444.0421\n",
      "Epoch 47/145\n",
      " - 3s - loss: 405.2304 - mean_absolute_error: 405.2304 - val_loss: 432.3467 - val_mean_absolute_error: 432.3467\n",
      "Epoch 48/145\n",
      " - 3s - loss: 417.7387 - mean_absolute_error: 417.7387 - val_loss: 432.7526 - val_mean_absolute_error: 432.7526\n",
      "Epoch 49/145\n",
      " - 3s - loss: 404.6418 - mean_absolute_error: 404.6418 - val_loss: 434.7404 - val_mean_absolute_error: 434.7404\n",
      "Epoch 50/145\n",
      " - 3s - loss: 404.0952 - mean_absolute_error: 404.0952 - val_loss: 431.5748 - val_mean_absolute_error: 431.5748\n",
      "Epoch 51/145\n",
      " - 3s - loss: 403.8282 - mean_absolute_error: 403.8282 - val_loss: 432.0703 - val_mean_absolute_error: 432.0703\n",
      "Epoch 52/145\n",
      " - 3s - loss: 404.7237 - mean_absolute_error: 404.7237 - val_loss: 434.3059 - val_mean_absolute_error: 434.3059\n",
      "Epoch 53/145\n",
      " - 3s - loss: 401.3312 - mean_absolute_error: 401.3312 - val_loss: 431.8621 - val_mean_absolute_error: 431.8621\n",
      "Epoch 54/145\n",
      " - 3s - loss: 401.5885 - mean_absolute_error: 401.5885 - val_loss: 433.5273 - val_mean_absolute_error: 433.5273\n",
      "Epoch 55/145\n",
      " - 3s - loss: 406.5684 - mean_absolute_error: 406.5684 - val_loss: 439.9093 - val_mean_absolute_error: 439.9093\n",
      "Epoch 56/145\n",
      " - 3s - loss: 401.1243 - mean_absolute_error: 401.1243 - val_loss: 433.0450 - val_mean_absolute_error: 433.0450\n",
      "Epoch 57/145\n",
      " - 3s - loss: 400.4356 - mean_absolute_error: 400.4356 - val_loss: 431.0214 - val_mean_absolute_error: 431.0214\n",
      "Epoch 58/145\n",
      " - 3s - loss: 400.6057 - mean_absolute_error: 400.6057 - val_loss: 440.4826 - val_mean_absolute_error: 440.4826\n",
      "Epoch 59/145\n",
      " - 3s - loss: 398.3039 - mean_absolute_error: 398.3039 - val_loss: 447.4162 - val_mean_absolute_error: 447.4162\n",
      "Epoch 60/145\n",
      " - 3s - loss: 400.9616 - mean_absolute_error: 400.9616 - val_loss: 434.5234 - val_mean_absolute_error: 434.5234\n",
      "Epoch 61/145\n",
      "lr changed to 0.0032399998046457766\n",
      " - 3s - loss: 394.0671 - mean_absolute_error: 394.0671 - val_loss: 427.3654 - val_mean_absolute_error: 427.3654\n",
      "Epoch 62/145\n",
      " - 3s - loss: 391.8878 - mean_absolute_error: 391.8878 - val_loss: 429.7528 - val_mean_absolute_error: 429.7528\n",
      "Epoch 63/145\n",
      " - 3s - loss: 389.7711 - mean_absolute_error: 389.7711 - val_loss: 427.6516 - val_mean_absolute_error: 427.6516\n",
      "Epoch 64/145\n",
      " - 3s - loss: 389.1834 - mean_absolute_error: 389.1834 - val_loss: 427.5414 - val_mean_absolute_error: 427.5414\n",
      "Epoch 65/145\n",
      " - 3s - loss: 388.9430 - mean_absolute_error: 388.9430 - val_loss: 426.1114 - val_mean_absolute_error: 426.1114\n",
      "Epoch 66/145\n",
      " - 3s - loss: 388.5647 - mean_absolute_error: 388.5647 - val_loss: 426.2456 - val_mean_absolute_error: 426.2456\n",
      "Epoch 67/145\n",
      " - 3s - loss: 388.2612 - mean_absolute_error: 388.2612 - val_loss: 426.1602 - val_mean_absolute_error: 426.1602\n",
      "Epoch 68/145\n",
      " - 3s - loss: 386.8636 - mean_absolute_error: 386.8636 - val_loss: 426.0102 - val_mean_absolute_error: 426.0102\n",
      "Epoch 69/145\n",
      " - 3s - loss: 387.4141 - mean_absolute_error: 387.4141 - val_loss: 425.4936 - val_mean_absolute_error: 425.4936\n",
      "Epoch 70/145\n",
      " - 3s - loss: 389.2491 - mean_absolute_error: 389.2491 - val_loss: 429.2742 - val_mean_absolute_error: 429.2742\n",
      "Epoch 71/145\n",
      " - 3s - loss: 389.2296 - mean_absolute_error: 389.2296 - val_loss: 425.1323 - val_mean_absolute_error: 425.1323\n",
      "Epoch 72/145\n",
      " - 3s - loss: 387.9997 - mean_absolute_error: 387.9997 - val_loss: 431.0845 - val_mean_absolute_error: 431.0845\n",
      "Epoch 73/145\n",
      " - 3s - loss: 387.9059 - mean_absolute_error: 387.9059 - val_loss: 427.0289 - val_mean_absolute_error: 427.0289\n",
      "Epoch 74/145\n",
      " - 3s - loss: 386.3257 - mean_absolute_error: 386.3257 - val_loss: 429.8110 - val_mean_absolute_error: 429.8110\n",
      "Epoch 75/145\n",
      " - 3s - loss: 386.6984 - mean_absolute_error: 386.6984 - val_loss: 434.1798 - val_mean_absolute_error: 434.1798\n",
      "Epoch 76/145\n",
      " - 3s - loss: 389.1774 - mean_absolute_error: 389.1774 - val_loss: 424.1594 - val_mean_absolute_error: 424.1594\n",
      "Epoch 77/145\n",
      " - 3s - loss: 386.0223 - mean_absolute_error: 386.0223 - val_loss: 425.5059 - val_mean_absolute_error: 425.5059\n",
      "Epoch 78/145\n",
      " - 3s - loss: 385.0952 - mean_absolute_error: 385.0952 - val_loss: 425.6085 - val_mean_absolute_error: 425.6085\n",
      "Epoch 79/145\n",
      " - 3s - loss: 385.1757 - mean_absolute_error: 385.1757 - val_loss: 423.2251 - val_mean_absolute_error: 423.2251\n",
      "Epoch 80/145\n",
      " - 3s - loss: 384.1972 - mean_absolute_error: 384.1972 - val_loss: 429.0672 - val_mean_absolute_error: 429.0672\n",
      "Epoch 81/145\n",
      "lr changed to 0.0019439998548477888\n",
      " - 3s - loss: 379.6465 - mean_absolute_error: 379.6465 - val_loss: 424.4928 - val_mean_absolute_error: 424.4928\n",
      "Epoch 82/145\n",
      " - 3s - loss: 378.8366 - mean_absolute_error: 378.8366 - val_loss: 422.1186 - val_mean_absolute_error: 422.1186\n",
      "Epoch 83/145\n",
      " - 3s - loss: 379.2694 - mean_absolute_error: 379.2694 - val_loss: 424.1597 - val_mean_absolute_error: 424.1597\n",
      "Epoch 84/145\n",
      " - 3s - loss: 378.0955 - mean_absolute_error: 378.0955 - val_loss: 425.6129 - val_mean_absolute_error: 425.6129\n",
      "Epoch 85/145\n",
      " - 3s - loss: 377.5200 - mean_absolute_error: 377.5200 - val_loss: 424.1399 - val_mean_absolute_error: 424.1399\n",
      "Epoch 86/145\n",
      " - 3s - loss: 377.4154 - mean_absolute_error: 377.4154 - val_loss: 423.8652 - val_mean_absolute_error: 423.8652\n",
      "Epoch 87/145\n",
      " - 3s - loss: 378.0553 - mean_absolute_error: 378.0553 - val_loss: 433.3384 - val_mean_absolute_error: 433.3384\n",
      "Epoch 88/145\n",
      " - 3s - loss: 379.0524 - mean_absolute_error: 379.0524 - val_loss: 425.2611 - val_mean_absolute_error: 425.2611\n",
      "Epoch 89/145\n",
      " - 3s - loss: 377.2616 - mean_absolute_error: 377.2616 - val_loss: 423.1689 - val_mean_absolute_error: 423.1689\n",
      "Epoch 90/145\n",
      " - 3s - loss: 377.1280 - mean_absolute_error: 377.1280 - val_loss: 422.3400 - val_mean_absolute_error: 422.3400\n",
      "Epoch 91/145\n",
      " - 3s - loss: 375.2148 - mean_absolute_error: 375.2148 - val_loss: 422.1935 - val_mean_absolute_error: 422.1935\n",
      "Epoch 92/145\n",
      " - 3s - loss: 376.2401 - mean_absolute_error: 376.2401 - val_loss: 428.8914 - val_mean_absolute_error: 428.8914\n",
      "Epoch 93/145\n",
      " - 3s - loss: 375.9558 - mean_absolute_error: 375.9558 - val_loss: 422.2573 - val_mean_absolute_error: 422.2573\n",
      "Epoch 94/145\n",
      " - 3s - loss: 376.6402 - mean_absolute_error: 376.6402 - val_loss: 426.3353 - val_mean_absolute_error: 426.3353\n",
      "Epoch 95/145\n",
      " - 3s - loss: 375.8416 - mean_absolute_error: 375.8416 - val_loss: 422.1019 - val_mean_absolute_error: 422.1019\n",
      "Epoch 96/145\n",
      " - 3s - loss: 375.2077 - mean_absolute_error: 375.2077 - val_loss: 423.8724 - val_mean_absolute_error: 423.8724\n",
      "Epoch 97/145\n",
      " - 3s - loss: 375.0822 - mean_absolute_error: 375.0822 - val_loss: 424.4516 - val_mean_absolute_error: 424.4516\n",
      "Epoch 98/145\n",
      " - 3s - loss: 375.0726 - mean_absolute_error: 375.0726 - val_loss: 423.6651 - val_mean_absolute_error: 423.6651\n",
      "Epoch 99/145\n",
      " - 4s - loss: 374.0817 - mean_absolute_error: 374.0817 - val_loss: 426.4206 - val_mean_absolute_error: 426.4206\n",
      "Epoch 100/145\n",
      " - 3s - loss: 374.0126 - mean_absolute_error: 374.0126 - val_loss: 424.5596 - val_mean_absolute_error: 424.5596\n",
      "Epoch 101/145\n",
      "lr changed to 0.0011663999408483504\n",
      " - 3s - loss: 371.3182 - mean_absolute_error: 371.3182 - val_loss: 421.5520 - val_mean_absolute_error: 421.5520\n",
      "Epoch 102/145\n",
      " - 3s - loss: 371.1461 - mean_absolute_error: 371.1461 - val_loss: 421.8034 - val_mean_absolute_error: 421.8034\n",
      "Epoch 103/145\n",
      " - 3s - loss: 371.1302 - mean_absolute_error: 371.1302 - val_loss: 422.0902 - val_mean_absolute_error: 422.0902\n",
      "Epoch 104/145\n",
      " - 3s - loss: 370.8732 - mean_absolute_error: 370.8732 - val_loss: 423.9060 - val_mean_absolute_error: 423.9060\n",
      "Epoch 105/145\n",
      " - 4s - loss: 370.2717 - mean_absolute_error: 370.2717 - val_loss: 420.8131 - val_mean_absolute_error: 420.8131\n",
      "Epoch 106/145\n",
      " - 3s - loss: 369.6760 - mean_absolute_error: 369.6760 - val_loss: 421.2074 - val_mean_absolute_error: 421.2074\n",
      "Epoch 107/145\n",
      " - 3s - loss: 369.6516 - mean_absolute_error: 369.6516 - val_loss: 422.9954 - val_mean_absolute_error: 422.9954\n",
      "Epoch 108/145\n",
      " - 3s - loss: 369.9348 - mean_absolute_error: 369.9348 - val_loss: 422.7861 - val_mean_absolute_error: 422.7861\n",
      "Epoch 109/145\n",
      " - 3s - loss: 369.5407 - mean_absolute_error: 369.5407 - val_loss: 420.7516 - val_mean_absolute_error: 420.7516\n",
      "Epoch 110/145\n",
      " - 3s - loss: 369.2068 - mean_absolute_error: 369.2068 - val_loss: 421.1982 - val_mean_absolute_error: 421.1982\n",
      "Epoch 111/145\n",
      " - 3s - loss: 369.0932 - mean_absolute_error: 369.0932 - val_loss: 420.4782 - val_mean_absolute_error: 420.4782\n",
      "Epoch 112/145\n",
      " - 3s - loss: 369.2902 - mean_absolute_error: 369.2902 - val_loss: 421.3589 - val_mean_absolute_error: 421.3589\n",
      "Epoch 113/145\n",
      " - 3s - loss: 368.5341 - mean_absolute_error: 368.5341 - val_loss: 422.1216 - val_mean_absolute_error: 422.1216\n",
      "Epoch 114/145\n",
      " - 4s - loss: 368.9868 - mean_absolute_error: 368.9868 - val_loss: 421.4082 - val_mean_absolute_error: 421.4082\n",
      "Epoch 115/145\n",
      " - 3s - loss: 370.0740 - mean_absolute_error: 370.0740 - val_loss: 421.2684 - val_mean_absolute_error: 421.2684\n",
      "Epoch 116/145\n",
      " - 3s - loss: 367.9689 - mean_absolute_error: 367.9689 - val_loss: 422.6687 - val_mean_absolute_error: 422.6687\n",
      "Epoch 117/145\n",
      " - 3s - loss: 367.4588 - mean_absolute_error: 367.4588 - val_loss: 421.5114 - val_mean_absolute_error: 421.5114\n",
      "Epoch 118/145\n",
      " - 3s - loss: 368.6303 - mean_absolute_error: 368.6303 - val_loss: 424.2177 - val_mean_absolute_error: 424.2177\n",
      "Epoch 119/145\n",
      " - 3s - loss: 368.7677 - mean_absolute_error: 368.7677 - val_loss: 423.9662 - val_mean_absolute_error: 423.9662\n",
      "Epoch 120/145\n",
      " - 3s - loss: 367.9028 - mean_absolute_error: 367.9028 - val_loss: 422.6116 - val_mean_absolute_error: 422.6116\n",
      "Epoch 121/145\n",
      "lr changed to 0.0006998399505391716\n",
      " - 3s - loss: 366.0653 - mean_absolute_error: 366.0653 - val_loss: 420.1895 - val_mean_absolute_error: 420.1895\n",
      "Epoch 122/145\n",
      " - 3s - loss: 365.6695 - mean_absolute_error: 365.6695 - val_loss: 421.5331 - val_mean_absolute_error: 421.5331\n",
      "Epoch 123/145\n",
      " - 3s - loss: 365.3902 - mean_absolute_error: 365.3902 - val_loss: 420.2319 - val_mean_absolute_error: 420.2319\n",
      "Epoch 124/145\n",
      " - 3s - loss: 365.6051 - mean_absolute_error: 365.6051 - val_loss: 420.9754 - val_mean_absolute_error: 420.9754\n",
      "Epoch 125/145\n",
      " - 3s - loss: 365.1290 - mean_absolute_error: 365.1290 - val_loss: 420.3620 - val_mean_absolute_error: 420.3620\n",
      "Epoch 126/145\n",
      " - 3s - loss: 365.1808 - mean_absolute_error: 365.1808 - val_loss: 420.2845 - val_mean_absolute_error: 420.2845\n",
      "Epoch 127/145\n",
      " - 3s - loss: 364.5943 - mean_absolute_error: 364.5943 - val_loss: 421.1048 - val_mean_absolute_error: 421.1048\n",
      "Epoch 128/145\n",
      " - 3s - loss: 364.6204 - mean_absolute_error: 364.6204 - val_loss: 420.4478 - val_mean_absolute_error: 420.4478\n",
      "Epoch 129/145\n",
      " - 3s - loss: 364.8959 - mean_absolute_error: 364.8959 - val_loss: 421.5912 - val_mean_absolute_error: 421.5912\n",
      "Epoch 130/145\n",
      " - 3s - loss: 364.6427 - mean_absolute_error: 364.6427 - val_loss: 421.1385 - val_mean_absolute_error: 421.1385\n",
      "Epoch 131/145\n",
      " - 3s - loss: 364.0644 - mean_absolute_error: 364.0644 - val_loss: 421.4253 - val_mean_absolute_error: 421.4253\n",
      "Epoch 132/145\n",
      " - 3s - loss: 364.4844 - mean_absolute_error: 364.4844 - val_loss: 420.2483 - val_mean_absolute_error: 420.2483\n",
      "Epoch 133/145\n",
      " - 3s - loss: 364.2187 - mean_absolute_error: 364.2187 - val_loss: 420.6850 - val_mean_absolute_error: 420.6850\n",
      "Epoch 134/145\n",
      " - 3s - loss: 363.8492 - mean_absolute_error: 363.8492 - val_loss: 420.6965 - val_mean_absolute_error: 420.6965\n",
      "Epoch 135/145\n",
      " - 3s - loss: 363.4173 - mean_absolute_error: 363.4173 - val_loss: 420.6244 - val_mean_absolute_error: 420.6244\n",
      "Epoch 136/145\n",
      " - 3s - loss: 363.8251 - mean_absolute_error: 363.8251 - val_loss: 420.5809 - val_mean_absolute_error: 420.5809\n",
      "Epoch 137/145\n",
      " - 3s - loss: 363.4276 - mean_absolute_error: 363.4276 - val_loss: 420.9341 - val_mean_absolute_error: 420.9341\n",
      "Epoch 138/145\n",
      " - 3s - loss: 363.5328 - mean_absolute_error: 363.5328 - val_loss: 420.0386 - val_mean_absolute_error: 420.0386\n",
      "Epoch 139/145\n",
      " - 3s - loss: 363.2633 - mean_absolute_error: 363.2633 - val_loss: 421.3343 - val_mean_absolute_error: 421.3343\n",
      "Epoch 140/145\n",
      " - 3s - loss: 363.1598 - mean_absolute_error: 363.1598 - val_loss: 420.2193 - val_mean_absolute_error: 420.2193\n",
      "Epoch 141/145\n",
      "lr changed to 0.0004199039773084223\n",
      " - 3s - loss: 361.9707 - mean_absolute_error: 361.9707 - val_loss: 419.8813 - val_mean_absolute_error: 419.8813\n",
      "Epoch 142/145\n",
      " - 3s - loss: 361.6485 - mean_absolute_error: 361.6485 - val_loss: 419.8359 - val_mean_absolute_error: 419.8359\n",
      "Epoch 143/145\n",
      " - 3s - loss: 361.8454 - mean_absolute_error: 361.8454 - val_loss: 421.1592 - val_mean_absolute_error: 421.1592\n",
      "Epoch 144/145\n",
      " - 3s - loss: 361.8481 - mean_absolute_error: 361.8481 - val_loss: 420.1054 - val_mean_absolute_error: 420.1054\n",
      "Epoch 145/145\n",
      " - 3s - loss: 361.7998 - mean_absolute_error: 361.7998 - val_loss: 419.8787 - val_mean_absolute_error: 419.8787\n",
      "\n",
      "val_mae is:419.87869579025266\n",
      "\n",
      "fold: 3\n",
      "Train on 125000 samples, validate on 25000 samples\n",
      "Epoch 1/145\n",
      " - 4s - loss: 2564.2541 - mean_absolute_error: 2564.2541 - val_loss: 898.3566 - val_mean_absolute_error: 898.3566\n",
      "Epoch 2/145\n",
      " - 4s - loss: 791.9411 - mean_absolute_error: 791.9411 - val_loss: 686.0341 - val_mean_absolute_error: 686.0341\n",
      "Epoch 3/145\n",
      " - 4s - loss: 699.7811 - mean_absolute_error: 699.7811 - val_loss: 609.9474 - val_mean_absolute_error: 609.9474\n",
      "Epoch 4/145\n",
      " - 5s - loss: 649.9140 - mean_absolute_error: 649.9140 - val_loss: 686.1708 - val_mean_absolute_error: 686.1708\n",
      "Epoch 5/145\n",
      " - 4s - loss: 632.1608 - mean_absolute_error: 632.1608 - val_loss: 549.6009 - val_mean_absolute_error: 549.6009\n",
      "Epoch 6/145\n",
      " - 4s - loss: 547.3512 - mean_absolute_error: 547.3512 - val_loss: 560.4450 - val_mean_absolute_error: 560.4450\n",
      "Epoch 7/145\n",
      " - 4s - loss: 559.3763 - mean_absolute_error: 559.3763 - val_loss: 524.2235 - val_mean_absolute_error: 524.2235\n",
      "Epoch 8/145\n",
      " - 4s - loss: 557.9159 - mean_absolute_error: 557.9159 - val_loss: 529.2299 - val_mean_absolute_error: 529.2299\n",
      "Epoch 9/145\n",
      " - 5s - loss: 578.1747 - mean_absolute_error: 578.1747 - val_loss: 558.8536 - val_mean_absolute_error: 558.8536\n",
      "Epoch 10/145\n",
      " - 4s - loss: 504.9032 - mean_absolute_error: 504.9032 - val_loss: 542.5105 - val_mean_absolute_error: 542.5105\n",
      "Epoch 11/145\n",
      " - 4s - loss: 498.1307 - mean_absolute_error: 498.1307 - val_loss: 478.9969 - val_mean_absolute_error: 478.9969\n",
      "Epoch 12/145\n",
      " - 4s - loss: 487.3513 - mean_absolute_error: 487.3513 - val_loss: 493.7991 - val_mean_absolute_error: 493.7991\n",
      "Epoch 13/145\n",
      " - 4s - loss: 496.6931 - mean_absolute_error: 496.6931 - val_loss: 524.0722 - val_mean_absolute_error: 524.0722\n",
      "Epoch 14/145\n",
      " - 4s - loss: 489.5763 - mean_absolute_error: 489.5763 - val_loss: 482.1194 - val_mean_absolute_error: 482.1194\n",
      "Epoch 15/145\n",
      " - 4s - loss: 508.5857 - mean_absolute_error: 508.5857 - val_loss: 566.4799 - val_mean_absolute_error: 566.4799\n",
      "Epoch 16/145\n",
      " - 4s - loss: 520.5500 - mean_absolute_error: 520.5500 - val_loss: 515.5409 - val_mean_absolute_error: 515.5409\n",
      "Epoch 17/145\n",
      " - 4s - loss: 487.9521 - mean_absolute_error: 487.9521 - val_loss: 479.5381 - val_mean_absolute_error: 479.5381\n",
      "Epoch 18/145\n",
      " - 4s - loss: 556.1730 - mean_absolute_error: 556.1730 - val_loss: 476.0982 - val_mean_absolute_error: 476.0982\n",
      "Epoch 19/145\n",
      " - 5s - loss: 491.1509 - mean_absolute_error: 491.1509 - val_loss: 529.2755 - val_mean_absolute_error: 529.2755\n",
      "Epoch 20/145\n",
      " - 4s - loss: 465.9528 - mean_absolute_error: 465.9528 - val_loss: 466.4281 - val_mean_absolute_error: 466.4281\n",
      "Epoch 21/145\n",
      "lr changed to 0.008999999798834323\n",
      " - 4s - loss: 447.5265 - mean_absolute_error: 447.5265 - val_loss: 443.9228 - val_mean_absolute_error: 443.9228\n",
      "Epoch 22/145\n",
      " - 4s - loss: 442.4479 - mean_absolute_error: 442.4479 - val_loss: 448.0857 - val_mean_absolute_error: 448.0857\n",
      "Epoch 23/145\n",
      " - 4s - loss: 443.5962 - mean_absolute_error: 443.5962 - val_loss: 444.6021 - val_mean_absolute_error: 444.6021\n",
      "Epoch 24/145\n",
      " - 5s - loss: 438.1803 - mean_absolute_error: 438.1803 - val_loss: 443.4684 - val_mean_absolute_error: 443.4684\n",
      "Epoch 25/145\n",
      " - 4s - loss: 441.0382 - mean_absolute_error: 441.0382 - val_loss: 442.2866 - val_mean_absolute_error: 442.2866\n",
      "Epoch 26/145\n",
      " - 4s - loss: 439.8411 - mean_absolute_error: 439.8411 - val_loss: 465.0867 - val_mean_absolute_error: 465.0867\n",
      "Epoch 27/145\n",
      " - 4s - loss: 438.5047 - mean_absolute_error: 438.5047 - val_loss: 441.3246 - val_mean_absolute_error: 441.3246\n",
      "Epoch 28/145\n",
      " - 4s - loss: 450.4540 - mean_absolute_error: 450.4540 - val_loss: 441.2694 - val_mean_absolute_error: 441.2694\n",
      "Epoch 29/145\n",
      " - 5s - loss: 443.7383 - mean_absolute_error: 443.7383 - val_loss: 457.8515 - val_mean_absolute_error: 457.8515\n",
      "Epoch 30/145\n",
      " - 4s - loss: 459.1498 - mean_absolute_error: 459.1498 - val_loss: 444.7280 - val_mean_absolute_error: 444.7280\n",
      "Epoch 31/145\n",
      " - 5s - loss: 432.3531 - mean_absolute_error: 432.3531 - val_loss: 482.7581 - val_mean_absolute_error: 482.7581\n",
      "Epoch 32/145\n",
      " - 4s - loss: 468.6111 - mean_absolute_error: 468.6111 - val_loss: 441.6715 - val_mean_absolute_error: 441.6715\n",
      "Epoch 33/145\n",
      " - 5s - loss: 434.9607 - mean_absolute_error: 434.9607 - val_loss: 451.3494 - val_mean_absolute_error: 451.3494\n",
      "Epoch 34/145\n",
      " - 5s - loss: 452.7587 - mean_absolute_error: 452.7587 - val_loss: 493.7302 - val_mean_absolute_error: 493.7302\n",
      "Epoch 35/145\n",
      " - 4s - loss: 438.9563 - mean_absolute_error: 438.9563 - val_loss: 435.4472 - val_mean_absolute_error: 435.4472\n",
      "Epoch 36/145\n",
      " - 4s - loss: 460.2804 - mean_absolute_error: 460.2804 - val_loss: 456.2725 - val_mean_absolute_error: 456.2725\n",
      "Epoch 37/145\n",
      " - 3s - loss: 429.7573 - mean_absolute_error: 429.7573 - val_loss: 447.6066 - val_mean_absolute_error: 447.6066\n",
      "Epoch 38/145\n",
      " - 3s - loss: 437.6069 - mean_absolute_error: 437.6069 - val_loss: 444.3325 - val_mean_absolute_error: 444.3325\n",
      "Epoch 39/145\n",
      " - 5s - loss: 456.5244 - mean_absolute_error: 456.5244 - val_loss: 448.0218 - val_mean_absolute_error: 448.0218\n",
      "Epoch 40/145\n",
      " - 4s - loss: 427.2582 - mean_absolute_error: 427.2582 - val_loss: 454.8108 - val_mean_absolute_error: 454.8108\n",
      "Epoch 41/145\n",
      "lr changed to 0.005399999767541885\n",
      " - 5s - loss: 415.8957 - mean_absolute_error: 415.8957 - val_loss: 429.1719 - val_mean_absolute_error: 429.1719\n",
      "Epoch 42/145\n",
      " - 4s - loss: 411.9243 - mean_absolute_error: 411.9243 - val_loss: 424.7755 - val_mean_absolute_error: 424.7755\n",
      "Epoch 43/145\n",
      " - 3s - loss: 407.1462 - mean_absolute_error: 407.1462 - val_loss: 427.7448 - val_mean_absolute_error: 427.7448\n",
      "Epoch 44/145\n",
      " - 3s - loss: 405.8362 - mean_absolute_error: 405.8362 - val_loss: 423.1944 - val_mean_absolute_error: 423.1944\n",
      "Epoch 45/145\n",
      " - 3s - loss: 406.6666 - mean_absolute_error: 406.6666 - val_loss: 424.1012 - val_mean_absolute_error: 424.1012\n",
      "Epoch 46/145\n",
      " - 3s - loss: 418.8529 - mean_absolute_error: 418.8529 - val_loss: 452.2076 - val_mean_absolute_error: 452.2076\n",
      "Epoch 47/145\n",
      " - 4s - loss: 407.3446 - mean_absolute_error: 407.3446 - val_loss: 424.7563 - val_mean_absolute_error: 424.7563\n",
      "Epoch 48/145\n",
      " - 3s - loss: 405.9595 - mean_absolute_error: 405.9595 - val_loss: 427.9804 - val_mean_absolute_error: 427.9804\n",
      "Epoch 49/145\n",
      " - 3s - loss: 403.5889 - mean_absolute_error: 403.5889 - val_loss: 435.9925 - val_mean_absolute_error: 435.9925\n",
      "Epoch 50/145\n",
      " - 4s - loss: 410.8738 - mean_absolute_error: 410.8738 - val_loss: 421.9483 - val_mean_absolute_error: 421.9483\n",
      "Epoch 51/145\n",
      " - 3s - loss: 404.2376 - mean_absolute_error: 404.2376 - val_loss: 427.3444 - val_mean_absolute_error: 427.3444\n",
      "Epoch 52/145\n",
      " - 3s - loss: 401.9731 - mean_absolute_error: 401.9731 - val_loss: 419.8416 - val_mean_absolute_error: 419.8416\n",
      "Epoch 53/145\n",
      " - 3s - loss: 401.3841 - mean_absolute_error: 401.3841 - val_loss: 424.5265 - val_mean_absolute_error: 424.5265\n",
      "Epoch 54/145\n",
      " - 3s - loss: 400.8637 - mean_absolute_error: 400.8637 - val_loss: 421.9336 - val_mean_absolute_error: 421.9336\n",
      "Epoch 55/145\n",
      " - 3s - loss: 399.4539 - mean_absolute_error: 399.4539 - val_loss: 438.5819 - val_mean_absolute_error: 438.5819\n",
      "Epoch 56/145\n",
      " - 3s - loss: 401.3574 - mean_absolute_error: 401.3574 - val_loss: 430.9549 - val_mean_absolute_error: 430.9549\n",
      "Epoch 57/145\n",
      " - 3s - loss: 414.2309 - mean_absolute_error: 414.2309 - val_loss: 457.9548 - val_mean_absolute_error: 457.9548\n",
      "Epoch 58/145\n",
      " - 3s - loss: 404.5918 - mean_absolute_error: 404.5918 - val_loss: 424.9337 - val_mean_absolute_error: 424.9337\n",
      "Epoch 59/145\n",
      " - 3s - loss: 396.9097 - mean_absolute_error: 396.9097 - val_loss: 419.8509 - val_mean_absolute_error: 419.8509\n",
      "Epoch 60/145\n",
      " - 3s - loss: 395.5493 - mean_absolute_error: 395.5493 - val_loss: 425.1448 - val_mean_absolute_error: 425.1448\n",
      "Epoch 61/145\n",
      "lr changed to 0.0032399998046457766\n",
      " - 3s - loss: 390.2211 - mean_absolute_error: 390.2211 - val_loss: 419.7499 - val_mean_absolute_error: 419.7499\n",
      "Epoch 62/145\n",
      " - 4s - loss: 391.0159 - mean_absolute_error: 391.0159 - val_loss: 424.0851 - val_mean_absolute_error: 424.0851\n",
      "Epoch 63/145\n",
      " - 3s - loss: 388.8311 - mean_absolute_error: 388.8311 - val_loss: 417.4548 - val_mean_absolute_error: 417.4548\n",
      "Epoch 64/145\n",
      " - 3s - loss: 387.6045 - mean_absolute_error: 387.6045 - val_loss: 422.8007 - val_mean_absolute_error: 422.8007\n",
      "Epoch 65/145\n",
      " - 4s - loss: 390.6893 - mean_absolute_error: 390.6893 - val_loss: 416.9665 - val_mean_absolute_error: 416.9665\n",
      "Epoch 66/145\n",
      " - 3s - loss: 386.4676 - mean_absolute_error: 386.4676 - val_loss: 417.2708 - val_mean_absolute_error: 417.2708\n",
      "Epoch 67/145\n",
      " - 3s - loss: 387.9702 - mean_absolute_error: 387.9702 - val_loss: 419.0814 - val_mean_absolute_error: 419.0814\n",
      "Epoch 68/145\n",
      " - 3s - loss: 385.0937 - mean_absolute_error: 385.0937 - val_loss: 419.9454 - val_mean_absolute_error: 419.9454\n",
      "Epoch 69/145\n",
      " - 3s - loss: 386.7470 - mean_absolute_error: 386.7470 - val_loss: 417.1795 - val_mean_absolute_error: 417.1795\n",
      "Epoch 70/145\n",
      " - 3s - loss: 385.6091 - mean_absolute_error: 385.6091 - val_loss: 418.9883 - val_mean_absolute_error: 418.9883\n",
      "Epoch 71/145\n",
      " - 3s - loss: 385.1849 - mean_absolute_error: 385.1849 - val_loss: 417.0278 - val_mean_absolute_error: 417.0278\n",
      "Epoch 72/145\n",
      " - 3s - loss: 382.8802 - mean_absolute_error: 382.8802 - val_loss: 418.7566 - val_mean_absolute_error: 418.7566\n",
      "Epoch 73/145\n",
      " - 3s - loss: 383.4728 - mean_absolute_error: 383.4728 - val_loss: 421.2254 - val_mean_absolute_error: 421.2254\n",
      "Epoch 74/145\n",
      " - 3s - loss: 383.7559 - mean_absolute_error: 383.7559 - val_loss: 420.0133 - val_mean_absolute_error: 420.0133\n",
      "Epoch 75/145\n",
      " - 3s - loss: 382.4480 - mean_absolute_error: 382.4480 - val_loss: 417.8979 - val_mean_absolute_error: 417.8979\n",
      "Epoch 76/145\n",
      " - 3s - loss: 382.5563 - mean_absolute_error: 382.5563 - val_loss: 416.9096 - val_mean_absolute_error: 416.9096\n",
      "Epoch 77/145\n",
      " - 3s - loss: 385.4091 - mean_absolute_error: 385.4091 - val_loss: 416.6773 - val_mean_absolute_error: 416.6773\n",
      "Epoch 78/145\n",
      " - 3s - loss: 382.5769 - mean_absolute_error: 382.5769 - val_loss: 419.8182 - val_mean_absolute_error: 419.8182\n",
      "Epoch 79/145\n",
      " - 3s - loss: 380.4526 - mean_absolute_error: 380.4526 - val_loss: 415.9330 - val_mean_absolute_error: 415.9330\n",
      "Epoch 80/145\n",
      " - 3s - loss: 380.8670 - mean_absolute_error: 380.8670 - val_loss: 417.6991 - val_mean_absolute_error: 417.6991\n",
      "Epoch 81/145\n",
      "lr changed to 0.0019439998548477888\n",
      " - 4s - loss: 377.0375 - mean_absolute_error: 377.0375 - val_loss: 415.8707 - val_mean_absolute_error: 415.8707\n",
      "Epoch 82/145\n",
      " - 3s - loss: 376.9301 - mean_absolute_error: 376.9301 - val_loss: 414.5521 - val_mean_absolute_error: 414.5521\n",
      "Epoch 83/145\n",
      " - 3s - loss: 375.5817 - mean_absolute_error: 375.5817 - val_loss: 416.9749 - val_mean_absolute_error: 416.9749\n",
      "Epoch 84/145\n",
      " - 4s - loss: 375.0070 - mean_absolute_error: 375.0070 - val_loss: 415.1230 - val_mean_absolute_error: 415.1230\n",
      "Epoch 85/145\n",
      " - 3s - loss: 374.2009 - mean_absolute_error: 374.2009 - val_loss: 413.5938 - val_mean_absolute_error: 413.5938\n",
      "Epoch 86/145\n",
      " - 3s - loss: 374.4991 - mean_absolute_error: 374.4991 - val_loss: 417.7765 - val_mean_absolute_error: 417.7765\n",
      "Epoch 87/145\n",
      " - 4s - loss: 372.8773 - mean_absolute_error: 372.8773 - val_loss: 415.5473 - val_mean_absolute_error: 415.5473\n",
      "Epoch 88/145\n",
      " - 3s - loss: 374.0822 - mean_absolute_error: 374.0822 - val_loss: 416.4602 - val_mean_absolute_error: 416.4602\n",
      "Epoch 89/145\n",
      " - 3s - loss: 373.8589 - mean_absolute_error: 373.8589 - val_loss: 414.5187 - val_mean_absolute_error: 414.5187\n",
      "Epoch 90/145\n",
      " - 3s - loss: 374.4167 - mean_absolute_error: 374.4167 - val_loss: 414.6956 - val_mean_absolute_error: 414.6956\n",
      "Epoch 91/145\n",
      " - 3s - loss: 375.1024 - mean_absolute_error: 375.1024 - val_loss: 414.7016 - val_mean_absolute_error: 414.7016\n",
      "Epoch 92/145\n",
      " - 3s - loss: 372.4484 - mean_absolute_error: 372.4484 - val_loss: 416.5756 - val_mean_absolute_error: 416.5756\n",
      "Epoch 93/145\n",
      " - 3s - loss: 372.9169 - mean_absolute_error: 372.9169 - val_loss: 417.4801 - val_mean_absolute_error: 417.4801\n",
      "Epoch 94/145\n",
      " - 3s - loss: 371.4238 - mean_absolute_error: 371.4238 - val_loss: 416.0106 - val_mean_absolute_error: 416.0106\n",
      "Epoch 95/145\n",
      " - 3s - loss: 371.3101 - mean_absolute_error: 371.3101 - val_loss: 415.4661 - val_mean_absolute_error: 415.4661\n",
      "Epoch 96/145\n",
      " - 4s - loss: 370.7068 - mean_absolute_error: 370.7068 - val_loss: 414.4183 - val_mean_absolute_error: 414.4183\n",
      "Epoch 97/145\n",
      " - 3s - loss: 370.3120 - mean_absolute_error: 370.3120 - val_loss: 415.9175 - val_mean_absolute_error: 415.9175\n",
      "Epoch 98/145\n",
      " - 3s - loss: 370.1668 - mean_absolute_error: 370.1668 - val_loss: 415.7821 - val_mean_absolute_error: 415.7821\n",
      "Epoch 99/145\n",
      " - 4s - loss: 371.5300 - mean_absolute_error: 371.5300 - val_loss: 425.0747 - val_mean_absolute_error: 425.0747\n",
      "Epoch 100/145\n",
      " - 3s - loss: 373.0229 - mean_absolute_error: 373.0229 - val_loss: 418.8942 - val_mean_absolute_error: 418.8942\n",
      "Epoch 101/145\n",
      "lr changed to 0.0011663999408483504\n",
      " - 3s - loss: 367.3186 - mean_absolute_error: 367.3186 - val_loss: 414.7701 - val_mean_absolute_error: 414.7701\n",
      "Epoch 102/145\n",
      " - 4s - loss: 366.8640 - mean_absolute_error: 366.8640 - val_loss: 412.4560 - val_mean_absolute_error: 412.4560\n",
      "Epoch 103/145\n",
      " - 3s - loss: 365.6010 - mean_absolute_error: 365.6010 - val_loss: 414.9927 - val_mean_absolute_error: 414.9927\n",
      "Epoch 104/145\n",
      " - 3s - loss: 365.5644 - mean_absolute_error: 365.5644 - val_loss: 414.8338 - val_mean_absolute_error: 414.8338\n",
      "Epoch 105/145\n",
      " - 4s - loss: 365.3304 - mean_absolute_error: 365.3304 - val_loss: 413.7593 - val_mean_absolute_error: 413.7593\n",
      "Epoch 106/145\n",
      " - 4s - loss: 365.0655 - mean_absolute_error: 365.0655 - val_loss: 416.0598 - val_mean_absolute_error: 416.0598\n",
      "Epoch 107/145\n",
      " - 3s - loss: 365.1942 - mean_absolute_error: 365.1942 - val_loss: 414.5304 - val_mean_absolute_error: 414.5304\n",
      "Epoch 108/145\n",
      " - 4s - loss: 365.1355 - mean_absolute_error: 365.1355 - val_loss: 414.2558 - val_mean_absolute_error: 414.2558\n",
      "Epoch 109/145\n",
      " - 3s - loss: 365.0052 - mean_absolute_error: 365.0052 - val_loss: 415.1110 - val_mean_absolute_error: 415.1110\n",
      "Epoch 110/145\n",
      " - 3s - loss: 364.2478 - mean_absolute_error: 364.2478 - val_loss: 415.3425 - val_mean_absolute_error: 415.3425\n",
      "Epoch 111/145\n",
      " - 4s - loss: 363.6970 - mean_absolute_error: 363.6970 - val_loss: 415.0165 - val_mean_absolute_error: 415.0165\n",
      "Epoch 112/145\n",
      " - 3s - loss: 363.3879 - mean_absolute_error: 363.3879 - val_loss: 414.8189 - val_mean_absolute_error: 414.8189\n",
      "Epoch 113/145\n",
      " - 3s - loss: 363.5845 - mean_absolute_error: 363.5845 - val_loss: 415.1065 - val_mean_absolute_error: 415.1065\n",
      "Epoch 114/145\n",
      " - 4s - loss: 363.5264 - mean_absolute_error: 363.5264 - val_loss: 414.1271 - val_mean_absolute_error: 414.1271\n",
      "Epoch 115/145\n",
      " - 3s - loss: 363.8807 - mean_absolute_error: 363.8807 - val_loss: 415.4607 - val_mean_absolute_error: 415.4607\n",
      "Epoch 116/145\n",
      " - 3s - loss: 362.6225 - mean_absolute_error: 362.6225 - val_loss: 415.0638 - val_mean_absolute_error: 415.0638\n",
      "Epoch 117/145\n",
      " - 5s - loss: 362.6174 - mean_absolute_error: 362.6174 - val_loss: 415.0346 - val_mean_absolute_error: 415.0346\n",
      "Epoch 118/145\n",
      " - 4s - loss: 362.3773 - mean_absolute_error: 362.3773 - val_loss: 414.5007 - val_mean_absolute_error: 414.5007\n",
      "Epoch 119/145\n",
      " - 5s - loss: 362.5693 - mean_absolute_error: 362.5693 - val_loss: 416.2490 - val_mean_absolute_error: 416.2490\n",
      "Epoch 120/145\n",
      " - 4s - loss: 362.4490 - mean_absolute_error: 362.4490 - val_loss: 418.2869 - val_mean_absolute_error: 418.2869\n",
      "Epoch 121/145\n",
      "lr changed to 0.0006998399505391716\n",
      " - 3s - loss: 360.3699 - mean_absolute_error: 360.3699 - val_loss: 415.2083 - val_mean_absolute_error: 415.2083\n",
      "Epoch 122/145\n",
      " - 4s - loss: 361.5495 - mean_absolute_error: 361.5495 - val_loss: 415.1664 - val_mean_absolute_error: 415.1664\n",
      "Epoch 123/145\n",
      " - 3s - loss: 359.9024 - mean_absolute_error: 359.9024 - val_loss: 414.8111 - val_mean_absolute_error: 414.8111\n",
      "Epoch 124/145\n",
      " - 3s - loss: 360.1969 - mean_absolute_error: 360.1969 - val_loss: 415.3792 - val_mean_absolute_error: 415.3792\n",
      "Epoch 125/145\n",
      " - 4s - loss: 359.9635 - mean_absolute_error: 359.9635 - val_loss: 415.7797 - val_mean_absolute_error: 415.7797\n",
      "Epoch 126/145\n",
      " - 3s - loss: 359.4626 - mean_absolute_error: 359.4626 - val_loss: 413.9723 - val_mean_absolute_error: 413.9723\n",
      "Epoch 127/145\n",
      " - 3s - loss: 359.9028 - mean_absolute_error: 359.9028 - val_loss: 414.5394 - val_mean_absolute_error: 414.5394\n",
      "Epoch 128/145\n",
      " - 4s - loss: 359.0448 - mean_absolute_error: 359.0448 - val_loss: 414.1907 - val_mean_absolute_error: 414.1907\n",
      "Epoch 129/145\n",
      " - 3s - loss: 358.9009 - mean_absolute_error: 358.9009 - val_loss: 415.0771 - val_mean_absolute_error: 415.0771\n",
      "Epoch 130/145\n",
      " - 3s - loss: 358.4344 - mean_absolute_error: 358.4344 - val_loss: 414.3513 - val_mean_absolute_error: 414.3513\n",
      "Epoch 131/145\n",
      " - 4s - loss: 359.0887 - mean_absolute_error: 359.0887 - val_loss: 414.3761 - val_mean_absolute_error: 414.3761\n",
      "Epoch 132/145\n",
      " - 3s - loss: 358.4267 - mean_absolute_error: 358.4267 - val_loss: 415.2073 - val_mean_absolute_error: 415.2073\n",
      "Epoch 133/145\n",
      " - 3s - loss: 358.1699 - mean_absolute_error: 358.1699 - val_loss: 414.1959 - val_mean_absolute_error: 414.1959\n",
      "Epoch 134/145\n",
      " - 4s - loss: 357.9942 - mean_absolute_error: 357.9942 - val_loss: 415.7822 - val_mean_absolute_error: 415.7822\n",
      "Epoch 135/145\n",
      " - 3s - loss: 358.3679 - mean_absolute_error: 358.3679 - val_loss: 415.3178 - val_mean_absolute_error: 415.3178\n",
      "Epoch 136/145\n",
      " - 4s - loss: 357.6300 - mean_absolute_error: 357.6300 - val_loss: 415.6980 - val_mean_absolute_error: 415.6980\n",
      "Epoch 137/145\n",
      " - 5s - loss: 357.8135 - mean_absolute_error: 357.8135 - val_loss: 414.4580 - val_mean_absolute_error: 414.4580\n",
      "Epoch 138/145\n",
      " - 4s - loss: 357.7502 - mean_absolute_error: 357.7502 - val_loss: 416.4911 - val_mean_absolute_error: 416.4911\n",
      "Epoch 139/145\n",
      " - 5s - loss: 357.4052 - mean_absolute_error: 357.4052 - val_loss: 415.5359 - val_mean_absolute_error: 415.5359\n",
      "Epoch 140/145\n",
      " - 4s - loss: 357.4494 - mean_absolute_error: 357.4494 - val_loss: 415.6648 - val_mean_absolute_error: 415.6648\n",
      "Epoch 141/145\n",
      "lr changed to 0.0004199039773084223\n",
      " - 5s - loss: 355.6914 - mean_absolute_error: 355.6914 - val_loss: 414.4233 - val_mean_absolute_error: 414.4233\n",
      "Epoch 142/145\n",
      " - 4s - loss: 355.6823 - mean_absolute_error: 355.6823 - val_loss: 414.4921 - val_mean_absolute_error: 414.4921\n",
      "Epoch 143/145\n",
      " - 3s - loss: 355.6078 - mean_absolute_error: 355.6078 - val_loss: 414.6585 - val_mean_absolute_error: 414.6585\n",
      "Epoch 144/145\n",
      " - 4s - loss: 355.3415 - mean_absolute_error: 355.3415 - val_loss: 414.9900 - val_mean_absolute_error: 414.9900\n",
      "Epoch 145/145\n",
      " - 3s - loss: 355.3899 - mean_absolute_error: 355.3899 - val_loss: 414.7829 - val_mean_absolute_error: 414.7829\n",
      "\n",
      "val_mae is:414.78288500198363\n",
      "\n",
      "fold: 4\n",
      "Train on 125000 samples, validate on 25000 samples\n",
      "Epoch 1/145\n",
      " - 5s - loss: 2577.2257 - mean_absolute_error: 2577.2257 - val_loss: 983.3343 - val_mean_absolute_error: 983.3343\n",
      "Epoch 2/145\n",
      " - 3s - loss: 824.2051 - mean_absolute_error: 824.2051 - val_loss: 701.7748 - val_mean_absolute_error: 701.7748\n",
      "Epoch 3/145\n",
      " - 3s - loss: 672.9655 - mean_absolute_error: 672.9655 - val_loss: 642.5826 - val_mean_absolute_error: 642.5826\n",
      "Epoch 4/145\n",
      " - 4s - loss: 624.2419 - mean_absolute_error: 624.2419 - val_loss: 702.0112 - val_mean_absolute_error: 702.0112\n",
      "Epoch 5/145\n",
      " - 3s - loss: 594.3951 - mean_absolute_error: 594.3951 - val_loss: 557.3611 - val_mean_absolute_error: 557.3611\n",
      "Epoch 6/145\n",
      " - 3s - loss: 567.7591 - mean_absolute_error: 567.7591 - val_loss: 554.0646 - val_mean_absolute_error: 554.0646\n",
      "Epoch 7/145\n",
      " - 4s - loss: 573.5879 - mean_absolute_error: 573.5879 - val_loss: 569.6282 - val_mean_absolute_error: 569.6282\n",
      "Epoch 8/145\n",
      " - 3s - loss: 587.2149 - mean_absolute_error: 587.2149 - val_loss: 590.9852 - val_mean_absolute_error: 590.9852\n",
      "Epoch 9/145\n",
      " - 3s - loss: 528.4340 - mean_absolute_error: 528.4340 - val_loss: 537.4175 - val_mean_absolute_error: 537.4175\n",
      "Epoch 10/145\n",
      " - 4s - loss: 511.7796 - mean_absolute_error: 511.7796 - val_loss: 511.3033 - val_mean_absolute_error: 511.3033\n",
      "Epoch 11/145\n",
      " - 3s - loss: 509.9952 - mean_absolute_error: 509.9952 - val_loss: 498.7562 - val_mean_absolute_error: 498.7562\n",
      "Epoch 12/145\n",
      " - 3s - loss: 494.9254 - mean_absolute_error: 494.9254 - val_loss: 514.0588 - val_mean_absolute_error: 514.0588\n",
      "Epoch 13/145\n",
      " - 4s - loss: 549.8453 - mean_absolute_error: 549.8453 - val_loss: 514.0701 - val_mean_absolute_error: 514.0701\n",
      "Epoch 14/145\n",
      " - 3s - loss: 543.9348 - mean_absolute_error: 543.9348 - val_loss: 537.8862 - val_mean_absolute_error: 537.8862\n",
      "Epoch 15/145\n",
      " - 3s - loss: 526.9647 - mean_absolute_error: 526.9647 - val_loss: 493.3004 - val_mean_absolute_error: 493.3004\n",
      "Epoch 16/145\n",
      " - 4s - loss: 497.9263 - mean_absolute_error: 497.9263 - val_loss: 498.3133 - val_mean_absolute_error: 498.3133\n",
      "Epoch 17/145\n",
      " - 3s - loss: 488.8659 - mean_absolute_error: 488.8659 - val_loss: 508.3489 - val_mean_absolute_error: 508.3489\n",
      "Epoch 18/145\n",
      " - 3s - loss: 466.5773 - mean_absolute_error: 466.5773 - val_loss: 470.7798 - val_mean_absolute_error: 470.7798\n",
      "Epoch 19/145\n",
      " - 4s - loss: 479.2079 - mean_absolute_error: 479.2079 - val_loss: 510.7023 - val_mean_absolute_error: 510.7023\n",
      "Epoch 20/145\n",
      " - 3s - loss: 523.0755 - mean_absolute_error: 523.0755 - val_loss: 493.1187 - val_mean_absolute_error: 493.1187\n",
      "Epoch 21/145\n",
      "lr changed to 0.008999999798834323\n",
      " - 3s - loss: 451.6145 - mean_absolute_error: 451.6145 - val_loss: 456.0484 - val_mean_absolute_error: 456.0484\n",
      "Epoch 22/145\n",
      " - 4s - loss: 440.8346 - mean_absolute_error: 440.8346 - val_loss: 457.4326 - val_mean_absolute_error: 457.4326\n",
      "Epoch 23/145\n",
      " - 3s - loss: 441.3686 - mean_absolute_error: 441.3686 - val_loss: 457.9804 - val_mean_absolute_error: 457.9804\n",
      "Epoch 24/145\n",
      " - 3s - loss: 456.8474 - mean_absolute_error: 456.8474 - val_loss: 449.3742 - val_mean_absolute_error: 449.3742\n",
      "Epoch 25/145\n",
      " - 4s - loss: 477.4648 - mean_absolute_error: 477.4648 - val_loss: 476.1534 - val_mean_absolute_error: 476.1534\n",
      "Epoch 26/145\n",
      " - 3s - loss: 444.5759 - mean_absolute_error: 444.5759 - val_loss: 459.3116 - val_mean_absolute_error: 459.3116\n",
      "Epoch 27/145\n",
      " - 3s - loss: 438.7766 - mean_absolute_error: 438.7766 - val_loss: 453.9560 - val_mean_absolute_error: 453.9560\n",
      "Epoch 28/145\n",
      " - 4s - loss: 437.7418 - mean_absolute_error: 437.7418 - val_loss: 449.8648 - val_mean_absolute_error: 449.8648\n",
      "Epoch 29/145\n",
      " - 3s - loss: 434.6636 - mean_absolute_error: 434.6636 - val_loss: 448.2635 - val_mean_absolute_error: 448.2635\n",
      "Epoch 30/145\n",
      " - 3s - loss: 431.9828 - mean_absolute_error: 431.9828 - val_loss: 467.3248 - val_mean_absolute_error: 467.3248\n",
      "Epoch 31/145\n",
      " - 4s - loss: 451.4029 - mean_absolute_error: 451.4029 - val_loss: 529.9512 - val_mean_absolute_error: 529.9512\n",
      "Epoch 32/145\n",
      " - 3s - loss: 472.9399 - mean_absolute_error: 472.9399 - val_loss: 462.4122 - val_mean_absolute_error: 462.4122\n",
      "Epoch 33/145\n",
      " - 3s - loss: 434.0068 - mean_absolute_error: 434.0068 - val_loss: 469.8213 - val_mean_absolute_error: 469.8213\n",
      "Epoch 34/145\n",
      " - 4s - loss: 434.2536 - mean_absolute_error: 434.2536 - val_loss: 441.3122 - val_mean_absolute_error: 441.3122\n",
      "Epoch 35/145\n",
      " - 3s - loss: 431.8910 - mean_absolute_error: 431.8910 - val_loss: 440.8933 - val_mean_absolute_error: 440.8933\n",
      "Epoch 36/145\n",
      " - 3s - loss: 426.9353 - mean_absolute_error: 426.9353 - val_loss: 443.4249 - val_mean_absolute_error: 443.4249\n",
      "Epoch 37/145\n",
      " - 4s - loss: 431.1205 - mean_absolute_error: 431.1205 - val_loss: 462.2410 - val_mean_absolute_error: 462.2410\n",
      "Epoch 38/145\n",
      " - 3s - loss: 429.0472 - mean_absolute_error: 429.0472 - val_loss: 446.5632 - val_mean_absolute_error: 446.5632\n",
      "Epoch 39/145\n",
      " - 3s - loss: 426.2512 - mean_absolute_error: 426.2512 - val_loss: 445.7365 - val_mean_absolute_error: 445.7365\n",
      "Epoch 40/145\n",
      " - 4s - loss: 427.9007 - mean_absolute_error: 427.9007 - val_loss: 448.1439 - val_mean_absolute_error: 448.1439\n",
      "Epoch 41/145\n",
      "lr changed to 0.005399999767541885\n",
      " - 3s - loss: 416.6243 - mean_absolute_error: 416.6243 - val_loss: 439.4211 - val_mean_absolute_error: 439.4211\n",
      "Epoch 42/145\n",
      " - 3s - loss: 414.4680 - mean_absolute_error: 414.4680 - val_loss: 435.1379 - val_mean_absolute_error: 435.1379\n",
      "Epoch 43/145\n",
      " - 3s - loss: 412.0594 - mean_absolute_error: 412.0594 - val_loss: 435.4923 - val_mean_absolute_error: 435.4923\n",
      "Epoch 44/145\n",
      " - 3s - loss: 412.6900 - mean_absolute_error: 412.6900 - val_loss: 433.9742 - val_mean_absolute_error: 433.9742\n",
      "Epoch 45/145\n",
      " - 3s - loss: 411.2696 - mean_absolute_error: 411.2696 - val_loss: 440.0559 - val_mean_absolute_error: 440.0559\n",
      "Epoch 46/145\n",
      " - 3s - loss: 410.6317 - mean_absolute_error: 410.6317 - val_loss: 434.9663 - val_mean_absolute_error: 434.9663\n",
      "Epoch 47/145\n",
      " - 3s - loss: 411.6797 - mean_absolute_error: 411.6797 - val_loss: 441.3842 - val_mean_absolute_error: 441.3842\n",
      "Epoch 48/145\n",
      " - 3s - loss: 416.3224 - mean_absolute_error: 416.3224 - val_loss: 430.8338 - val_mean_absolute_error: 430.8338\n",
      "Epoch 49/145\n",
      " - 4s - loss: 410.4143 - mean_absolute_error: 410.4143 - val_loss: 431.8442 - val_mean_absolute_error: 431.8442\n",
      "Epoch 50/145\n",
      " - 3s - loss: 409.0430 - mean_absolute_error: 409.0430 - val_loss: 432.3698 - val_mean_absolute_error: 432.3698\n",
      "Epoch 51/145\n",
      " - 3s - loss: 408.1128 - mean_absolute_error: 408.1128 - val_loss: 431.0510 - val_mean_absolute_error: 431.0510\n",
      "Epoch 52/145\n",
      " - 3s - loss: 406.5837 - mean_absolute_error: 406.5837 - val_loss: 431.1930 - val_mean_absolute_error: 431.1930\n",
      "Epoch 53/145\n",
      " - 3s - loss: 406.2288 - mean_absolute_error: 406.2288 - val_loss: 428.9151 - val_mean_absolute_error: 428.9151\n",
      "Epoch 54/145\n",
      " - 3s - loss: 407.8617 - mean_absolute_error: 407.8617 - val_loss: 431.5598 - val_mean_absolute_error: 431.5598\n",
      "Epoch 55/145\n",
      " - 3s - loss: 406.0736 - mean_absolute_error: 406.0736 - val_loss: 433.1691 - val_mean_absolute_error: 433.1691\n",
      "Epoch 56/145\n",
      " - 4s - loss: 404.7129 - mean_absolute_error: 404.7129 - val_loss: 429.7876 - val_mean_absolute_error: 429.7876\n",
      "Epoch 57/145\n",
      " - 3s - loss: 409.5080 - mean_absolute_error: 409.5080 - val_loss: 433.7723 - val_mean_absolute_error: 433.7723\n",
      "Epoch 58/145\n",
      " - 3s - loss: 405.2107 - mean_absolute_error: 405.2107 - val_loss: 436.4056 - val_mean_absolute_error: 436.4056\n",
      "Epoch 59/145\n",
      " - 3s - loss: 406.9573 - mean_absolute_error: 406.9573 - val_loss: 486.8763 - val_mean_absolute_error: 486.8763\n",
      "Epoch 60/145\n",
      " - 3s - loss: 423.9329 - mean_absolute_error: 423.9329 - val_loss: 431.0047 - val_mean_absolute_error: 431.0047\n",
      "Epoch 61/145\n",
      "lr changed to 0.0032399998046457766\n",
      " - 3s - loss: 398.3368 - mean_absolute_error: 398.3368 - val_loss: 426.7256 - val_mean_absolute_error: 426.7256\n",
      "Epoch 62/145\n",
      " - 4s - loss: 397.6387 - mean_absolute_error: 397.6387 - val_loss: 423.9377 - val_mean_absolute_error: 423.9377\n",
      "Epoch 63/145\n",
      " - 3s - loss: 394.2574 - mean_absolute_error: 394.2574 - val_loss: 427.2759 - val_mean_absolute_error: 427.2759\n",
      "Epoch 64/145\n",
      " - 3s - loss: 393.4523 - mean_absolute_error: 393.4523 - val_loss: 427.1770 - val_mean_absolute_error: 427.1770\n",
      "Epoch 65/145\n",
      " - 4s - loss: 393.7478 - mean_absolute_error: 393.7478 - val_loss: 426.8395 - val_mean_absolute_error: 426.8395\n",
      "Epoch 66/145\n",
      " - 3s - loss: 394.3023 - mean_absolute_error: 394.3023 - val_loss: 426.4473 - val_mean_absolute_error: 426.4473\n",
      "Epoch 67/145\n",
      " - 3s - loss: 395.8254 - mean_absolute_error: 395.8254 - val_loss: 424.2025 - val_mean_absolute_error: 424.2025\n",
      "Epoch 68/145\n",
      " - 4s - loss: 392.8337 - mean_absolute_error: 392.8337 - val_loss: 430.1540 - val_mean_absolute_error: 430.1540\n",
      "Epoch 69/145\n",
      " - 3s - loss: 392.5414 - mean_absolute_error: 392.5414 - val_loss: 424.2587 - val_mean_absolute_error: 424.2587\n",
      "Epoch 70/145\n",
      " - 3s - loss: 391.8698 - mean_absolute_error: 391.8698 - val_loss: 426.1779 - val_mean_absolute_error: 426.1779\n",
      "Epoch 71/145\n",
      " - 3s - loss: 391.6153 - mean_absolute_error: 391.6153 - val_loss: 423.3820 - val_mean_absolute_error: 423.3820\n",
      "Epoch 72/145\n",
      " - 3s - loss: 391.2473 - mean_absolute_error: 391.2473 - val_loss: 425.3082 - val_mean_absolute_error: 425.3082\n",
      "Epoch 73/145\n",
      " - 3s - loss: 391.3086 - mean_absolute_error: 391.3086 - val_loss: 424.1974 - val_mean_absolute_error: 424.1974\n",
      "Epoch 74/145\n",
      " - 3s - loss: 391.7854 - mean_absolute_error: 391.7854 - val_loss: 435.5882 - val_mean_absolute_error: 435.5882\n",
      "Epoch 75/145\n",
      " - 3s - loss: 395.4578 - mean_absolute_error: 395.4578 - val_loss: 426.1510 - val_mean_absolute_error: 426.1510\n",
      "Epoch 76/145\n",
      " - 3s - loss: 390.4368 - mean_absolute_error: 390.4368 - val_loss: 425.8402 - val_mean_absolute_error: 425.8402\n",
      "Epoch 77/145\n",
      " - 3s - loss: 390.9567 - mean_absolute_error: 390.9567 - val_loss: 422.1023 - val_mean_absolute_error: 422.1023\n",
      "Epoch 78/145\n",
      " - 3s - loss: 388.2939 - mean_absolute_error: 388.2939 - val_loss: 423.3171 - val_mean_absolute_error: 423.3171\n",
      "Epoch 79/145\n",
      " - 3s - loss: 388.3537 - mean_absolute_error: 388.3537 - val_loss: 421.1299 - val_mean_absolute_error: 421.1299\n",
      "Epoch 80/145\n",
      " - 3s - loss: 389.4938 - mean_absolute_error: 389.4938 - val_loss: 425.7037 - val_mean_absolute_error: 425.7037\n",
      "Epoch 81/145\n",
      "lr changed to 0.0019439998548477888\n",
      " - 3s - loss: 384.8575 - mean_absolute_error: 384.8575 - val_loss: 420.8390 - val_mean_absolute_error: 420.8390\n",
      "Epoch 82/145\n",
      " - 3s - loss: 382.8087 - mean_absolute_error: 382.8087 - val_loss: 422.5483 - val_mean_absolute_error: 422.5483\n",
      "Epoch 83/145\n",
      " - 3s - loss: 384.3527 - mean_absolute_error: 384.3527 - val_loss: 424.9958 - val_mean_absolute_error: 424.9958\n",
      "Epoch 84/145\n",
      " - 3s - loss: 382.5051 - mean_absolute_error: 382.5051 - val_loss: 421.5134 - val_mean_absolute_error: 421.5134\n",
      "Epoch 85/145\n",
      " - 3s - loss: 383.0539 - mean_absolute_error: 383.0539 - val_loss: 428.0083 - val_mean_absolute_error: 428.0083\n",
      "Epoch 86/145\n",
      " - 3s - loss: 385.4956 - mean_absolute_error: 385.4956 - val_loss: 423.5026 - val_mean_absolute_error: 423.5026\n",
      "Epoch 87/145\n",
      " - 4s - loss: 381.8429 - mean_absolute_error: 381.8429 - val_loss: 420.5518 - val_mean_absolute_error: 420.5518\n",
      "Epoch 88/145\n",
      " - 5s - loss: 380.6324 - mean_absolute_error: 380.6324 - val_loss: 419.9794 - val_mean_absolute_error: 419.9794\n",
      "Epoch 89/145\n",
      " - 6s - loss: 380.3855 - mean_absolute_error: 380.3855 - val_loss: 420.5714 - val_mean_absolute_error: 420.5714\n",
      "Epoch 90/145\n",
      " - 3s - loss: 381.8941 - mean_absolute_error: 381.8941 - val_loss: 421.8314 - val_mean_absolute_error: 421.8314\n",
      "Epoch 91/145\n",
      " - 3s - loss: 380.4150 - mean_absolute_error: 380.4150 - val_loss: 420.1051 - val_mean_absolute_error: 420.1051\n",
      "Epoch 92/145\n",
      " - 3s - loss: 381.1601 - mean_absolute_error: 381.1601 - val_loss: 428.5012 - val_mean_absolute_error: 428.5012\n",
      "Epoch 93/145\n",
      " - 3s - loss: 381.0834 - mean_absolute_error: 381.0834 - val_loss: 420.6733 - val_mean_absolute_error: 420.6733\n",
      "Epoch 94/145\n",
      " - 3s - loss: 378.8466 - mean_absolute_error: 378.8466 - val_loss: 422.0517 - val_mean_absolute_error: 422.0517\n",
      "Epoch 95/145\n",
      " - 3s - loss: 378.7092 - mean_absolute_error: 378.7092 - val_loss: 419.1003 - val_mean_absolute_error: 419.1003\n",
      "Epoch 96/145\n",
      " - 3s - loss: 379.2024 - mean_absolute_error: 379.2024 - val_loss: 422.8448 - val_mean_absolute_error: 422.8448\n",
      "Epoch 97/145\n",
      " - 3s - loss: 379.2054 - mean_absolute_error: 379.2054 - val_loss: 422.6368 - val_mean_absolute_error: 422.6368\n",
      "Epoch 98/145\n",
      " - 3s - loss: 378.8711 - mean_absolute_error: 378.8711 - val_loss: 419.4639 - val_mean_absolute_error: 419.4639\n",
      "Epoch 99/145\n",
      " - 4s - loss: 379.1591 - mean_absolute_error: 379.1591 - val_loss: 421.3880 - val_mean_absolute_error: 421.3880\n",
      "Epoch 100/145\n",
      " - 3s - loss: 377.7187 - mean_absolute_error: 377.7187 - val_loss: 422.2159 - val_mean_absolute_error: 422.2159\n",
      "Epoch 101/145\n",
      "lr changed to 0.0011663999408483504\n",
      " - 3s - loss: 375.4828 - mean_absolute_error: 375.4828 - val_loss: 419.0025 - val_mean_absolute_error: 419.0025\n",
      "Epoch 102/145\n",
      " - 3s - loss: 374.1632 - mean_absolute_error: 374.1632 - val_loss: 418.7602 - val_mean_absolute_error: 418.7602\n",
      "Epoch 103/145\n",
      " - 3s - loss: 375.2186 - mean_absolute_error: 375.2186 - val_loss: 419.2655 - val_mean_absolute_error: 419.2655\n",
      "Epoch 104/145\n",
      " - 3s - loss: 374.7733 - mean_absolute_error: 374.7733 - val_loss: 418.6554 - val_mean_absolute_error: 418.6554\n",
      "Epoch 105/145\n",
      " - 3s - loss: 373.3983 - mean_absolute_error: 373.3983 - val_loss: 419.5904 - val_mean_absolute_error: 419.5904\n",
      "Epoch 106/145\n",
      " - 3s - loss: 373.3312 - mean_absolute_error: 373.3312 - val_loss: 418.7509 - val_mean_absolute_error: 418.7509\n",
      "Epoch 107/145\n",
      " - 3s - loss: 373.2307 - mean_absolute_error: 373.2307 - val_loss: 418.4037 - val_mean_absolute_error: 418.4037\n",
      "Epoch 108/145\n",
      " - 3s - loss: 372.9401 - mean_absolute_error: 372.9401 - val_loss: 419.0266 - val_mean_absolute_error: 419.0266\n",
      "Epoch 109/145\n",
      " - 3s - loss: 373.5024 - mean_absolute_error: 373.5024 - val_loss: 417.2522 - val_mean_absolute_error: 417.2522\n",
      "Epoch 110/145\n",
      " - 3s - loss: 372.4753 - mean_absolute_error: 372.4753 - val_loss: 417.6924 - val_mean_absolute_error: 417.6924\n",
      "Epoch 111/145\n",
      " - 3s - loss: 373.5100 - mean_absolute_error: 373.5100 - val_loss: 420.5709 - val_mean_absolute_error: 420.5709\n",
      "Epoch 112/145\n",
      " - 3s - loss: 372.5758 - mean_absolute_error: 372.5758 - val_loss: 421.7202 - val_mean_absolute_error: 421.7202\n",
      "Epoch 113/145\n",
      " - 3s - loss: 372.3544 - mean_absolute_error: 372.3544 - val_loss: 419.5305 - val_mean_absolute_error: 419.5305\n",
      "Epoch 114/145\n",
      " - 3s - loss: 372.8853 - mean_absolute_error: 372.8853 - val_loss: 418.0842 - val_mean_absolute_error: 418.0842\n",
      "Epoch 115/145\n",
      " - 3s - loss: 373.3656 - mean_absolute_error: 373.3656 - val_loss: 419.4055 - val_mean_absolute_error: 419.4055\n",
      "Epoch 116/145\n",
      " - 4s - loss: 371.6980 - mean_absolute_error: 371.6980 - val_loss: 417.2898 - val_mean_absolute_error: 417.2898\n",
      "Epoch 117/145\n",
      " - 4s - loss: 371.7354 - mean_absolute_error: 371.7354 - val_loss: 419.0467 - val_mean_absolute_error: 419.0467\n",
      "Epoch 118/145\n",
      " - 3s - loss: 372.5292 - mean_absolute_error: 372.5292 - val_loss: 422.6295 - val_mean_absolute_error: 422.6295\n",
      "Epoch 119/145\n",
      " - 3s - loss: 372.1279 - mean_absolute_error: 372.1279 - val_loss: 419.5558 - val_mean_absolute_error: 419.5558\n",
      "Epoch 120/145\n",
      " - 3s - loss: 370.3492 - mean_absolute_error: 370.3492 - val_loss: 419.4331 - val_mean_absolute_error: 419.4331\n",
      "Epoch 121/145\n",
      "lr changed to 0.0006998399505391716\n",
      " - 3s - loss: 369.1999 - mean_absolute_error: 369.1999 - val_loss: 417.5028 - val_mean_absolute_error: 417.5028\n",
      "Epoch 122/145\n",
      " - 3s - loss: 369.0677 - mean_absolute_error: 369.0677 - val_loss: 417.9487 - val_mean_absolute_error: 417.9487\n",
      "Epoch 123/145\n",
      " - 4s - loss: 368.7823 - mean_absolute_error: 368.7823 - val_loss: 417.6291 - val_mean_absolute_error: 417.6291\n",
      "Epoch 124/145\n",
      " - 3s - loss: 368.6342 - mean_absolute_error: 368.6342 - val_loss: 418.1979 - val_mean_absolute_error: 418.1979\n",
      "Epoch 125/145\n",
      " - 3s - loss: 368.6994 - mean_absolute_error: 368.6994 - val_loss: 417.3198 - val_mean_absolute_error: 417.3198\n",
      "Epoch 126/145\n",
      " - 3s - loss: 368.3412 - mean_absolute_error: 368.3412 - val_loss: 418.6621 - val_mean_absolute_error: 418.6621\n",
      "Epoch 127/145\n",
      " - 3s - loss: 368.1112 - mean_absolute_error: 368.1112 - val_loss: 418.6878 - val_mean_absolute_error: 418.6878\n",
      "Epoch 128/145\n",
      " - 3s - loss: 368.2098 - mean_absolute_error: 368.2098 - val_loss: 418.9996 - val_mean_absolute_error: 418.9996\n",
      "Epoch 129/145\n",
      " - 3s - loss: 368.0050 - mean_absolute_error: 368.0050 - val_loss: 417.5404 - val_mean_absolute_error: 417.5404\n",
      "Epoch 130/145\n",
      " - 3s - loss: 368.1807 - mean_absolute_error: 368.1807 - val_loss: 419.0865 - val_mean_absolute_error: 419.0865\n",
      "Epoch 131/145\n",
      " - 3s - loss: 367.4445 - mean_absolute_error: 367.4445 - val_loss: 418.2075 - val_mean_absolute_error: 418.2075\n",
      "Epoch 132/145\n",
      " - 3s - loss: 367.7008 - mean_absolute_error: 367.7008 - val_loss: 417.6234 - val_mean_absolute_error: 417.6234\n",
      "Epoch 133/145\n",
      " - 3s - loss: 367.2365 - mean_absolute_error: 367.2365 - val_loss: 417.4584 - val_mean_absolute_error: 417.4584\n",
      "Epoch 134/145\n",
      " - 3s - loss: 367.6832 - mean_absolute_error: 367.6832 - val_loss: 418.3023 - val_mean_absolute_error: 418.3023\n",
      "Epoch 135/145\n",
      " - 3s - loss: 367.1053 - mean_absolute_error: 367.1053 - val_loss: 417.4670 - val_mean_absolute_error: 417.4670\n",
      "Epoch 136/145\n",
      " - 3s - loss: 366.7826 - mean_absolute_error: 366.7826 - val_loss: 418.0057 - val_mean_absolute_error: 418.0057\n",
      "Epoch 137/145\n",
      " - 3s - loss: 366.7595 - mean_absolute_error: 366.7595 - val_loss: 417.4710 - val_mean_absolute_error: 417.4710\n",
      "Epoch 138/145\n",
      " - 3s - loss: 366.6194 - mean_absolute_error: 366.6194 - val_loss: 417.8604 - val_mean_absolute_error: 417.8604\n",
      "Epoch 139/145\n",
      " - 3s - loss: 366.5178 - mean_absolute_error: 366.5178 - val_loss: 418.2480 - val_mean_absolute_error: 418.2480\n",
      "Epoch 140/145\n",
      " - 3s - loss: 366.5321 - mean_absolute_error: 366.5321 - val_loss: 417.1077 - val_mean_absolute_error: 417.1077\n",
      "Epoch 141/145\n",
      "lr changed to 0.0004199039773084223\n",
      " - 3s - loss: 365.2941 - mean_absolute_error: 365.2941 - val_loss: 417.7946 - val_mean_absolute_error: 417.7946\n",
      "Epoch 142/145\n",
      " - 3s - loss: 365.5607 - mean_absolute_error: 365.5607 - val_loss: 417.8676 - val_mean_absolute_error: 417.8676\n",
      "Epoch 143/145\n",
      " - 3s - loss: 365.2276 - mean_absolute_error: 365.2276 - val_loss: 417.0345 - val_mean_absolute_error: 417.0345\n",
      "Epoch 144/145\n",
      " - 3s - loss: 365.1251 - mean_absolute_error: 365.1251 - val_loss: 417.3600 - val_mean_absolute_error: 417.3600\n",
      "Epoch 145/145\n",
      " - 3s - loss: 365.0643 - mean_absolute_error: 365.0643 - val_loss: 417.2792 - val_mean_absolute_error: 417.2792\n",
      "\n",
      "val_mae is:417.27916424126386\n",
      "\n",
      "fold: 5\n",
      "Train on 125000 samples, validate on 25000 samples\n",
      "Epoch 1/145\n",
      " - 4s - loss: 2627.6680 - mean_absolute_error: 2627.6680 - val_loss: 937.3375 - val_mean_absolute_error: 937.3375\n",
      "Epoch 2/145\n",
      " - 3s - loss: 802.7030 - mean_absolute_error: 802.7030 - val_loss: 726.1773 - val_mean_absolute_error: 726.1773\n",
      "Epoch 3/145\n",
      " - 3s - loss: 661.8290 - mean_absolute_error: 661.8290 - val_loss: 643.1917 - val_mean_absolute_error: 643.1917\n",
      "Epoch 4/145\n",
      " - 3s - loss: 615.7901 - mean_absolute_error: 615.7901 - val_loss: 576.6172 - val_mean_absolute_error: 576.6172\n",
      "Epoch 5/145\n",
      " - 3s - loss: 633.9460 - mean_absolute_error: 633.9460 - val_loss: 603.9317 - val_mean_absolute_error: 603.9317\n",
      "Epoch 6/145\n",
      " - 3s - loss: 597.1888 - mean_absolute_error: 597.1888 - val_loss: 579.3048 - val_mean_absolute_error: 579.3048\n",
      "Epoch 7/145\n",
      " - 3s - loss: 556.7159 - mean_absolute_error: 556.7159 - val_loss: 523.9407 - val_mean_absolute_error: 523.9407\n",
      "Epoch 8/145\n",
      " - 4s - loss: 519.1758 - mean_absolute_error: 519.1758 - val_loss: 533.6433 - val_mean_absolute_error: 533.6433\n",
      "Epoch 9/145\n",
      " - 3s - loss: 563.0573 - mean_absolute_error: 563.0573 - val_loss: 509.6221 - val_mean_absolute_error: 509.6221\n",
      "Epoch 10/145\n",
      " - 3s - loss: 524.1384 - mean_absolute_error: 524.1384 - val_loss: 539.9783 - val_mean_absolute_error: 539.9783\n",
      "Epoch 11/145\n",
      " - 3s - loss: 496.4399 - mean_absolute_error: 496.4399 - val_loss: 494.9710 - val_mean_absolute_error: 494.9710\n",
      "Epoch 12/145\n",
      " - 3s - loss: 497.0531 - mean_absolute_error: 497.0531 - val_loss: 608.5234 - val_mean_absolute_error: 608.5234\n",
      "Epoch 13/145\n",
      " - 3s - loss: 534.3257 - mean_absolute_error: 534.3257 - val_loss: 494.0567 - val_mean_absolute_error: 494.0567\n",
      "Epoch 14/145\n",
      " - 3s - loss: 491.2926 - mean_absolute_error: 491.2926 - val_loss: 504.4358 - val_mean_absolute_error: 504.4358\n",
      "Epoch 15/145\n",
      " - 3s - loss: 521.8459 - mean_absolute_error: 521.8459 - val_loss: 513.0607 - val_mean_absolute_error: 513.0607\n",
      "Epoch 16/145\n",
      " - 3s - loss: 485.0489 - mean_absolute_error: 485.0489 - val_loss: 470.2864 - val_mean_absolute_error: 470.2864\n",
      "Epoch 17/145\n",
      " - 3s - loss: 489.0438 - mean_absolute_error: 489.0438 - val_loss: 572.4624 - val_mean_absolute_error: 572.4624\n",
      "Epoch 18/145\n",
      " - 3s - loss: 520.5767 - mean_absolute_error: 520.5767 - val_loss: 543.4656 - val_mean_absolute_error: 543.4656\n",
      "Epoch 19/145\n",
      " - 3s - loss: 470.6722 - mean_absolute_error: 470.6722 - val_loss: 470.1480 - val_mean_absolute_error: 470.1480\n",
      "Epoch 20/145\n",
      " - 3s - loss: 511.0877 - mean_absolute_error: 511.0877 - val_loss: 485.4597 - val_mean_absolute_error: 485.4597\n",
      "Epoch 21/145\n",
      "lr changed to 0.008999999798834323\n",
      " - 3s - loss: 443.4870 - mean_absolute_error: 443.4870 - val_loss: 458.1472 - val_mean_absolute_error: 458.1472\n",
      "Epoch 22/145\n",
      " - 3s - loss: 442.9151 - mean_absolute_error: 442.9151 - val_loss: 463.8240 - val_mean_absolute_error: 463.8240\n",
      "Epoch 23/145\n",
      " - 3s - loss: 439.9242 - mean_absolute_error: 439.9242 - val_loss: 464.9407 - val_mean_absolute_error: 464.9407\n",
      "Epoch 24/145\n",
      " - 3s - loss: 436.8287 - mean_absolute_error: 436.8287 - val_loss: 448.7722 - val_mean_absolute_error: 448.7722\n",
      "Epoch 25/145\n",
      " - 3s - loss: 437.1773 - mean_absolute_error: 437.1773 - val_loss: 449.9185 - val_mean_absolute_error: 449.9185\n",
      "Epoch 26/145\n",
      " - 3s - loss: 437.4861 - mean_absolute_error: 437.4861 - val_loss: 452.7481 - val_mean_absolute_error: 452.7481\n",
      "Epoch 27/145\n",
      " - 3s - loss: 443.1557 - mean_absolute_error: 443.1557 - val_loss: 455.1777 - val_mean_absolute_error: 455.1777\n",
      "Epoch 28/145\n",
      " - 3s - loss: 436.5671 - mean_absolute_error: 436.5671 - val_loss: 455.6449 - val_mean_absolute_error: 455.6449\n",
      "Epoch 29/145\n",
      " - 3s - loss: 434.9407 - mean_absolute_error: 434.9407 - val_loss: 473.1171 - val_mean_absolute_error: 473.1171\n",
      "Epoch 30/145\n",
      " - 3s - loss: 443.5219 - mean_absolute_error: 443.5219 - val_loss: 454.5929 - val_mean_absolute_error: 454.5929\n",
      "Epoch 31/145\n",
      " - 3s - loss: 434.6888 - mean_absolute_error: 434.6888 - val_loss: 449.6761 - val_mean_absolute_error: 449.6761\n",
      "Epoch 32/145\n",
      " - 3s - loss: 430.1385 - mean_absolute_error: 430.1385 - val_loss: 448.7666 - val_mean_absolute_error: 448.7666\n",
      "Epoch 33/145\n",
      " - 3s - loss: 431.5220 - mean_absolute_error: 431.5220 - val_loss: 462.6553 - val_mean_absolute_error: 462.6553\n",
      "Epoch 34/145\n",
      " - 3s - loss: 429.8191 - mean_absolute_error: 429.8191 - val_loss: 476.7729 - val_mean_absolute_error: 476.7729\n",
      "Epoch 35/145\n",
      " - 3s - loss: 428.7762 - mean_absolute_error: 428.7762 - val_loss: 447.0295 - val_mean_absolute_error: 447.0295\n",
      "Epoch 36/145\n",
      " - 3s - loss: 463.0939 - mean_absolute_error: 463.0939 - val_loss: 447.5137 - val_mean_absolute_error: 447.5137\n",
      "Epoch 37/145\n",
      " - 3s - loss: 427.3221 - mean_absolute_error: 427.3221 - val_loss: 443.8070 - val_mean_absolute_error: 443.8070\n",
      "Epoch 38/145\n",
      " - 3s - loss: 434.0933 - mean_absolute_error: 434.0933 - val_loss: 445.0278 - val_mean_absolute_error: 445.0278\n",
      "Epoch 39/145\n",
      " - 3s - loss: 427.0559 - mean_absolute_error: 427.0559 - val_loss: 448.8691 - val_mean_absolute_error: 448.8691\n",
      "Epoch 40/145\n",
      " - 3s - loss: 424.5924 - mean_absolute_error: 424.5924 - val_loss: 445.9921 - val_mean_absolute_error: 445.9921\n",
      "Epoch 41/145\n",
      "lr changed to 0.005399999767541885\n",
      " - 3s - loss: 411.7113 - mean_absolute_error: 411.7113 - val_loss: 435.6332 - val_mean_absolute_error: 435.6332\n",
      "Epoch 42/145\n",
      " - 3s - loss: 410.4905 - mean_absolute_error: 410.4905 - val_loss: 436.1707 - val_mean_absolute_error: 436.1707\n",
      "Epoch 43/145\n",
      " - 3s - loss: 409.1476 - mean_absolute_error: 409.1476 - val_loss: 453.9911 - val_mean_absolute_error: 453.9911\n",
      "Epoch 44/145\n",
      " - 3s - loss: 416.2904 - mean_absolute_error: 416.2904 - val_loss: 434.1591 - val_mean_absolute_error: 434.1591\n",
      "Epoch 45/145\n",
      " - 3s - loss: 409.7360 - mean_absolute_error: 409.7360 - val_loss: 441.1733 - val_mean_absolute_error: 441.1733\n",
      "Epoch 46/145\n",
      " - 3s - loss: 407.2142 - mean_absolute_error: 407.2142 - val_loss: 433.7636 - val_mean_absolute_error: 433.7636\n",
      "Epoch 47/145\n",
      " - 3s - loss: 405.1112 - mean_absolute_error: 405.1112 - val_loss: 433.0953 - val_mean_absolute_error: 433.0953\n",
      "Epoch 48/145\n",
      " - 3s - loss: 425.1213 - mean_absolute_error: 425.1213 - val_loss: 454.4281 - val_mean_absolute_error: 454.4281\n",
      "Epoch 49/145\n",
      " - 3s - loss: 408.9028 - mean_absolute_error: 408.9028 - val_loss: 437.5795 - val_mean_absolute_error: 437.5795\n",
      "Epoch 50/145\n",
      " - 3s - loss: 404.3506 - mean_absolute_error: 404.3506 - val_loss: 430.4516 - val_mean_absolute_error: 430.4516\n",
      "Epoch 51/145\n",
      " - 3s - loss: 403.8310 - mean_absolute_error: 403.8310 - val_loss: 434.3986 - val_mean_absolute_error: 434.3986\n",
      "Epoch 52/145\n",
      " - 3s - loss: 420.7230 - mean_absolute_error: 420.7230 - val_loss: 476.6557 - val_mean_absolute_error: 476.6557\n",
      "Epoch 53/145\n",
      " - 3s - loss: 410.7159 - mean_absolute_error: 410.7159 - val_loss: 432.4281 - val_mean_absolute_error: 432.4281\n",
      "Epoch 54/145\n",
      " - 3s - loss: 405.5624 - mean_absolute_error: 405.5624 - val_loss: 428.8772 - val_mean_absolute_error: 428.8772\n",
      "Epoch 55/145\n",
      " - 3s - loss: 402.7978 - mean_absolute_error: 402.7978 - val_loss: 431.0510 - val_mean_absolute_error: 431.0510\n",
      "Epoch 56/145\n",
      " - 3s - loss: 398.6084 - mean_absolute_error: 398.6084 - val_loss: 436.6804 - val_mean_absolute_error: 436.6804\n",
      "Epoch 57/145\n",
      " - 3s - loss: 403.6184 - mean_absolute_error: 403.6184 - val_loss: 443.8111 - val_mean_absolute_error: 443.8111\n",
      "Epoch 58/145\n",
      " - 3s - loss: 402.3330 - mean_absolute_error: 402.3330 - val_loss: 428.3766 - val_mean_absolute_error: 428.3766\n",
      "Epoch 59/145\n",
      " - 3s - loss: 400.7664 - mean_absolute_error: 400.7664 - val_loss: 444.4276 - val_mean_absolute_error: 444.4276\n",
      "Epoch 60/145\n",
      " - 3s - loss: 400.4895 - mean_absolute_error: 400.4895 - val_loss: 428.6689 - val_mean_absolute_error: 428.6689\n",
      "Epoch 61/145\n",
      "lr changed to 0.0032399998046457766\n",
      " - 3s - loss: 391.5632 - mean_absolute_error: 391.5632 - val_loss: 424.1200 - val_mean_absolute_error: 424.1200\n",
      "Epoch 62/145\n",
      " - 3s - loss: 390.9290 - mean_absolute_error: 390.9290 - val_loss: 429.0050 - val_mean_absolute_error: 429.0050\n",
      "Epoch 63/145\n",
      " - 3s - loss: 391.4526 - mean_absolute_error: 391.4526 - val_loss: 427.0878 - val_mean_absolute_error: 427.0878\n",
      "Epoch 64/145\n",
      " - 3s - loss: 391.4758 - mean_absolute_error: 391.4758 - val_loss: 423.8158 - val_mean_absolute_error: 423.8158\n",
      "Epoch 65/145\n",
      " - 3s - loss: 394.9078 - mean_absolute_error: 394.9078 - val_loss: 425.7923 - val_mean_absolute_error: 425.7923\n",
      "Epoch 66/145\n",
      " - 3s - loss: 389.4476 - mean_absolute_error: 389.4476 - val_loss: 428.0623 - val_mean_absolute_error: 428.0623\n",
      "Epoch 67/145\n",
      " - 3s - loss: 388.5431 - mean_absolute_error: 388.5431 - val_loss: 429.1717 - val_mean_absolute_error: 429.1717\n",
      "Epoch 68/145\n",
      " - 3s - loss: 387.4498 - mean_absolute_error: 387.4498 - val_loss: 430.0539 - val_mean_absolute_error: 430.0539\n",
      "Epoch 69/145\n",
      " - 3s - loss: 390.1782 - mean_absolute_error: 390.1782 - val_loss: 421.9784 - val_mean_absolute_error: 421.9784\n",
      "Epoch 70/145\n",
      " - 3s - loss: 388.1648 - mean_absolute_error: 388.1648 - val_loss: 424.9160 - val_mean_absolute_error: 424.9160\n",
      "Epoch 71/145\n",
      " - 3s - loss: 387.0702 - mean_absolute_error: 387.0702 - val_loss: 424.5317 - val_mean_absolute_error: 424.5317\n",
      "Epoch 72/145\n",
      " - 3s - loss: 387.8789 - mean_absolute_error: 387.8789 - val_loss: 420.1481 - val_mean_absolute_error: 420.1481\n",
      "Epoch 73/145\n",
      " - 3s - loss: 386.4407 - mean_absolute_error: 386.4407 - val_loss: 426.6376 - val_mean_absolute_error: 426.6376\n",
      "Epoch 74/145\n",
      " - 3s - loss: 386.4016 - mean_absolute_error: 386.4016 - val_loss: 419.9725 - val_mean_absolute_error: 419.9725\n",
      "Epoch 75/145\n",
      " - 3s - loss: 384.3597 - mean_absolute_error: 384.3597 - val_loss: 422.0731 - val_mean_absolute_error: 422.0731\n",
      "Epoch 76/145\n",
      " - 3s - loss: 390.1155 - mean_absolute_error: 390.1155 - val_loss: 433.6241 - val_mean_absolute_error: 433.6241\n",
      "Epoch 77/145\n",
      " - 3s - loss: 388.5514 - mean_absolute_error: 388.5514 - val_loss: 423.4389 - val_mean_absolute_error: 423.4389\n",
      "Epoch 78/145\n",
      " - 3s - loss: 389.3446 - mean_absolute_error: 389.3446 - val_loss: 447.9743 - val_mean_absolute_error: 447.9743\n",
      "Epoch 79/145\n",
      " - 3s - loss: 393.2606 - mean_absolute_error: 393.2606 - val_loss: 429.6764 - val_mean_absolute_error: 429.6764\n",
      "Epoch 80/145\n",
      " - 3s - loss: 384.2983 - mean_absolute_error: 384.2983 - val_loss: 419.7083 - val_mean_absolute_error: 419.7083\n",
      "Epoch 81/145\n",
      "lr changed to 0.0019439998548477888\n",
      " - 3s - loss: 378.1805 - mean_absolute_error: 378.1805 - val_loss: 417.3850 - val_mean_absolute_error: 417.3850\n",
      "Epoch 82/145\n",
      " - 3s - loss: 377.4346 - mean_absolute_error: 377.4346 - val_loss: 420.1432 - val_mean_absolute_error: 420.1432\n",
      "Epoch 83/145\n",
      " - 3s - loss: 377.3364 - mean_absolute_error: 377.3364 - val_loss: 417.3418 - val_mean_absolute_error: 417.3418\n",
      "Epoch 84/145\n",
      " - 3s - loss: 377.2589 - mean_absolute_error: 377.2589 - val_loss: 418.5319 - val_mean_absolute_error: 418.5319\n",
      "Epoch 85/145\n",
      " - 3s - loss: 376.6148 - mean_absolute_error: 376.6148 - val_loss: 418.2561 - val_mean_absolute_error: 418.2561\n",
      "Epoch 86/145\n",
      " - 3s - loss: 376.8251 - mean_absolute_error: 376.8251 - val_loss: 420.2569 - val_mean_absolute_error: 420.2569\n",
      "Epoch 87/145\n",
      " - 3s - loss: 377.4826 - mean_absolute_error: 377.4826 - val_loss: 419.3008 - val_mean_absolute_error: 419.3008\n",
      "Epoch 88/145\n",
      " - 3s - loss: 377.2668 - mean_absolute_error: 377.2668 - val_loss: 420.2066 - val_mean_absolute_error: 420.2066\n",
      "Epoch 89/145\n",
      " - 3s - loss: 376.2206 - mean_absolute_error: 376.2206 - val_loss: 424.0677 - val_mean_absolute_error: 424.0677\n",
      "Epoch 90/145\n",
      " - 3s - loss: 375.0791 - mean_absolute_error: 375.0791 - val_loss: 416.5641 - val_mean_absolute_error: 416.5641\n",
      "Epoch 91/145\n",
      " - 3s - loss: 375.1022 - mean_absolute_error: 375.1022 - val_loss: 419.7805 - val_mean_absolute_error: 419.7805\n",
      "Epoch 92/145\n",
      " - 3s - loss: 374.9288 - mean_absolute_error: 374.9288 - val_loss: 419.9620 - val_mean_absolute_error: 419.9620\n",
      "Epoch 93/145\n",
      " - 3s - loss: 375.1900 - mean_absolute_error: 375.1900 - val_loss: 419.6381 - val_mean_absolute_error: 419.6381\n",
      "Epoch 94/145\n",
      " - 3s - loss: 375.9079 - mean_absolute_error: 375.9079 - val_loss: 423.0593 - val_mean_absolute_error: 423.0593\n",
      "Epoch 95/145\n",
      " - 3s - loss: 374.1757 - mean_absolute_error: 374.1757 - val_loss: 418.6360 - val_mean_absolute_error: 418.6360\n",
      "Epoch 96/145\n",
      " - 3s - loss: 374.0223 - mean_absolute_error: 374.0223 - val_loss: 417.5630 - val_mean_absolute_error: 417.5630\n",
      "Epoch 97/145\n",
      " - 3s - loss: 373.9345 - mean_absolute_error: 373.9345 - val_loss: 422.6447 - val_mean_absolute_error: 422.6447\n",
      "Epoch 98/145\n",
      " - 3s - loss: 373.1984 - mean_absolute_error: 373.1984 - val_loss: 415.5774 - val_mean_absolute_error: 415.5774\n",
      "Epoch 99/145\n",
      " - 3s - loss: 373.2530 - mean_absolute_error: 373.2530 - val_loss: 418.0682 - val_mean_absolute_error: 418.0682\n",
      "Epoch 100/145\n",
      " - 3s - loss: 375.1796 - mean_absolute_error: 375.1796 - val_loss: 415.5568 - val_mean_absolute_error: 415.5568\n",
      "Epoch 101/145\n",
      "lr changed to 0.0011663999408483504\n",
      " - 3s - loss: 369.4827 - mean_absolute_error: 369.4827 - val_loss: 415.0105 - val_mean_absolute_error: 415.0105\n",
      "Epoch 102/145\n",
      " - 3s - loss: 368.6981 - mean_absolute_error: 368.6981 - val_loss: 414.8644 - val_mean_absolute_error: 414.8644\n",
      "Epoch 103/145\n",
      " - 3s - loss: 369.4777 - mean_absolute_error: 369.4777 - val_loss: 414.9612 - val_mean_absolute_error: 414.9612\n",
      "Epoch 104/145\n",
      " - 3s - loss: 368.7481 - mean_absolute_error: 368.7481 - val_loss: 415.1438 - val_mean_absolute_error: 415.1438\n",
      "Epoch 105/145\n",
      " - 3s - loss: 368.7820 - mean_absolute_error: 368.7820 - val_loss: 415.9705 - val_mean_absolute_error: 415.9705\n",
      "Epoch 106/145\n",
      " - 3s - loss: 368.1799 - mean_absolute_error: 368.1799 - val_loss: 415.0683 - val_mean_absolute_error: 415.0683\n",
      "Epoch 107/145\n",
      " - 3s - loss: 368.3935 - mean_absolute_error: 368.3935 - val_loss: 414.4344 - val_mean_absolute_error: 414.4344\n",
      "Epoch 108/145\n",
      " - 3s - loss: 368.0725 - mean_absolute_error: 368.0725 - val_loss: 415.3040 - val_mean_absolute_error: 415.3040\n",
      "Epoch 109/145\n",
      " - 3s - loss: 367.7103 - mean_absolute_error: 367.7103 - val_loss: 415.2135 - val_mean_absolute_error: 415.2135\n",
      "Epoch 110/145\n",
      " - 3s - loss: 367.5605 - mean_absolute_error: 367.5605 - val_loss: 415.4084 - val_mean_absolute_error: 415.4084\n",
      "Epoch 111/145\n",
      " - 3s - loss: 367.0451 - mean_absolute_error: 367.0451 - val_loss: 416.5945 - val_mean_absolute_error: 416.5945\n",
      "Epoch 112/145\n",
      " - 3s - loss: 367.2722 - mean_absolute_error: 367.2722 - val_loss: 415.6892 - val_mean_absolute_error: 415.6892\n",
      "Epoch 113/145\n",
      " - 4s - loss: 366.4252 - mean_absolute_error: 366.4252 - val_loss: 415.2176 - val_mean_absolute_error: 415.2176\n",
      "Epoch 114/145\n",
      " - 3s - loss: 366.9596 - mean_absolute_error: 366.9596 - val_loss: 415.4219 - val_mean_absolute_error: 415.4219\n",
      "Epoch 115/145\n",
      " - 3s - loss: 367.6034 - mean_absolute_error: 367.6034 - val_loss: 416.0186 - val_mean_absolute_error: 416.0186\n",
      "Epoch 116/145\n",
      " - 3s - loss: 366.5978 - mean_absolute_error: 366.5978 - val_loss: 416.9107 - val_mean_absolute_error: 416.9107\n",
      "Epoch 117/145\n",
      " - 3s - loss: 366.2752 - mean_absolute_error: 366.2752 - val_loss: 415.1570 - val_mean_absolute_error: 415.1570\n",
      "Epoch 118/145\n",
      " - 3s - loss: 365.4031 - mean_absolute_error: 365.4031 - val_loss: 414.9169 - val_mean_absolute_error: 414.9169\n",
      "Epoch 119/145\n",
      " - 3s - loss: 366.5302 - mean_absolute_error: 366.5302 - val_loss: 414.9449 - val_mean_absolute_error: 414.9449\n",
      "Epoch 120/145\n",
      " - 3s - loss: 365.3480 - mean_absolute_error: 365.3480 - val_loss: 414.6968 - val_mean_absolute_error: 414.6968\n",
      "Epoch 121/145\n",
      "lr changed to 0.0006998399505391716\n",
      " - 3s - loss: 363.2801 - mean_absolute_error: 363.2801 - val_loss: 414.2809 - val_mean_absolute_error: 414.2809\n",
      "Epoch 122/145\n",
      " - 3s - loss: 363.2673 - mean_absolute_error: 363.2673 - val_loss: 414.1937 - val_mean_absolute_error: 414.1937\n",
      "Epoch 123/145\n",
      " - 3s - loss: 363.3078 - mean_absolute_error: 363.3078 - val_loss: 414.0161 - val_mean_absolute_error: 414.0161\n",
      "Epoch 124/145\n",
      " - 3s - loss: 363.0547 - mean_absolute_error: 363.0547 - val_loss: 415.5365 - val_mean_absolute_error: 415.5365\n",
      "Epoch 125/145\n",
      " - 3s - loss: 363.1215 - mean_absolute_error: 363.1215 - val_loss: 413.6129 - val_mean_absolute_error: 413.6129\n",
      "Epoch 126/145\n",
      " - 3s - loss: 363.1414 - mean_absolute_error: 363.1414 - val_loss: 415.1038 - val_mean_absolute_error: 415.1038\n",
      "Epoch 127/145\n",
      " - 3s - loss: 362.5315 - mean_absolute_error: 362.5315 - val_loss: 416.2421 - val_mean_absolute_error: 416.2421\n",
      "Epoch 128/145\n",
      " - 3s - loss: 362.6181 - mean_absolute_error: 362.6181 - val_loss: 414.3458 - val_mean_absolute_error: 414.3458\n",
      "Epoch 129/145\n",
      " - 3s - loss: 361.8047 - mean_absolute_error: 361.8047 - val_loss: 414.0293 - val_mean_absolute_error: 414.0293\n",
      "Epoch 130/145\n",
      " - 3s - loss: 362.1982 - mean_absolute_error: 362.1982 - val_loss: 416.4054 - val_mean_absolute_error: 416.4054\n",
      "Epoch 131/145\n",
      " - 3s - loss: 362.3398 - mean_absolute_error: 362.3398 - val_loss: 413.9319 - val_mean_absolute_error: 413.9319\n",
      "Epoch 132/145\n",
      " - 3s - loss: 361.6081 - mean_absolute_error: 361.6081 - val_loss: 414.3143 - val_mean_absolute_error: 414.3143\n",
      "Epoch 133/145\n",
      " - 3s - loss: 361.6499 - mean_absolute_error: 361.6499 - val_loss: 414.9340 - val_mean_absolute_error: 414.9340\n",
      "Epoch 134/145\n",
      " - 3s - loss: 361.7748 - mean_absolute_error: 361.7748 - val_loss: 414.8799 - val_mean_absolute_error: 414.8799\n",
      "Epoch 135/145\n",
      " - 3s - loss: 361.2034 - mean_absolute_error: 361.2034 - val_loss: 413.9105 - val_mean_absolute_error: 413.9105\n",
      "Epoch 136/145\n",
      " - 3s - loss: 361.6259 - mean_absolute_error: 361.6259 - val_loss: 414.3024 - val_mean_absolute_error: 414.3024\n",
      "Epoch 137/145\n",
      " - 3s - loss: 361.1919 - mean_absolute_error: 361.1919 - val_loss: 414.3258 - val_mean_absolute_error: 414.3258\n",
      "Epoch 138/145\n",
      " - 3s - loss: 361.5076 - mean_absolute_error: 361.5076 - val_loss: 414.0210 - val_mean_absolute_error: 414.0210\n",
      "Epoch 139/145\n",
      " - 3s - loss: 360.5462 - mean_absolute_error: 360.5462 - val_loss: 416.3054 - val_mean_absolute_error: 416.3054\n",
      "Epoch 140/145\n",
      " - 3s - loss: 361.0276 - mean_absolute_error: 361.0276 - val_loss: 414.8624 - val_mean_absolute_error: 414.8624\n",
      "Epoch 141/145\n",
      "lr changed to 0.0004199039773084223\n",
      " - 3s - loss: 359.6409 - mean_absolute_error: 359.6409 - val_loss: 413.9110 - val_mean_absolute_error: 413.9110\n",
      "Epoch 142/145\n",
      " - 3s - loss: 359.1208 - mean_absolute_error: 359.1208 - val_loss: 414.5091 - val_mean_absolute_error: 414.5091\n",
      "Epoch 143/145\n",
      " - 3s - loss: 358.9915 - mean_absolute_error: 358.9915 - val_loss: 413.4049 - val_mean_absolute_error: 413.4049\n",
      "Epoch 144/145\n",
      " - 3s - loss: 359.4672 - mean_absolute_error: 359.4672 - val_loss: 413.9082 - val_mean_absolute_error: 413.9082\n",
      "Epoch 145/145\n",
      " - 3s - loss: 358.8786 - mean_absolute_error: 358.8786 - val_loss: 413.7657 - val_mean_absolute_error: 413.7657\n",
      "\n",
      "val_mae is:413.76572185791014\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "416.11608949802439"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 6\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "import keras \n",
    "\n",
    "b_size = 2000\n",
    "max_epochs = 145\n",
    "oof_pred = np.zeros((len(X_pca), ))\n",
    "\n",
    "sub = pd.read_csv('datalab/62977/used_car_testB_20200421.csv',sep = ' ')[['SaleID']].copy()\n",
    "sub['price'] = 0\n",
    "\n",
    "avg_mae = 0\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(X_pca, y)):\n",
    "    print('fold:', fold)\n",
    "    X_train, y_train = X_pca[trn_idx], y[trn_idx]\n",
    "    X_val, y_val = X_pca[val_idx], y[val_idx]\n",
    "    \n",
    "    model = NN_model(X_train.shape[1])\n",
    "    simple_adam = keras.optimizers.Adam(lr = 0.015)\n",
    "    \n",
    "    model.compile(loss='mae', optimizer=simple_adam,metrics=['mae'])\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_score', patience=10, verbose=2, mode='min')\n",
    "    es.set_model(model)\n",
    "    metric = Metric(model, [es], [(X_train, y_train), (X_val, y_val)])\n",
    "    model.fit(X_train, y_train, batch_size=b_size, epochs=max_epochs, \n",
    "              validation_data = [X_val, y_val],\n",
    "              callbacks=[reduce_lr], shuffle=True, verbose=2)\n",
    "    y_pred3 = model.predict(X_val)\n",
    "    y_pred = np.zeros((len(y_pred3), ))\n",
    "    sub['price'] += model.predict(test).reshape(-1,)/n_splits\n",
    "    for i in range(len(y_pred3)):\n",
    "        y_pred[i] = y_pred3[i]\n",
    "        \n",
    "    oof_pred[val_idx] = y_pred\n",
    "    val_mae = mean_absolute_error(y[val_idx], y_pred)\n",
    "    avg_mae += val_mae/n_splits\n",
    "    print()\n",
    "    print('val_mae is:{}'.format(val_mae))\n",
    "    print()\n",
    "mean_absolute_error(y, oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('nn_sub_{}_{}.csv'.format('mae', sub['price'].mean()), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
